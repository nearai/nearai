{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NEAR AI: Building a Truly Open AI","text":"<p>Welcome! NEAR AI is a toolkit to help build, measure, and deploy AI systems focused on agents.</p> <p>Driven by one of the minds behinds TensorFlow and the Transformer Architecture, NEAR AI puts you back in control. Your data stays yours, and your AI works for you, with no compromises on privacy or ownership.</p> <ul> <li> <p> NEAR AI Agents</p> <p>Autonomous system that can interact with you and use tools to solve tasks</p> <p>  Quickstart  Registry  Tools </p> </li> <li> <p> AI Models</p> <p>Best in class AI models that you can use and fine-tune to solve your tasks</p> <p>  Benchmarks  Fine-Tuning </p> </li> <li> <p> Developer Hub </p> <p>NEAR AI developer hub where you can discover and deploy agents, datasets, and models with ease. </p> <p>  Agents  Models  Datasets </p> </li> <li> <p> Community </p> <p>Join our community! Get help and contribute to the future of AI</p> <p> Community</p> </li> </ul> <p>Alpha</p> <p>NEAR AI is currently in <code>alpha</code> - we're building something special and shipping new features every day! Want to help shape the future of AI? Join our community and contribute! \ud83d\ude80</p> <ul> <li>\ud83d\udc1b Report bugs and suggest features</li> <li>\ud83d\udcbb Submit pull requests</li> <li>\ud83d\udcd6 Improve documentation</li> <li>\ud83e\udd1d Help other users in the community</li> <li>\ud83c\udf1f Star our repository</li> </ul> <p>Check out our contributing guide to get started.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#nearai","title":"nearai","text":""},{"location":"api/#nearai.EntryLocation","title":"EntryLocation","text":"<p>               Bases: <code>BaseModel</code></p> <p>EntryLocation</p> Source code in <code>nearai/openapi_client/models/entry_location.py</code> <pre><code>class EntryLocation(BaseModel):\n    \"\"\"\n    EntryLocation\n    \"\"\" # noqa: E501\n    namespace: StrictStr\n    name: StrictStr\n    version: StrictStr\n    __properties: ClassVar[List[str]] = [\"namespace\", \"name\", \"version\"]\n\n    model_config = ConfigDict(\n        populate_by_name=True,\n        validate_assignment=True,\n        protected_namespaces=(),\n    )\n\n\n    def to_str(self) -&gt; str:\n        \"\"\"Returns the string representation of the model using alias\"\"\"\n        return pprint.pformat(self.model_dump(by_alias=True))\n\n    def to_json(self) -&gt; str:\n        \"\"\"Returns the JSON representation of the model using alias\"\"\"\n        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead\n        return json.dumps(self.to_dict())\n\n    @classmethod\n    def from_json(cls, json_str: str) -&gt; Optional[Self]:\n        \"\"\"Create an instance of EntryLocation from a JSON string\"\"\"\n        return cls.from_dict(json.loads(json_str))\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Return the dictionary representation of the model using alias.\n\n        This has the following differences from calling pydantic's\n        `self.model_dump(by_alias=True)`:\n\n        * `None` is only added to the output dict for nullable fields that\n          were set at model initialization. Other fields with value `None`\n          are ignored.\n        \"\"\"\n        excluded_fields: Set[str] = set([\n        ])\n\n        _dict = self.model_dump(\n            by_alias=True,\n            exclude=excluded_fields,\n            exclude_none=True,\n        )\n        return _dict\n\n    @classmethod\n    def from_dict(cls, obj: Optional[Dict[str, Any]]) -&gt; Optional[Self]:\n        \"\"\"Create an instance of EntryLocation from a dict\"\"\"\n        if obj is None:\n            return None\n\n        if not isinstance(obj, dict):\n            return cls.model_validate(obj)\n\n        _obj = cls.model_validate({\n            \"namespace\": obj.get(\"namespace\"),\n            \"name\": obj.get(\"name\"),\n            \"version\": obj.get(\"version\")\n        })\n        return _obj\n</code></pre>"},{"location":"api/#nearai.EntryLocation.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(obj: Optional[Dict[str, Any]]) -&gt; Optional[Self]\n</code></pre> <p>Create an instance of EntryLocation from a dict</p> Source code in <code>nearai/openapi_client/models/entry_location.py</code> <pre><code>@classmethod\ndef from_dict(cls, obj: Optional[Dict[str, Any]]) -&gt; Optional[Self]:\n    \"\"\"Create an instance of EntryLocation from a dict\"\"\"\n    if obj is None:\n        return None\n\n    if not isinstance(obj, dict):\n        return cls.model_validate(obj)\n\n    _obj = cls.model_validate({\n        \"namespace\": obj.get(\"namespace\"),\n        \"name\": obj.get(\"name\"),\n        \"version\": obj.get(\"version\")\n    })\n    return _obj\n</code></pre>"},{"location":"api/#nearai.EntryLocation.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(json_str: str) -&gt; Optional[Self]\n</code></pre> <p>Create an instance of EntryLocation from a JSON string</p> Source code in <code>nearai/openapi_client/models/entry_location.py</code> <pre><code>@classmethod\ndef from_json(cls, json_str: str) -&gt; Optional[Self]:\n    \"\"\"Create an instance of EntryLocation from a JSON string\"\"\"\n    return cls.from_dict(json.loads(json_str))\n</code></pre>"},{"location":"api/#nearai.EntryLocation.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Return the dictionary representation of the model using alias.</p> <p>This has the following differences from calling pydantic's <code>self.model_dump(by_alias=True)</code>:</p> <ul> <li><code>None</code> is only added to the output dict for nullable fields that   were set at model initialization. Other fields with value <code>None</code>   are ignored.</li> </ul> Source code in <code>nearai/openapi_client/models/entry_location.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Return the dictionary representation of the model using alias.\n\n    This has the following differences from calling pydantic's\n    `self.model_dump(by_alias=True)`:\n\n    * `None` is only added to the output dict for nullable fields that\n      were set at model initialization. Other fields with value `None`\n      are ignored.\n    \"\"\"\n    excluded_fields: Set[str] = set([\n    ])\n\n    _dict = self.model_dump(\n        by_alias=True,\n        exclude=excluded_fields,\n        exclude_none=True,\n    )\n    return _dict\n</code></pre>"},{"location":"api/#nearai.EntryLocation.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Returns the JSON representation of the model using alias</p> Source code in <code>nearai/openapi_client/models/entry_location.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Returns the JSON representation of the model using alias\"\"\"\n    # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead\n    return json.dumps(self.to_dict())\n</code></pre>"},{"location":"api/#nearai.EntryLocation.to_str","title":"to_str","text":"<pre><code>to_str() -&gt; str\n</code></pre> <p>Returns the string representation of the model using alias</p> Source code in <code>nearai/openapi_client/models/entry_location.py</code> <pre><code>def to_str(self) -&gt; str:\n    \"\"\"Returns the string representation of the model using alias\"\"\"\n    return pprint.pformat(self.model_dump(by_alias=True))\n</code></pre>"},{"location":"api/#nearai.parse_location","title":"parse_location","text":"<pre><code>parse_location(entry_location: str) -&gt; EntryLocation\n</code></pre> <p>Create a EntryLocation from a string in the format namespace/name/version.</p> Source code in <code>nearai/lib.py</code> <pre><code>def parse_location(entry_location: str) -&gt; EntryLocation:\n    \"\"\"Create a EntryLocation from a string in the format namespace/name/version.\"\"\"\n    match = entry_location_pattern.match(entry_location)\n\n    if match is None:\n        raise ValueError(f\"Invalid entry format: {entry_location}. Should have the format &lt;namespace&gt;/&lt;name&gt;/&lt;version&gt;\")\n\n    return EntryLocation(\n        namespace=match.group(\"namespace\"),\n        name=match.group(\"name\"),\n        version=match.group(\"version\"),\n    )\n</code></pre>"},{"location":"api/#nearai.agent_creator","title":"agent_creator","text":""},{"location":"api/#nearai.agent_creator.create_new_agent","title":"create_new_agent","text":"<pre><code>create_new_agent(\n    namespace: str,\n    name: Optional[str],\n    description: Optional[str],\n) -&gt; None\n</code></pre> <p>Create a new agent from scratch with interactive options.</p> Source code in <code>nearai/agent_creator.py</code> <pre><code>def create_new_agent(namespace: str, name: Optional[str], description: Optional[str]) -&gt; None:\n    \"\"\"Create a new agent from scratch with interactive options.\"\"\"\n    # If no name/description provided, use interactive prompts\n    init_instructions = \"\"\n    if name is None and description is None:\n        _, name, description, init_instructions = prompt_agent_details()\n\n    # Set the agent path\n    registry_folder = get_registry_folder()\n    if registry_folder is None:\n        raise ValueError(\"Registry folder path cannot be None\")\n\n    # Narrow the type of namespace &amp; name from Optional[str] to str\n    namespace_str: str = namespace if namespace is not None else \"\"\n    if namespace_str == \"\":\n        raise ValueError(\"Namespace cannot be None or empty\")\n\n    name_str: str = name if name is not None else \"\"\n    if name_str == \"\":\n        raise ValueError(\"Name cannot be None or empty\")\n\n    agent_path = registry_folder / namespace_str / name_str / \"0.0.1\"\n    agent_path.mkdir(parents=True, exist_ok=True)\n\n    metadata: Dict[str, Any] = {\n        \"name\": name_str,\n        \"version\": \"0.0.1\",\n        \"description\": description or \"\",\n        \"category\": \"agent\",\n        \"tags\": [],\n        \"details\": {\n            \"agent\": {\n                \"defaults\": {\n                    \"model\": DEFAULT_MODEL,\n                    \"model_provider\": DEFAULT_PROVIDER,\n                    \"model_temperature\": DEFAULT_MODEL_TEMPERATURE,\n                    \"model_max_tokens\": DEFAULT_MODEL_MAX_TOKENS,\n                }\n            }\n        },\n        \"show_entry\": True,\n    }\n\n    metadata_path = agent_path / \"metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        json.dump(metadata, f, indent=2)\n\n    # Create a default agent.py with the provided initial instructions\n    agent_py_content = f\"\"\"from nearai.agents.environment import Environment\n\n\ndef run(env: Environment):\n    # Your agent code here\n    prompt = {{\"role\": \"system\", \"content\": \"{init_instructions}\"}}\n    result = env.completion([prompt] + env.list_messages())\n    env.add_reply(result)\n    env.request_user_input()\n\nrun(env)\n\n\"\"\"\n    agent_py_path = agent_path / \"agent.py\"\n    with open(agent_py_path, \"w\") as f:\n        f.write(agent_py_content)\n\n    # Display success message and options\n    display_success_and_options(agent_path)\n</code></pre>"},{"location":"api/#nearai.agent_creator.display_success_and_options","title":"display_success_and_options","text":"<pre><code>display_success_and_options(agent_path: Path) -&gt; None\n</code></pre> <p>Display success message and interactive options for next steps.</p> Source code in <code>nearai/agent_creator.py</code> <pre><code>def display_success_and_options(agent_path: Path) -&gt; None:\n    \"\"\"Display success message and interactive options for next steps.\"\"\"\n    console = Console()\n    success_title = Text(\" \ud83c\udf89 SUCCESS!\", style=\"bold green\")\n    path_text = Text.assemble((\"\\n  \u2022 New AI Agent created at: \", \"bold green\"), (f\"{agent_path}\", \"bold\"))\n\n    files_panel = Panel(\n        Text.assemble(\n            (\"Edit agent code here:\\n\\n\", \"yellow\"),\n            (f\"\ud83d\udcc4 - {agent_path}/agent.py\\n\", \"bold blue\"),\n            (f\"\ud83d\udcc4 - {agent_path}/metadata.json\", \"bold blue\"),\n        ),\n        title=\"Agent Files\",\n        border_style=\"yellow\",\n    )\n\n    commands_panel = Panel(\n        Text.assemble(\n            (\"Run this agent locally:\\n\", \"light_green\"),\n            (f\"  nearai agent interactive {agent_path} --local\\n\\n\", \"bold\"),\n            (\"Upload this agent to NEAR AI's public registry:\\n\", \"light_green\"),\n            (f\"  nearai registry upload {agent_path}\\n\\n\", \"bold\"),\n            (\"Run ANY agent from your local registry:\\n\", \"light_green\"),\n            (\"  nearai agent interactive --local\", \"bold\"),\n        ),\n        title=\"Useful Commands\",\n        border_style=\"green\",\n    )\n\n    console.print(\"\\n\")\n    console.print(success_title)\n    console.print(path_text)\n    console.print(\"\\n\")\n    console.print(files_panel)\n    console.print(\"\\n\")\n    console.print(commands_panel)\n    console.print(\"\\n\")\n\n    # Create next steps options with proper markup\n    options = [\"Upload agent to NEAR AI registry \ud83d\ude80\", \"Run agent \ud83d\udcac\", \"Open agent code in editor \ud83e\uddd1\u200d\ud83d\udcbb\", \"Exit \ud83d\udc4b\"]\n\n    # Create the panel with direct markup\n    next_steps_panel = Panel(\n        f\"\"\"[bold blue]What would you like to do next?[/bold blue]\n\n[bold blue]1.[/bold blue] {options[0]}\n[bold blue]2.[/bold blue] {options[1]}\n[bold blue]3.[/bold blue] {options[2]}\n[bold blue]4.[/bold blue] {options[3]}\"\"\",\n        title=\"[bold blue]Next Steps[/bold blue]\",\n        border_style=\"blue\",\n    )\n    console.print(next_steps_panel)\n    console.print(\"\\n\")\n\n    # Main options loop\n    while True:\n        try:\n            choice = int(Prompt.ask(\"[bold]Choose an option\", default=\"4\")) - 1\n            if not (0 &lt;= choice &lt; len(options)):\n                console.print(\"[red]Invalid choice. Please try again.\")\n                continue\n        except ValueError:\n            console.print(\"[red]Please enter a valid number.\")\n            continue\n\n        # Exit option\n        if choice == 3:  # Exit\n            break\n\n        # Handle user choice\n        if choice == 0:  # Upload agent\n            console.print(\"\\n[green]Uploading agent to registry...[/green]\")\n            try:\n                registry.upload(agent_path, show_progress=True)\n                console.print(\"[green bold]\u2713 Agent uploaded successfully![/green bold]\\n\")\n\n                # Extract namespace and name from agent_path\n                namespace = agent_path.parts[-3]\n                agent_name = agent_path.parts[-2]\n\n                # Generate and display link to the agent\n                agent_url = f\"https://app.near.ai/agents/{namespace}/{agent_name}/latest\"\n                console.print(\"[yellow]View your agent in the NEAR AI Developer Hub:[/yellow]\")\n                console.print(f\"[link={agent_url}]{agent_url}[/link]\\n\")\n\n                break  # Exit after successful upload\n            except Exception as e:\n                console.print(f\"[red bold]\u2717 Error uploading agent: {str(e)}[/red bold]\\n\")\n\n        elif choice == 1:  # Run agent\n            console.print(\"\\n[green]Running agent...[/green]\")\n            try:\n                from nearai.cli import AgentCli\n\n                agent_cli = AgentCli()\n                agent_cli.interactive(str(agent_path), local=True)\n                break  # Exit after running agent\n            except Exception as e:\n                console.print(f\"[red bold]\u2717 Error running agent: {str(e)}[/red bold]\\n\")\n\n        elif choice == 2:  # Code agent\n            console.print(\"\\n[green]Attempting to open agent in a code editor...[/green]\")\n            try:\n                # Check for common editors\n                editors = [\n                    (\"Visual Studio Code\", \"code\"),\n                    (\"PyCharm\", \"charm\"),\n                    (\"Atom\", \"atom\"),\n                    (\"IntelliJ IDEA\", \"idea\"),\n                ]\n\n                # Try each editor\n                editor_found = False\n                for editor_name, command in editors:\n                    cmd_path = shutil.which(command)\n                    if cmd_path:\n                        subprocess.run([command, str(agent_path)], check=False)\n                        console.print(f\"[green bold]\u2713 Agent opened in {editor_name}![/green bold]\\n\")\n                        editor_found = True\n                        break\n\n                # If no code editor found, try opening in file explorer\n                if not editor_found:\n                    console.print(\"[yellow]Could not find any common code editors. Trying file explorer...[/yellow]\")\n                    system = platform.system()\n                    explorer_opened = False\n\n                    if system == \"Windows\":\n                        subprocess.run([\"explorer\", str(agent_path)], check=False)\n                        explorer_opened = True\n                    elif system == \"Darwin\":  # macOS\n                        subprocess.run([\"open\", str(agent_path)], check=False)\n                        explorer_opened = True\n                    elif system == \"Linux\":\n                        subprocess.run([\"xdg-open\", str(agent_path)], check=False)\n                        explorer_opened = True\n\n                    if explorer_opened:\n                        console.print(\"[green bold]\u2713 Agent directory opened in file explorer![/green bold]\\n\")\n                    else:\n                        console.print(\"[yellow]Could not open directory automatically.[/yellow]\")\n                        console.print(\"[yellow]Your agent is located at:[/yellow]\")\n                        console.print(f\"[bold cyan]{agent_path}[/bold cyan]\\n\")\n\n                break  # Exit after attempt\n            except Exception as e:\n                console.print(f\"[red bold]\u2717 Error opening agent: {str(e)}[/red bold]\")\n                console.print(f\"[yellow]Your agent is located at: {agent_path}[/yellow]\\n\")\n</code></pre>"},{"location":"api/#nearai.agent_creator.fork_agent","title":"fork_agent","text":"<pre><code>fork_agent(\n    fork: str, namespace: str, new_name: Optional[str]\n) -&gt; None\n</code></pre> <p>Fork an existing agent.</p> Source code in <code>nearai/agent_creator.py</code> <pre><code>def fork_agent(fork: str, namespace: str, new_name: Optional[str]) -&gt; None:\n    \"\"\"Fork an existing agent.\"\"\"\n    import shutil\n\n    # Parse the fork parameter\n    try:\n        entry_location = parse_location(fork)\n        fork_namespace = entry_location.namespace\n        fork_name = entry_location.name\n        fork_version = entry_location.version\n    except ValueError:\n        print(\"Invalid fork parameter format. Expected format: &lt;namespace&gt;/&lt;agent-name&gt;/&lt;version&gt;\")\n        return\n\n    # Download the agent from the registry\n    agent_location = f\"{fork_namespace}/{fork_name}/{fork_version}\"\n    print(f\"Downloading agent '{agent_location}'...\")\n    registry.download(agent_location, force=False, show_progress=True)\n    source_path = get_registry_folder() / fork_namespace / fork_name / fork_version\n\n    # Prompt for the new agent name if not provided\n    if not new_name:\n        new_name = input(\"Enter the new agent name: \").strip()\n        if not new_name:\n            print(\"Agent name cannot be empty.\")\n            return\n\n        # confirm pattern is ok\n        identifier_pattern = re.compile(r\"^[a-zA-Z0-9_\\-.]+$\")\n        if identifier_pattern.match(new_name) is None:\n            print(\"Invalid Name, please choose something different\")\n            return\n\n    # Set the destination path\n    dest_path = get_registry_folder() / namespace / new_name / \"0.0.1\"\n\n    # Copy the agent files\n    shutil.copytree(source_path, dest_path)\n\n    # Update metadata.json\n    metadata_path = dest_path / \"metadata.json\"\n    with open(metadata_path, \"r\") as file:\n        metadata = json.load(file)\n\n    metadata[\"name\"] = new_name\n    metadata[\"version\"] = \"0.0.1\"\n\n    with open(metadata_path, \"w\") as file:\n        json.dump(metadata, file, indent=2)\n\n    print(f\"\\nForked agent '{agent_location}' to '{dest_path}'\")\n    print(f\"Agent '{new_name}' created at '{dest_path}' with updated metadata.\")\n\n    # Display success and interactive options\n    display_success_and_options(dest_path)\n</code></pre>"},{"location":"api/#nearai.agent_creator.prompt_agent_details","title":"prompt_agent_details","text":"<pre><code>prompt_agent_details() -&gt; Tuple[str, str, str, str]\n</code></pre> <p>Prompt user for agent details and return them.</p> Source code in <code>nearai/agent_creator.py</code> <pre><code>def prompt_agent_details() -&gt; Tuple[str, str, str, str]:\n    \"\"\"Prompt user for agent details and return them.\"\"\"\n    console = Console()\n\n    # Get namespace from CONFIG, with null check\n    from nearai.config import CONFIG\n\n    if CONFIG.auth is None:\n        raise ValueError(\"Not logged in. Please run 'nearai login' first.\")\n    namespace = CONFIG.auth.namespace\n\n    # Welcome message\n    console.print(NEAR_AI_BANNER)\n    welcome_panel = Panel(\n        Text.assemble(\n            (\"Let's create a new agent! \ud83e\uddbe \\n\", \"bold green\"),\n            (\"We'll need some basic information to get started.\", \"dim\"),\n        ),\n        title=\"Agent Creator\",\n        border_style=\"green\",\n    )\n    console.print(welcome_panel)\n    console.print(\"\\n\")\n\n    # Name prompt with explanation\n    name_info = Panel(\n        Text.assemble(\n            (\"Choose a unique name for your agent using only:\\n\\n\", \"\"),\n            (\"\u2022 letters\\n\", \"dim\"),\n            (\"\u2022 numbers\\n\", \"dim\"),\n            (\"\u2022 dots (.)\\n\", \"dim\"),\n            (\"\u2022 hyphens (-)\\n\", \"dim\"),\n            (\"\u2022 underscores (_)\\n\\n\", \"dim\"),\n            (\"Examples: 'code-reviewer', 'data.analyzer', 'text_summarizer'\", \"green\"),\n        ),\n        title=\"Agent Name Rules\",\n        border_style=\"blue\",\n    )\n    console.print(name_info)\n\n    while True:\n        name = Prompt.ask(\"[bold blue]Enter agent name\").strip()\n        # Validate name format\n        if not re.match(r\"^[a-zA-Z0-9][a-zA-Z0-9._-]*$\", name):\n            console.print(\n                \"[red]\u274c Invalid name format. Please use only letters, numbers, dots, hyphens, or underscores.\"\n            )\n            continue\n        if \" \" in name:\n            console.print(\"[red]\u274c Spaces are not allowed. Use dots, hyphens, or underscores instead.\")\n            continue\n        break\n\n    console.print(\"\\n\")\n\n    # Description prompt\n    description_info = Panel(\n        \"Describe what your agent will do in a few words...\", title=\"Description Info\", border_style=\"blue\"\n    )\n    console.print(description_info)\n    description = Prompt.ask(\"[bold blue]Enter description\")\n\n    console.print(\"\\n\")\n\n    # Initial instructions prompt\n    init_instructions_info = Panel(\n        Text.assemble(\n            (\"Provide initial instructions for your AI agent...\\n\\n\", \"\"),\n            (\"This will be used as the system message to guide the agent's behavior.\\n\", \"dim\"),\n            (\"You can edit these instructions later in the `agent.py` file.\\n\\n\", \"dim\"),\n            (\n                \"Example: You are a helpful humorous assistant. Use puns or jokes to make the user smile.\",\n                \"green\",\n            ),\n        ),\n        title=\"Instructions\",\n        border_style=\"blue\",\n    )\n    console.print(init_instructions_info)\n    init_instructions = Prompt.ask(\"[bold blue]Enter instructions\")\n\n    # Confirmation\n    console.print(\"\\n\")\n    summary_panel = Panel(\n        Text.assemble(\n            (\"Summary of your new agent:\\n\\n\", \"bold\"),\n            (\"Namespace/Account:    \", \"dim\"),\n            (f\"{namespace}\\n\", \"green\"),\n            (\"Agent Name:           \", \"dim\"),\n            (f\"{name}\\n\", \"green\"),\n            (\"Description:          \", \"dim\"),\n            (f\"{description}\\n\", \"green\"),\n            (\"Instructions:         \", \"dim\"),\n            (f\"{init_instructions}\", \"green\"),\n        ),\n        title=\"\ud83d\udccb Review\",\n        border_style=\"green\",\n    )\n    console.print(summary_panel)\n    console.print(\"\\n\")\n\n    if not Confirm.ask(\"[bold]Would you like to proceed?\", default=True):\n        console.print(\"[red]\u274c Agent creation cancelled\")\n        raise SystemExit(0)\n\n    return namespace, name, description, init_instructions\n</code></pre>"},{"location":"api/#nearai.agents","title":"agents","text":""},{"location":"api/#nearai.agents.agent","title":"agent","text":""},{"location":"api/#nearai.agents.agent.Agent","title":"Agent","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/agents/agent.py</code> <pre><code>class Agent(object):\n    def __init__(  # noqa: D107\n        self, identifier: str, agent_files: Union[List, Path], metadata: Dict, change_to_temp_dir: bool = True\n    ):  # noqa: D107\n        self.code: Optional[CodeType] = None\n        self.file_cache: dict[str, Union[str, bytes]] = {}\n        self.identifier = identifier\n        name_parts = identifier.split(\"/\")\n        self.namespace = name_parts[0]\n        self.name = name_parts[1]\n        self.version = name_parts[2]\n\n        self.metadata = metadata\n        self.env_vars: Dict[str, Any] = {}\n\n        self.model = \"\"\n        self.model_provider = \"\"\n        self.model_temperature: Optional[float] = None\n        self.model_max_tokens: Optional[int] = None\n        self.max_iterations = 1\n        self.welcome_title: Optional[str] = None\n        self.welcome_description: Optional[str] = None\n\n        self.set_agent_metadata(metadata)\n        self.agent_files = agent_files\n        self.original_cwd = os.getcwd()\n\n        self.temp_dir = self.write_agent_files_to_temp(agent_files)\n        self.ts_runner_dir = \"\"\n        self.change_to_temp_dir = change_to_temp_dir\n        self.agent_filename = \"\"\n        self.agent_language = \"\"\n\n    def get_full_name(self):\n        \"\"\"Returns full agent name.\"\"\"\n        return f\"{self.namespace}/{self.name}/{self.version}\"\n\n    @staticmethod\n    def write_agent_files_to_temp(agent_files):\n        \"\"\"Write agent files to a temporary directory.\"\"\"\n        unique_id = uuid.uuid4().hex\n        temp_dir = os.path.join(tempfile.gettempdir(), f\"agent_{unique_id}\")\n\n        if isinstance(agent_files, List):\n            os.makedirs(temp_dir, exist_ok=True)\n\n            for file_obj in agent_files:\n                file_path = os.path.join(temp_dir, file_obj[\"filename\"])\n\n                try:\n                    if not os.path.exists(os.path.dirname(file_path)):\n                        os.makedirs(os.path.dirname(file_path))\n\n                    content = file_obj[\"content\"]\n\n                    if isinstance(content, dict) or isinstance(content, list):\n                        try:\n                            content = json.dumps(content)\n                        except Exception as e:\n                            print(f\"Error converting content to json: {e}\")\n                        content = str(content)\n\n                    if isinstance(content, str):\n                        content = content.encode(\"utf-8\")\n\n                    with open(file_path, \"wb\") as f:\n                        with io.BytesIO(content) as byte_stream:\n                            shutil.copyfileobj(byte_stream, f)\n                except Exception as e:\n                    print(f\"Error writing file {file_path}: {e}\")\n                    raise e\n\n        else:\n            # if agent files is a PosixPath, it is a path to the agent directory\n            # Copy all agent files including subfolders\n            shutil.copytree(agent_files, temp_dir, dirs_exist_ok=True)\n\n        return temp_dir\n\n    def set_agent_metadata(self, metadata) -&gt; None:\n        \"\"\"Set agent details from metadata.\"\"\"\n        try:\n            self.name = metadata[\"name\"]\n            self.version = metadata[\"version\"]\n        except KeyError as e:\n            raise ValueError(f\"Missing key in metadata: {e}\") from None\n\n        details = metadata.get(\"details\", {})\n        agent = details.get(\"agent\", {})\n        welcome = agent.get(\"welcome\", {})\n\n        self.env_vars = details.get(\"env_vars\", {})\n        self.welcome_title = welcome.get(\"title\")\n        self.welcome_description = welcome.get(\"description\")\n\n        if agent_metadata := details.get(\"agent\", None):\n            if defaults := agent_metadata.get(\"defaults\", None):\n                self.model = defaults.get(\"model\", self.model)\n                self.model_provider = defaults.get(\"model_provider\", self.model_provider)\n                self.model_temperature = defaults.get(\"model_temperature\", self.model_temperature)\n                self.model_max_tokens = defaults.get(\"model_max_tokens\", self.model_max_tokens)\n                self.max_iterations = defaults.get(\"max_iterations\", self.max_iterations)\n\n        if not self.version or not self.name:\n            raise ValueError(\"Both 'version' and 'name' must be non-empty in metadata.\")\n\n    def run_python_code(\n        self, agent_namespace, agent_runner_user, agent_py_modules_import\n    ) -&gt; Tuple[Optional[str], Optional[str]]:\n        \"\"\"Launch python agent.\"\"\"\n        try:\n            # switch to user env.agent_runner_user\n            if agent_runner_user:\n                user_info = pwd.getpwnam(agent_runner_user)\n                os.setgid(user_info.pw_gid)\n                os.setuid(user_info.pw_uid)\n\n            # Run the code\n            # NOTE: runpy.run_path does not work in a multithreaded environment when running benchmark.\n            #       The performance of runpy.run_path may also change depending on a system, e.g. it may\n            #       work on Linux but not work on Mac.\n            #       `compile` and `exec` have been tested to work properly in a multithreaded environment.\n            if self.code:\n                clear_module_cache(agent_py_modules_import, agent_namespace)\n                exec(self.code, agent_namespace)\n\n            # If no errors occur, return None\n            return None, None\n\n        except Exception as e:\n            # Return error message and full traceback as strings\n            return str(e), traceback.format_exc()\n\n    def run_ts_agent(self, agent_filename, env_vars, json_params):\n        \"\"\"Launch typescript agent.\"\"\"\n        print(f\"Running typescript agent {agent_filename} from {self.ts_runner_dir}\")\n\n        # Configure npm to use tmp directories\n        env = os.environ.copy()\n        env.update(\n            {\n                \"NPM_CONFIG_CACHE\": \"/tmp/npm_cache\",\n                \"NPM_CONFIG_PREFIX\": \"/tmp/npm_prefix\",\n                \"HOME\": \"/tmp\",  # Redirect npm home\n                \"NPM_CONFIG_LOGLEVEL\": \"error\",  # Suppress warnings, show only errors\n            }\n        )\n\n        # Ensure directory structure exists\n        os.makedirs(\"/tmp/npm_cache\", exist_ok=True)\n        os.makedirs(\"/tmp/npm_prefix\", exist_ok=True)\n\n        # read file /tmp/build-info.txt if exists\n        if os.path.exists(\"/var/task/build-info.txt\"):\n            with open(\"/var/task/build-info.txt\", \"r\") as file:\n                print(\"BUILD ID: \", file.read())\n\n        if env_vars.get(\"DEBUG\"):\n            print(\"Directory structure:\", os.listdir(\"/tmp/ts_runner\"))\n            print(\"Check package.json:\", os.path.exists(os.path.join(self.ts_runner_dir, \"package.json\")))\n            print(\"Symlink exists:\", os.path.exists(\"/tmp/ts_runner/node_modules/.bin/tsc\"))\n            print(\"Build files exist:\", os.path.exists(\"/tmp/ts_runner/build/sdk/main.js\"))\n\n        # Launching a subprocess to run an npm script with specific configurations\n        ts_process = subprocess.Popen(\n            [\n                \"npm\",  # Command to run Node Package Manager\n                \"--loglevel=error\",  # Suppress npm warnings and info logs, only show errors\n                \"--prefix\",\n                self.ts_runner_dir,  # Specifies the directory where npm should look for package.json\n                \"run\",\n                \"start\",  # Runs the \"start\" script defined in package.json, this launches the agent\n                \"agents/agent.ts\",\n                json_params,  # Arguments passed to the \"start\" script to configure the agent\n            ],\n            stdout=subprocess.PIPE,  # Captures standard output from the process\n            stderr=subprocess.PIPE,  # Captures standard error\n            cwd=self.ts_runner_dir,  # Sets the current working directory for the process\n            env=env_vars,  # Provides custom environment variables to the subprocess\n        )\n\n        stdout, stderr = ts_process.communicate()\n\n        stdout = stdout.decode().strip()\n        if stdout and env_vars.get(\"DEBUG\"):\n            print(f\"TS AGENT STDOUT: {stdout}\")\n\n        stderr = stderr.decode().strip()\n        if stderr:\n            print(f\"TS AGENT STDERR: {stderr}\")\n\n    def run(self, env: Any, task: Optional[str] = None) -&gt; Tuple[Optional[str], Optional[str]]:\n        \"\"\"Run the agent code. Returns error message and traceback message.\"\"\"\n        # combine agent.env_vars and env.env_vars\n        total_env_vars = {**self.env_vars, **env.env_vars}\n\n        # save os env vars\n        os.environ.update(total_env_vars)\n        # save env.env_vars\n        env.env_vars = total_env_vars\n\n        agent_ts_files_to_transpile = []\n        agent_py_modules_import = []\n\n        if not self.agent_filename or True:\n            # if agent has \"agent.py\" file, we use python runner\n            if os.path.exists(os.path.join(self.temp_dir, AGENT_FILENAME_PY)):\n                self.agent_filename = os.path.join(self.temp_dir, AGENT_FILENAME_PY)\n                self.agent_language = \"py\"\n                with open(self.agent_filename, \"r\") as agent_file:\n                    self.code = compile(agent_file.read(), self.agent_filename, \"exec\")\n            # else, if agent has \"agent.ts\" file, we use typescript runner\n            elif os.path.exists(os.path.join(self.temp_dir, AGENT_FILENAME_TS)):\n                self.agent_filename = os.path.join(self.temp_dir, AGENT_FILENAME_TS)\n                self.agent_language = \"ts\"\n\n                # copy files from nearai/ts_runner_sdk to self.temp_dir\n                ts_runner_sdk_dir = \"/tmp/ts_runner\"\n                ts_runner_agent_dir = os.path.join(ts_runner_sdk_dir, \"agents\")\n\n                ts_runner_actual_path = \"/var/task/ts_runner\"\n\n                shutil.copytree(ts_runner_actual_path, ts_runner_sdk_dir, symlinks=True, dirs_exist_ok=True)\n\n                # make ts agents dir if not exists\n                if not os.path.exists(ts_runner_agent_dir):\n                    os.makedirs(ts_runner_agent_dir, exist_ok=True)\n\n                # copy agents files\n                shutil.copy(os.path.join(self.temp_dir, AGENT_FILENAME_TS), ts_runner_agent_dir)\n\n                self.ts_runner_dir = ts_runner_sdk_dir\n            else:\n                raise ValueError(f\"Agent run error: {AGENT_FILENAME_PY} or {AGENT_FILENAME_TS} does not exist\")\n\n            # cache all agent files in file_cache\n            for root, dirs, files in os.walk(self.temp_dir):\n                is_main_dir = root == self.temp_dir\n\n                if is_main_dir:\n                    # add all folders in the root directory as potential modules to import\n                    agent_py_modules_import.extend(dirs)\n\n                for file in files:\n                    file_path = os.path.join(root, file)\n\n                    # get file extension for agent_filename\n                    if file_path.endswith(\".ts\"):\n                        agent_ts_files_to_transpile.append(file_path)\n\n                    if is_main_dir and file != AGENT_FILENAME_PY and file_path.endswith(\".py\"):\n                        # save py file without extension as potential module to import\n                        agent_py_modules_import.append(os.path.splitext(os.path.basename(file_path))[0])\n\n                    relative_path = os.path.relpath(file_path, self.temp_dir)\n                    try:\n                        with open(file_path, \"rb\") as f:\n                            content = f.read()\n                            try:\n                                # Try to decode as text\n                                self.file_cache[relative_path] = content.decode(\"utf-8\")\n                            except UnicodeDecodeError:\n                                # If decoding fails, store as binary\n                                self.file_cache[relative_path] = content\n\n                    except Exception as e:\n                        print(f\"Error with cache creation {file_path}: {e}\")\n\n        else:\n            print(\"Using cached agent code\")\n\n        namespace = {\n            \"env\": env,\n            \"agent\": self,\n            \"task\": task,\n            \"__name__\": \"__main__\",\n            \"__file__\": self.agent_filename,\n        }\n\n        user_auth = env.user_auth\n\n        # clear user_auth we saved before\n        env.user_auth = None\n\n        error_message, traceback_message = None, None\n\n        try:\n            if self.change_to_temp_dir:\n                if not os.path.exists(self.temp_dir):\n                    os.makedirs(self.temp_dir, exist_ok=True)\n                os.chdir(self.temp_dir)\n            sys.path.insert(0, self.temp_dir)\n\n            if self.agent_language == \"ts\":\n                agent_json_params = json.dumps(\n                    {\n                        \"thread_id\": env._thread_id,\n                        \"user_auth\": user_auth,\n                        \"base_url\": env.base_url,\n                        \"env_vars\": env.env_vars,\n                        \"agent_ts_files_to_transpile\": agent_ts_files_to_transpile,\n                    }\n                )\n\n                process = multiprocessing.Process(\n                    target=self.run_ts_agent, args=[self.agent_filename, env.env_vars, agent_json_params]\n                )\n                process.start()\n                process.join()\n            else:\n                if env.agent_runner_user:\n                    process = multiprocessing.Process(\n                        target=self.run_python_code, args=[namespace, env.agent_runner_user]\n                    )\n                    process.start()\n                    process.join()\n                else:\n                    error_message, traceback_message = self.run_python_code(\n                        namespace, env.agent_runner_user, agent_py_modules_import\n                    )\n\n                    if error_message:\n                        print(f\"[ERROR PYTHON]: {error_message}\")\n                    if traceback_message:\n                        print(f\"[ERROR PYTHON TRACEBACK]: {traceback_message}\")\n        finally:\n            if os.path.exists(self.temp_dir):\n                sys.path.remove(self.temp_dir)\n            if self.change_to_temp_dir:\n                os.chdir(self.original_cwd)\n\n        return error_message, traceback_message\n\n    @staticmethod\n    def load_agents(agents: str, config: ClientConfig, local: bool = False):\n        \"\"\"Loads agents from the registry.\"\"\"\n        return [Agent.load_agent(agent, config, local) for agent in agents.split(\",\")]\n\n    @staticmethod\n    def load_agent(\n        name: str,\n        config: ClientConfig,\n        local: bool = False,\n    ):\n        \"\"\"Loads a single agent from the registry.\"\"\"\n        from nearai.registry import get_registry_folder, registry\n\n        identifier = None\n        if local:\n            agent_files_path = get_registry_folder() / name\n            if config.auth is None:\n                namespace = \"not-logged-in\"\n            else:\n                namespace = config.auth.account_id\n        else:\n            agent_files_path = registry.download(name)\n            identifier = name\n        assert agent_files_path is not None, f\"Agent {name} not found.\"\n\n        metadata_path = os.path.join(agent_files_path, \"metadata.json\")\n        if not os.path.exists(metadata_path):\n            raise FileNotFoundError(f\"Metadata file not found: {metadata_path}\")\n        with open(metadata_path) as f:\n            metadata: Dict[str, Any] = json.load(f)\n\n        if not identifier:\n            identifier = \"/\".join([namespace, metadata[\"name\"], metadata[\"version\"]])\n\n        return Agent(identifier, agent_files_path, metadata)\n</code></pre>"},{"location":"api/#nearai.agents.agent.Agent.get_full_name","title":"get_full_name","text":"<pre><code>get_full_name()\n</code></pre> <p>Returns full agent name.</p> Source code in <code>nearai/agents/agent.py</code> <pre><code>def get_full_name(self):\n    \"\"\"Returns full agent name.\"\"\"\n    return f\"{self.namespace}/{self.name}/{self.version}\"\n</code></pre>"},{"location":"api/#nearai.agents.agent.Agent.load_agent","title":"load_agent  <code>staticmethod</code>","text":"<pre><code>load_agent(\n    name: str, config: ClientConfig, local: bool = False\n)\n</code></pre> <p>Loads a single agent from the registry.</p> Source code in <code>nearai/agents/agent.py</code> <pre><code>@staticmethod\ndef load_agent(\n    name: str,\n    config: ClientConfig,\n    local: bool = False,\n):\n    \"\"\"Loads a single agent from the registry.\"\"\"\n    from nearai.registry import get_registry_folder, registry\n\n    identifier = None\n    if local:\n        agent_files_path = get_registry_folder() / name\n        if config.auth is None:\n            namespace = \"not-logged-in\"\n        else:\n            namespace = config.auth.account_id\n    else:\n        agent_files_path = registry.download(name)\n        identifier = name\n    assert agent_files_path is not None, f\"Agent {name} not found.\"\n\n    metadata_path = os.path.join(agent_files_path, \"metadata.json\")\n    if not os.path.exists(metadata_path):\n        raise FileNotFoundError(f\"Metadata file not found: {metadata_path}\")\n    with open(metadata_path) as f:\n        metadata: Dict[str, Any] = json.load(f)\n\n    if not identifier:\n        identifier = \"/\".join([namespace, metadata[\"name\"], metadata[\"version\"]])\n\n    return Agent(identifier, agent_files_path, metadata)\n</code></pre>"},{"location":"api/#nearai.agents.agent.Agent.load_agents","title":"load_agents  <code>staticmethod</code>","text":"<pre><code>load_agents(\n    agents: str, config: ClientConfig, local: bool = False\n)\n</code></pre> <p>Loads agents from the registry.</p> Source code in <code>nearai/agents/agent.py</code> <pre><code>@staticmethod\ndef load_agents(agents: str, config: ClientConfig, local: bool = False):\n    \"\"\"Loads agents from the registry.\"\"\"\n    return [Agent.load_agent(agent, config, local) for agent in agents.split(\",\")]\n</code></pre>"},{"location":"api/#nearai.agents.agent.Agent.run","title":"run","text":"<pre><code>run(\n    env: Any, task: Optional[str] = None\n) -&gt; Tuple[Optional[str], Optional[str]]\n</code></pre> <p>Run the agent code. Returns error message and traceback message.</p> Source code in <code>nearai/agents/agent.py</code> <pre><code>def run(self, env: Any, task: Optional[str] = None) -&gt; Tuple[Optional[str], Optional[str]]:\n    \"\"\"Run the agent code. Returns error message and traceback message.\"\"\"\n    # combine agent.env_vars and env.env_vars\n    total_env_vars = {**self.env_vars, **env.env_vars}\n\n    # save os env vars\n    os.environ.update(total_env_vars)\n    # save env.env_vars\n    env.env_vars = total_env_vars\n\n    agent_ts_files_to_transpile = []\n    agent_py_modules_import = []\n\n    if not self.agent_filename or True:\n        # if agent has \"agent.py\" file, we use python runner\n        if os.path.exists(os.path.join(self.temp_dir, AGENT_FILENAME_PY)):\n            self.agent_filename = os.path.join(self.temp_dir, AGENT_FILENAME_PY)\n            self.agent_language = \"py\"\n            with open(self.agent_filename, \"r\") as agent_file:\n                self.code = compile(agent_file.read(), self.agent_filename, \"exec\")\n        # else, if agent has \"agent.ts\" file, we use typescript runner\n        elif os.path.exists(os.path.join(self.temp_dir, AGENT_FILENAME_TS)):\n            self.agent_filename = os.path.join(self.temp_dir, AGENT_FILENAME_TS)\n            self.agent_language = \"ts\"\n\n            # copy files from nearai/ts_runner_sdk to self.temp_dir\n            ts_runner_sdk_dir = \"/tmp/ts_runner\"\n            ts_runner_agent_dir = os.path.join(ts_runner_sdk_dir, \"agents\")\n\n            ts_runner_actual_path = \"/var/task/ts_runner\"\n\n            shutil.copytree(ts_runner_actual_path, ts_runner_sdk_dir, symlinks=True, dirs_exist_ok=True)\n\n            # make ts agents dir if not exists\n            if not os.path.exists(ts_runner_agent_dir):\n                os.makedirs(ts_runner_agent_dir, exist_ok=True)\n\n            # copy agents files\n            shutil.copy(os.path.join(self.temp_dir, AGENT_FILENAME_TS), ts_runner_agent_dir)\n\n            self.ts_runner_dir = ts_runner_sdk_dir\n        else:\n            raise ValueError(f\"Agent run error: {AGENT_FILENAME_PY} or {AGENT_FILENAME_TS} does not exist\")\n\n        # cache all agent files in file_cache\n        for root, dirs, files in os.walk(self.temp_dir):\n            is_main_dir = root == self.temp_dir\n\n            if is_main_dir:\n                # add all folders in the root directory as potential modules to import\n                agent_py_modules_import.extend(dirs)\n\n            for file in files:\n                file_path = os.path.join(root, file)\n\n                # get file extension for agent_filename\n                if file_path.endswith(\".ts\"):\n                    agent_ts_files_to_transpile.append(file_path)\n\n                if is_main_dir and file != AGENT_FILENAME_PY and file_path.endswith(\".py\"):\n                    # save py file without extension as potential module to import\n                    agent_py_modules_import.append(os.path.splitext(os.path.basename(file_path))[0])\n\n                relative_path = os.path.relpath(file_path, self.temp_dir)\n                try:\n                    with open(file_path, \"rb\") as f:\n                        content = f.read()\n                        try:\n                            # Try to decode as text\n                            self.file_cache[relative_path] = content.decode(\"utf-8\")\n                        except UnicodeDecodeError:\n                            # If decoding fails, store as binary\n                            self.file_cache[relative_path] = content\n\n                except Exception as e:\n                    print(f\"Error with cache creation {file_path}: {e}\")\n\n    else:\n        print(\"Using cached agent code\")\n\n    namespace = {\n        \"env\": env,\n        \"agent\": self,\n        \"task\": task,\n        \"__name__\": \"__main__\",\n        \"__file__\": self.agent_filename,\n    }\n\n    user_auth = env.user_auth\n\n    # clear user_auth we saved before\n    env.user_auth = None\n\n    error_message, traceback_message = None, None\n\n    try:\n        if self.change_to_temp_dir:\n            if not os.path.exists(self.temp_dir):\n                os.makedirs(self.temp_dir, exist_ok=True)\n            os.chdir(self.temp_dir)\n        sys.path.insert(0, self.temp_dir)\n\n        if self.agent_language == \"ts\":\n            agent_json_params = json.dumps(\n                {\n                    \"thread_id\": env._thread_id,\n                    \"user_auth\": user_auth,\n                    \"base_url\": env.base_url,\n                    \"env_vars\": env.env_vars,\n                    \"agent_ts_files_to_transpile\": agent_ts_files_to_transpile,\n                }\n            )\n\n            process = multiprocessing.Process(\n                target=self.run_ts_agent, args=[self.agent_filename, env.env_vars, agent_json_params]\n            )\n            process.start()\n            process.join()\n        else:\n            if env.agent_runner_user:\n                process = multiprocessing.Process(\n                    target=self.run_python_code, args=[namespace, env.agent_runner_user]\n                )\n                process.start()\n                process.join()\n            else:\n                error_message, traceback_message = self.run_python_code(\n                    namespace, env.agent_runner_user, agent_py_modules_import\n                )\n\n                if error_message:\n                    print(f\"[ERROR PYTHON]: {error_message}\")\n                if traceback_message:\n                    print(f\"[ERROR PYTHON TRACEBACK]: {traceback_message}\")\n    finally:\n        if os.path.exists(self.temp_dir):\n            sys.path.remove(self.temp_dir)\n        if self.change_to_temp_dir:\n            os.chdir(self.original_cwd)\n\n    return error_message, traceback_message\n</code></pre>"},{"location":"api/#nearai.agents.agent.Agent.run_python_code","title":"run_python_code","text":"<pre><code>run_python_code(\n    agent_namespace,\n    agent_runner_user,\n    agent_py_modules_import,\n) -&gt; Tuple[Optional[str], Optional[str]]\n</code></pre> <p>Launch python agent.</p> Source code in <code>nearai/agents/agent.py</code> <pre><code>def run_python_code(\n    self, agent_namespace, agent_runner_user, agent_py_modules_import\n) -&gt; Tuple[Optional[str], Optional[str]]:\n    \"\"\"Launch python agent.\"\"\"\n    try:\n        # switch to user env.agent_runner_user\n        if agent_runner_user:\n            user_info = pwd.getpwnam(agent_runner_user)\n            os.setgid(user_info.pw_gid)\n            os.setuid(user_info.pw_uid)\n\n        # Run the code\n        # NOTE: runpy.run_path does not work in a multithreaded environment when running benchmark.\n        #       The performance of runpy.run_path may also change depending on a system, e.g. it may\n        #       work on Linux but not work on Mac.\n        #       `compile` and `exec` have been tested to work properly in a multithreaded environment.\n        if self.code:\n            clear_module_cache(agent_py_modules_import, agent_namespace)\n            exec(self.code, agent_namespace)\n\n        # If no errors occur, return None\n        return None, None\n\n    except Exception as e:\n        # Return error message and full traceback as strings\n        return str(e), traceback.format_exc()\n</code></pre>"},{"location":"api/#nearai.agents.agent.Agent.run_ts_agent","title":"run_ts_agent","text":"<pre><code>run_ts_agent(agent_filename, env_vars, json_params)\n</code></pre> <p>Launch typescript agent.</p> Source code in <code>nearai/agents/agent.py</code> <pre><code>def run_ts_agent(self, agent_filename, env_vars, json_params):\n    \"\"\"Launch typescript agent.\"\"\"\n    print(f\"Running typescript agent {agent_filename} from {self.ts_runner_dir}\")\n\n    # Configure npm to use tmp directories\n    env = os.environ.copy()\n    env.update(\n        {\n            \"NPM_CONFIG_CACHE\": \"/tmp/npm_cache\",\n            \"NPM_CONFIG_PREFIX\": \"/tmp/npm_prefix\",\n            \"HOME\": \"/tmp\",  # Redirect npm home\n            \"NPM_CONFIG_LOGLEVEL\": \"error\",  # Suppress warnings, show only errors\n        }\n    )\n\n    # Ensure directory structure exists\n    os.makedirs(\"/tmp/npm_cache\", exist_ok=True)\n    os.makedirs(\"/tmp/npm_prefix\", exist_ok=True)\n\n    # read file /tmp/build-info.txt if exists\n    if os.path.exists(\"/var/task/build-info.txt\"):\n        with open(\"/var/task/build-info.txt\", \"r\") as file:\n            print(\"BUILD ID: \", file.read())\n\n    if env_vars.get(\"DEBUG\"):\n        print(\"Directory structure:\", os.listdir(\"/tmp/ts_runner\"))\n        print(\"Check package.json:\", os.path.exists(os.path.join(self.ts_runner_dir, \"package.json\")))\n        print(\"Symlink exists:\", os.path.exists(\"/tmp/ts_runner/node_modules/.bin/tsc\"))\n        print(\"Build files exist:\", os.path.exists(\"/tmp/ts_runner/build/sdk/main.js\"))\n\n    # Launching a subprocess to run an npm script with specific configurations\n    ts_process = subprocess.Popen(\n        [\n            \"npm\",  # Command to run Node Package Manager\n            \"--loglevel=error\",  # Suppress npm warnings and info logs, only show errors\n            \"--prefix\",\n            self.ts_runner_dir,  # Specifies the directory where npm should look for package.json\n            \"run\",\n            \"start\",  # Runs the \"start\" script defined in package.json, this launches the agent\n            \"agents/agent.ts\",\n            json_params,  # Arguments passed to the \"start\" script to configure the agent\n        ],\n        stdout=subprocess.PIPE,  # Captures standard output from the process\n        stderr=subprocess.PIPE,  # Captures standard error\n        cwd=self.ts_runner_dir,  # Sets the current working directory for the process\n        env=env_vars,  # Provides custom environment variables to the subprocess\n    )\n\n    stdout, stderr = ts_process.communicate()\n\n    stdout = stdout.decode().strip()\n    if stdout and env_vars.get(\"DEBUG\"):\n        print(f\"TS AGENT STDOUT: {stdout}\")\n\n    stderr = stderr.decode().strip()\n    if stderr:\n        print(f\"TS AGENT STDERR: {stderr}\")\n</code></pre>"},{"location":"api/#nearai.agents.agent.Agent.set_agent_metadata","title":"set_agent_metadata","text":"<pre><code>set_agent_metadata(metadata) -&gt; None\n</code></pre> <p>Set agent details from metadata.</p> Source code in <code>nearai/agents/agent.py</code> <pre><code>def set_agent_metadata(self, metadata) -&gt; None:\n    \"\"\"Set agent details from metadata.\"\"\"\n    try:\n        self.name = metadata[\"name\"]\n        self.version = metadata[\"version\"]\n    except KeyError as e:\n        raise ValueError(f\"Missing key in metadata: {e}\") from None\n\n    details = metadata.get(\"details\", {})\n    agent = details.get(\"agent\", {})\n    welcome = agent.get(\"welcome\", {})\n\n    self.env_vars = details.get(\"env_vars\", {})\n    self.welcome_title = welcome.get(\"title\")\n    self.welcome_description = welcome.get(\"description\")\n\n    if agent_metadata := details.get(\"agent\", None):\n        if defaults := agent_metadata.get(\"defaults\", None):\n            self.model = defaults.get(\"model\", self.model)\n            self.model_provider = defaults.get(\"model_provider\", self.model_provider)\n            self.model_temperature = defaults.get(\"model_temperature\", self.model_temperature)\n            self.model_max_tokens = defaults.get(\"model_max_tokens\", self.model_max_tokens)\n            self.max_iterations = defaults.get(\"max_iterations\", self.max_iterations)\n\n    if not self.version or not self.name:\n        raise ValueError(\"Both 'version' and 'name' must be non-empty in metadata.\")\n</code></pre>"},{"location":"api/#nearai.agents.agent.Agent.write_agent_files_to_temp","title":"write_agent_files_to_temp  <code>staticmethod</code>","text":"<pre><code>write_agent_files_to_temp(agent_files)\n</code></pre> <p>Write agent files to a temporary directory.</p> Source code in <code>nearai/agents/agent.py</code> <pre><code>@staticmethod\ndef write_agent_files_to_temp(agent_files):\n    \"\"\"Write agent files to a temporary directory.\"\"\"\n    unique_id = uuid.uuid4().hex\n    temp_dir = os.path.join(tempfile.gettempdir(), f\"agent_{unique_id}\")\n\n    if isinstance(agent_files, List):\n        os.makedirs(temp_dir, exist_ok=True)\n\n        for file_obj in agent_files:\n            file_path = os.path.join(temp_dir, file_obj[\"filename\"])\n\n            try:\n                if not os.path.exists(os.path.dirname(file_path)):\n                    os.makedirs(os.path.dirname(file_path))\n\n                content = file_obj[\"content\"]\n\n                if isinstance(content, dict) or isinstance(content, list):\n                    try:\n                        content = json.dumps(content)\n                    except Exception as e:\n                        print(f\"Error converting content to json: {e}\")\n                    content = str(content)\n\n                if isinstance(content, str):\n                    content = content.encode(\"utf-8\")\n\n                with open(file_path, \"wb\") as f:\n                    with io.BytesIO(content) as byte_stream:\n                        shutil.copyfileobj(byte_stream, f)\n            except Exception as e:\n                print(f\"Error writing file {file_path}: {e}\")\n                raise e\n\n    else:\n        # if agent files is a PosixPath, it is a path to the agent directory\n        # Copy all agent files including subfolders\n        shutil.copytree(agent_files, temp_dir, dirs_exist_ok=True)\n\n    return temp_dir\n</code></pre>"},{"location":"api/#nearai.agents.agent.clear_module_cache","title":"clear_module_cache","text":"<pre><code>clear_module_cache(module_names, namespace)\n</code></pre> <p>Clears specified modules from the cache before executing the main code.</p> <p>When executing agent code that imports utility modules from different locations, Python's module caching can sometimes use cached versions from the wrong location instead of importing from the agent's directory.</p> <p>This function removes modules from sys.modules to ensure they're freshly imported when used in subsequent code executions, preventing issues with cached imports.</p> <pre><code>module_names: List of module names to clear from cache\nnamespace: Dictionary namespace for code execution\n</code></pre> Source code in <code>nearai/agents/agent.py</code> <pre><code>def clear_module_cache(module_names, namespace):\n    \"\"\"Clears specified modules from the cache before executing the main code.\n\n    When executing agent code that imports utility modules from different locations,\n    Python's module caching can sometimes use cached versions from the wrong location\n    instead of importing from the agent's directory.\n\n    This function removes modules from sys.modules to ensure they're freshly\n    imported when used in subsequent code executions, preventing issues with\n    cached imports.\n\n    Args:\n    ----\n        module_names: List of module names to clear from cache\n        namespace: Dictionary namespace for code execution\n\n    \"\"\"\n    cleanup_code = \"import sys\\n\"\n    for module_name in module_names:\n        cleanup_code += f\"if '{module_name}' in sys.modules:\\n\"\n        cleanup_code += f\"    del sys.modules['{module_name}']\\n\"\n\n    exec(cleanup_code, namespace)\n</code></pre>"},{"location":"api/#nearai.agents.environment","title":"environment","text":""},{"location":"api/#nearai.agents.environment.Environment","title":"Environment","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/agents/environment.py</code> <pre><code>class Environment(object):\n    def __init__(  # noqa: D107\n        self,\n        path: str,\n        agents: List[Agent],\n        client: InferenceClient,\n        hub_client: OpenAI,\n        thread_id: str,\n        run_id: str,\n        create_files: bool = True,\n        env_vars: Optional[Dict[str, Any]] = None,\n        tool_resources: Optional[Dict[str, Any]] = None,\n        print_system_log: bool = False,\n        agent_runner_user: Optional[str] = None,\n        fastnear_api_key: Optional[str] = None,\n        approvals=None,\n    ) -&gt; None:\n        # Warning: never expose `client` or `_hub_client` to agent's environment\n\n        self.base_url = client._config.base_url\n\n        # user_auth is used to authenticate the user in the ts_runner. It will be removed after that in\n        # `nearai/agents/agent.py`\n        auth = client._auth\n        self.user_auth = auth\n\n        # Initialize secure openai clients\n        openai_client_params = {\n            \"api_key\": auth,\n            \"base_url\": client._config.base_url,\n            \"default_headers\": {\"Authorization\": f\"Bearer {auth}\"},\n        }\n        self.openai = SecureOpenAI(**openai_client_params)\n        self.async_openai = SecureAsyncOpenAI(**openai_client_params)\n\n        # Placeholder for solver\n        self.client: Optional[InferenceClient] = None\n\n        self._path = path\n        self._agents = agents\n        self._done = False\n        self._pending_ext_agent = False\n        self.env_vars: Dict[str, Any] = env_vars if env_vars else {}\n        self._last_used_model = \"\"\n        self.tool_resources: Dict[str, Any] = tool_resources if tool_resources else {}\n        self.print_system_log = print_system_log\n        self.agent_runner_user = agent_runner_user\n        self._approvals = approvals if approvals else default_approvals\n        self._thread_id = thread_id\n        self._run_id = run_id\n        self._debug_mode: bool = any(\n            str(value).lower() in (\"true\", \"1\", \"yes\", \"on\")\n            for key, value in self.env_vars.items()\n            if key.lower() == \"debug\"\n        )\n        # Expose the NEAR account_id of a user that signs this request to run an agent.\n        self.signer_account_id: str = client._config.auth.account_id if client._config.auth else \"\"\n\n        if fastnear_api_key:\n            default_mainnet_rpc = f\"https://{fastnear_api_key}@rpc.mainnet.fastnear.com\"\n        else:\n            default_mainnet_rpc = \"https://rpc.mainnet.near.org\"\n\n        class NearAccount(Account):\n            user_rpc_addr: Union[str, None]\n\n            async def view(\n                self,\n                contract_id: str,\n                method_name: str,\n                args: dict,\n                block_id: Optional[int] = None,\n                threshold: Optional[int] = None,\n                max_retries: int = 3,\n            ):\n                \"\"\"Wrapper for the view method of the Account class, adding multiple retry attempts.\n\n                Parameters\n                ----------\n                contract_id : str\n                    The ID of the contract to call.\n                method_name : str\n                    The name of the method to invoke on the contract.\n                args : dict\n                    The arguments to pass to the contract method.\n                block_id : Optional[int]\n                    The block ID to query at.\n                threshold : Optional[int]\n                    The threshold for the view function.\n                max_retries : int\n                    The maximum number of retry attempts.\n\n                Returns\n                -------\n                The result of the contract method call.\n\n                Raises\n                ------\n                Exception\n                    If all retry attempts fail, the exception is propagated.\n\n                \"\"\"\n                acc = Account(self.account_id, self.private_key, self.user_rpc_addr or default_mainnet_rpc)\n                await acc.startup()\n                max_retries = min(max_retries, 10)\n\n                for attempt in range(1, max_retries + 1):\n                    try:\n                        # Attempt to read the contract view method\n                        return await acc.view_function(contract_id, method_name, args, block_id, threshold)\n                    except Exception as e:\n                        # Log the error message for the current attempt\n                        print(\n                            f\"Attempt {attempt}/{max_retries} to view method '{method_name}' on contract \"\n                            f\"'{contract_id}' failed with error: {e}\"\n                        )\n\n                        # If it's the last attempt, re-raise the exception\n                        if attempt == max_retries:\n                            raise\n\n            async def call(\n                self,\n                contract_id: str,\n                method_name: str,\n                args: dict,\n                gas: int = DEFAULT_ATTACHED_GAS,\n                amount: int = 0,\n                nowait: bool = False,\n                included: bool = False,\n                max_retries: int = 1,\n            ):\n                \"\"\"Wrapper for the call method of the Account class, adding multiple retry attempts.\n\n                Parameters\n                ----------\n                contract_id : str\n                    The ID of the contract to call.\n                method_name : str\n                    The name of the method to invoke on the contract.\n                args : dict\n                    The arguments to pass to the contract method.\n                gas : int\n                    The amount of gas to attach to the call.\n                amount : int\n                    The amount of tokens to attach to the call.\n                nowait : bool\n                    If nowait is True, return transaction hash, else wait execution.\n                included : bool\n                    If included is True, return transaction hash, else wait execution\n                max_retries : int\n                    The maximum number of retry attempts.\n\n                Returns\n                -------\n                The result of the contract method call.\n\n                Raises\n                ------\n                Exception\n                    If all retry attempts fail, the exception is propagated.\n\n                \"\"\"\n                acc = Account(self.account_id, self.private_key, self.user_rpc_addr or default_mainnet_rpc)\n                await acc.startup()\n                max_retries = min(max_retries, 10)\n\n                for attempt in range(1, max_retries + 1):\n                    try:\n                        # Attempt to call the contract method\n                        return await acc.function_call(contract_id, method_name, args, gas, amount, nowait, included)\n                    except Exception as e:\n                        # Log the error message for the current attempt\n                        print(\n                            f\"Attempt {attempt}/{max_retries} to call method '{method_name}' on contract \"\n                            f\"'{contract_id}' failed with error: {e}\"\n                        )\n\n                        # If it's the last attempt, re-raise the exception\n                        if attempt == max_retries:\n                            raise\n\n            async def get_balance(self, account_id: Optional[str] = None) -&gt; int:\n                \"\"\"Retrieves the balance of the specified NEAR account.\n\n                Parameters\n                ----------\n                account_id : Optional[str]\n                    The ID of the account to retrieve the balance for. If not provided, the balance of the current\n                    account is retrieved.\n\n                Returns\n                -------\n                int\n                    The balance of the specified account in yoctoNEAR.\n\n                Raises\n                ------\n                Exception\n                    If there is an error retrieving the balance.\n\n                \"\"\"\n                acc = Account(self.account_id, self.private_key, self.user_rpc_addr or default_mainnet_rpc)\n                await acc.startup()\n                return await acc.get_balance(account_id)\n\n            def __init__(\n                self,\n                account_id: Optional[str] = None,\n                private_key: Optional[Union[List[Union[str, bytes]], str, bytes]] = None,\n                rpc_addr: Optional[str] = None,\n            ):\n                self.user_rpc_addr = rpc_addr\n                self.account_id = account_id\n                self.private_key = private_key\n                super().__init__(account_id, private_key, rpc_addr)\n\n        self.set_near = NearAccount\n\n        self._tools = ToolRegistry()\n\n        if create_files:\n            os.makedirs(self._path, exist_ok=True)\n            open(os.path.join(self._path, CHAT_FILENAME), \"a\").close()\n        os.chdir(self._path)\n\n        # Protected client methods\n        def query_vector_store(vector_store_id: str, query: str, full_files: bool = False):\n            \"\"\"Queries a vector store.\n\n            vector_store_id: The id of the vector store to query.\n            query: The query to search for.\n            \"\"\"\n            return client.query_vector_store(vector_store_id, query, full_files)\n\n        self.query_vector_store = query_vector_store\n\n        def upload_file(\n            file_content: str,\n            purpose: Literal[\"assistants\", \"batch\", \"fine-tune\", \"vision\"] = \"assistants\",\n            encoding: Optional[str] = \"utf-8\",\n            file_name: Optional[str] = \"file.txt\",\n            file_type: Optional[str] = \"text/plain\",\n        ):\n            \"\"\"Uploads a file to the registry.\"\"\"\n            return client.upload_file(\n                file_content, purpose, encoding=encoding, file_name=file_name, file_type=file_type\n            )\n\n        self.upload_file = upload_file\n\n        def remove_file(file_id: str):\n            \"\"\"Removes a file from the registry.\"\"\"\n            return client.remove_file(file_id)\n\n        self.remove_file = remove_file\n\n        def create_vector_store_from_source(\n            name: str,\n            source: Union[GitHubSource, GitLabSource],\n            source_auth: Optional[str] = None,\n            chunking_strategy: Optional[ChunkingStrategy] = None,\n            expires_after: Optional[ExpiresAfter] = None,\n            metadata: Optional[Dict[str, str]] = None,\n        ) -&gt; VectorStore:\n            \"\"\"Creates a vector store from the given source.\n\n            Args:\n            ----\n                name: The name of the vector store.\n                source: The source from which to create the vector store.\n                source_auth: The source authentication token.\n                chunking_strategy: The chunking strategy to use.\n                expires_after: The expiration policy.\n                metadata: Additional metadata.\n\n            Returns:\n            -------\n                VectorStore: The created vector store.\n\n            \"\"\"\n            return client.create_vector_store_from_source(\n                name=name,\n                source=source,\n                source_auth=source_auth,\n                chunking_strategy=chunking_strategy,\n                expires_after=expires_after,\n                metadata=metadata,\n            )\n\n        self.create_vector_store_from_source = create_vector_store_from_source\n\n        def add_file_to_vector_store(vector_store_id: str, file_id: str):\n            \"\"\"Adds a file to the vector store.\"\"\"\n            return client.add_file_to_vector_store(vector_store_id, file_id)\n\n        self.add_file_to_vector_store = add_file_to_vector_store\n\n        # positional arguments are not allowed because arguments list will be updated\n        def find_agents(\n            *,\n            owner_id: Optional[str] = None,\n            with_capabilities: Optional[bool] = False,\n            latest_versions_only: Optional[bool] = True,\n            limit: Optional[int] = None,\n            offset: Optional[int] = None,\n        ):\n            \"\"\"Find agents based on various parameters.\"\"\"\n            return client.find_agents(owner_id, with_capabilities, latest_versions_only, limit, offset)\n\n        self.find_agents = find_agents\n\n        def create_vector_store(\n            name: str,\n            file_ids: list,\n            expires_after: Union[ExpiresAfter, NotGiven] = NOT_GIVEN,\n            chunking_strategy: Union[\n                AutoFileChunkingStrategyParam, StaticFileChunkingStrategyObjectParam, NotGiven\n            ] = NOT_GIVEN,\n            metadata: Optional[Dict[str, str]] = None,\n        ) -&gt; VectorStore:\n            \"\"\"Creates a vector store.\n\n            Args:\n            ----\n                name: The name of the vector store.\n                file_ids: List of file ids to create the vector store.\n                chunking_strategy: The chunking strategy to use.\n                expires_after: The expiration policy.\n                metadata: Additional metadata.\n\n            Returns:\n            -------\n                VectorStore: The created vector store.\n\n            \"\"\"\n            return client.create_vector_store(\n                name=name,\n                file_ids=file_ids,\n                chunking_strategy=chunking_strategy,\n                expires_after=expires_after,\n                metadata=metadata,\n            )\n\n        self.create_vector_store = create_vector_store\n\n        def get_vector_store(vector_store_id: str) -&gt; VectorStore:\n            \"\"\"Gets a vector store by id.\"\"\"\n            return client.get_vector_store(vector_store_id)\n\n        self.get_vector_store = get_vector_store\n\n        def get_vector_store_files(vector_store_id: str) -&gt; Optional[List[VectorStoreFile]]:\n            \"\"\"Gets a list of vector store files.\"\"\"\n            return client.get_vector_store_files(vector_store_id)\n\n        self.get_vector_store_files = get_vector_store_files\n\n        # Save cache of requested models for inference to avoid extra server calls\n        self.cached_models_for_inference: Dict[str, str] = {}\n\n        def get_model_for_inference(model: str = \"\") -&gt; str:\n            \"\"\"Returns 'provider::model_full_path'.\"\"\"\n            if self.cached_models_for_inference.get(model, None) is None:\n                provider = self.get_primary_agent().model_provider if self._agents else \"\"\n                if model == \"\":\n                    model = self.get_primary_agent().model if self._agents else \"\"\n                if model == \"\":\n                    return DEFAULT_PROVIDER_MODEL\n\n                _, model_for_inference = client.provider_models.match_provider_model(model, provider)\n\n                self.cached_models_for_inference[model] = model_for_inference\n\n            return self.cached_models_for_inference[model]\n\n        self.get_model_for_inference = get_model_for_inference\n\n        def _run_inference_completions(\n            messages: Union[Iterable[ChatCompletionMessageParam], str],\n            model: Union[Iterable[ChatCompletionMessageParam], str],\n            stream: bool,\n            **kwargs: Any,\n        ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n            \"\"\"Run inference completions for given parameters.\"\"\"\n            params, kwargs = self.get_inference_parameters(messages, model, stream, **kwargs)\n\n            completions = client.completions(\n                params.model, params.messages, params.stream, params.temperature, params.max_tokens, **kwargs\n            )\n\n            return completions\n\n        self._run_inference_completions = _run_inference_completions\n\n        def get_agent_public_key():\n            \"\"\"Returns public key of the agent.\"\"\"\n            agent_name = self.get_primary_agent().get_full_name()\n\n            return client.get_agent_public_key(agent_name)\n\n        self.get_agent_public_key = get_agent_public_key\n\n        def run_agent(\n            agent_id: str,\n            query: Optional[str] = None,\n            thread_mode: ThreadMode = ThreadMode.FORK,\n            run_mode: RunMode = RunMode.SIMPLE,\n        ):\n            \"\"\"Runs a child agent on the thread.\"\"\"\n            child_thread_id = self._thread_id\n\n            if thread_mode == ThreadMode.SAME:\n                pass\n            elif thread_mode == ThreadMode.FORK:\n                child_thread_id = client.threads_fork(self._thread_id).id\n                self.add_system_log(f\"Forked thread {child_thread_id}\", logging.INFO)\n            elif thread_mode == ThreadMode.CHILD:\n                child_thread_id = client.create_subthread(self._thread_id).id\n                self.add_system_log(f\"Created subthread {child_thread_id}\", logging.INFO)\n\n            if query:\n                client.threads_messages_create(thread_id=child_thread_id, content=query, role=\"user\")\n\n            self.add_system_log(f\"Running agent {agent_id}\", logging.INFO)\n            client.run_agent(\n                parent_run_id=self._run_id,\n                run_on_thread_id=child_thread_id,\n                assistant_id=agent_id,\n                run_mode=run_mode,\n            )\n            self._pending_ext_agent = True\n\n            return child_thread_id\n\n        self.run_agent = run_agent\n\n        def schedule_run(\n            agent: str,\n            input_message: str,\n            run_at: datetime,\n            run_params: Optional[Dict[str, str]] = None,\n            thread_id: Optional[str] = None,\n        ):\n            \"\"\"Schedules a run.\"\"\"\n            return client.schedule_run(agent, input_message, thread_id, run_params, run_at)\n\n        self.schedule_run = schedule_run\n\n        # TODO(https://github.com/nearai/nearai/issues/549): Allow only a subset of agents to access/update user memory.\n        def add_user_memory(memory: str):\n            \"\"\"Add user memory.\"\"\"\n            return client.add_user_memory(memory)\n\n        self.add_user_memory = add_user_memory\n\n        def query_user_memory(query: str):\n            \"\"\"Query user memory.\"\"\"\n            return client.query_user_memory(query)\n\n        self.query_user_memory = query_user_memory\n\n        def generate_image(prompt: str):\n            \"\"\"Generate an image.\"\"\"\n            return client.generate_image(prompt)\n\n        self.generate_image = generate_image\n\n        def save_agent_data(key, data: Dict[str, Any]):\n            \"\"\"Save agent data.\"\"\"\n            try:\n                return client.save_agent_data(key, data)\n            except Exception as ex:\n                self.add_system_log(f\"Error saving agent data by key {key}: {ex}\", logging.ERROR)\n                return None\n\n        self.save_agent_data = save_agent_data\n\n        def get_agent_data():\n            \"\"\"Get agent data.\"\"\"\n            return client.get_agent_data()\n\n        self.get_agent_data = get_agent_data\n\n        def get_agent_data_by_key(key, default=None):\n            \"\"\"Get agent data by key.\"\"\"\n            namespace = self.get_primary_agent().namespace\n            name = self.get_primary_agent().name\n            try:\n                result = client.get_agent_data_by_key(key)\n            except Exception as ex:\n                self.add_system_log(f\"Error getting agent data by key {key}: {ex}\", logging.ERROR)\n                result = None\n            return (\n                result\n                if result\n                else {\n                    \"value\": default,\n                    \"namespace\": namespace,\n                    \"key\": key,\n                    \"name\": name,\n                    \"updated_at\": \"\",\n                    \"created_at\": \"\",\n                }\n            )\n\n        self.get_agent_data_by_key = get_agent_data_by_key\n\n        # HubClient methods\n        def add_reply(\n            message: str,\n            attachments: Optional[Iterable[Attachment]] = None,\n            message_type: Optional[str] = None,\n            thread_id: str = self._thread_id,\n        ):\n            \"\"\"Assistant adds a message to the environment.\"\"\"\n            # NOTE: message from `user` are not stored in the memory\n\n            return hub_client.beta.threads.messages.create(\n                thread_id=thread_id,\n                role=\"assistant\",\n                content=message,\n                extra_body={\n                    \"assistant_id\": self.get_primary_agent().identifier,\n                    \"run_id\": self._run_id,\n                },\n                attachments=attachments,\n                metadata={\"message_type\": message_type} if message_type else None,\n            )\n\n        self.add_reply = add_reply\n\n        def get_thread(thread_id=self._thread_id):\n            \"\"\"Returns the current Thread object or the requested Thread.\"\"\"\n            return client.get_thread(thread_id)\n\n        self.get_thread = get_thread\n\n        def _add_message(\n            role: str,\n            message: str,\n            attachments: Optional[Iterable[Attachment]] = None,\n            **kwargs: Any,\n        ):\n            return hub_client.beta.threads.messages.create(\n                thread_id=self._thread_id,\n                role=role,  # type: ignore\n                content=message,\n                extra_body={\n                    \"assistant_id\": self.get_primary_agent().identifier,\n                    \"run_id\": self._run_id,\n                },\n                metadata=kwargs,\n                attachments=attachments,\n            )\n\n        self._add_message = _add_message\n\n        def _list_messages(\n            limit: Union[int, NotGiven] = NOT_GIVEN,\n            order: Literal[\"asc\", \"desc\"] = \"asc\",\n            thread_id: Optional[str] = None,\n        ) -&gt; List[Message]:\n            \"\"\"Returns messages from the environment.\"\"\"\n            messages = hub_client.beta.threads.messages.list(\n                thread_id=thread_id or self._thread_id, limit=limit, order=order\n            )\n            self.add_system_log(f\"Retrieved {len(messages.data)} messages from NEAR AI Hub\")\n            return messages.data\n\n        self._list_messages = _list_messages\n\n        def list_files_from_thread(\n            order: Literal[\"asc\", \"desc\"] = \"asc\", thread_id: Optional[str] = None\n        ) -&gt; List[FileObject]:\n            \"\"\"Lists files in the thread.\"\"\"\n            messages = self._list_messages(order=order)\n            # Extract attachments from messages\n            attachments = [a for m in messages if m.attachments for a in m.attachments]\n            # Extract files from attachments\n            file_ids = [a.file_id for a in attachments]\n            files = [hub_client.files.retrieve(f) for f in file_ids if f]\n            return files\n\n        self.list_files_from_thread = list_files_from_thread\n\n        def read_file_by_id(file_id: str):\n            \"\"\"Read a file from the thread.\"\"\"\n            content = hub_client.files.content(file_id).content.decode(\"utf-8\")\n            print(\"file content returned by api\", content)\n            return content\n\n        self.read_file_by_id = read_file_by_id\n\n        def write_file(\n            filename: str,\n            content: Union[str, bytes],\n            encoding: str = \"utf-8\",\n            filetype: str = \"text/plain\",\n            write_to_disk: bool = True,\n        ) -&gt; FileObject:\n            \"\"\"Writes a file to the environment.\n\n            filename: The name of the file to write to\n            content: The content to write to the file\n            encoding: The encoding to use when writing the file (default is utf-8)\n            filetype: The MIME type of the file (default is text/plain)\n            write_to_disk: If True, write locally to disk (default is True)\n            \"\"\"\n            if write_to_disk:\n                # Write locally\n                path = Path(self.get_primary_agent_temp_dir()) / filename\n                path.parent.mkdir(parents=True, exist_ok=True)\n                if isinstance(content, bytes):\n                    with open(path, \"wb\") as f:\n                        f.write(content)\n                else:\n                    with open(path, \"w\", encoding=encoding) as f:\n                        f.write(content)\n\n            if isinstance(content, bytes):\n                file_data = content\n            else:\n                file_data = io.BytesIO(content.encode(encoding))  # type:ignore\n\n            # Upload to Hub\n            file = hub_client.files.create(file=(filename, file_data, filetype), purpose=\"assistants\")\n            res = self.add_reply(\n                message=f\"Successfully wrote {len(content) if content else 0} characters to {filename}\",\n                attachments=[{\"file_id\": file.id, \"tools\": [{\"type\": \"file_search\"}]}],\n                message_type=\"system:file_write\",\n            )\n            self.add_system_log(\n                f\"Uploaded file {filename} with {len(content)} characters, id: {file.id}. Added in thread as: {res.id}\"\n            )\n            return file\n\n        self.write_file = write_file\n\n        def mark_done() -&gt; Run:  # noqa: D102\n            self._done = True\n            res = hub_client.beta.threads.runs.update(\n                thread_id=self._thread_id,\n                run_id=self._run_id,\n                extra_body={\n                    \"status\": \"completed\",\n                    \"completed_at\": datetime.now().isoformat(),\n                },\n            )\n            return res\n\n        self.mark_done = mark_done\n\n        def mark_failed() -&gt; Run:\n            \"\"\"Marks the environment run as failed.\"\"\"\n            self._done = True\n            self.add_system_log(\"Environment run failed\", logging.ERROR)\n            res = hub_client.beta.threads.runs.update(\n                thread_id=self._thread_id,\n                run_id=self._run_id,\n                extra_body={\"status\": \"failed\", \"failed_at\": datetime.now().isoformat()},\n            )\n            return res\n\n        self.mark_failed = mark_failed\n\n        def request_user_input() -&gt; Run:\n            \"\"\"Must be called to request input from the user.\"\"\"\n            return hub_client.beta.threads.runs.update(\n                thread_id=self._thread_id,\n                run_id=self._run_id,\n                extra_body={\"status\": \"requires_action\", \"required_action\": {\"type\": \"user_input\"}},\n            )\n\n        self.request_user_input = request_user_input\n\n        def request_agent_input() -&gt; Run:\n            \"\"\"Mark the run as ready for input from another agent.\"\"\"\n            return hub_client.beta.threads.runs.update(\n                thread_id=self._thread_id,\n                run_id=self._run_id,\n                extra_body={\"status\": \"requires_action\", \"required_action\": {\"type\": \"agent_input\"}},\n            )\n\n        self.request_agent_input = request_agent_input\n\n        # Must be placed after method definitions\n        self.register_standard_tools()\n\n    # end of protected client methods\n\n    def get_tool_registry(self, new: bool = False) -&gt; ToolRegistry:\n        \"\"\"Returns the tool registry, a dictionary of tools that can be called by the agent.\"\"\"\n        if new:\n            self._tools = ToolRegistry()\n        return self._tools\n\n    def register_standard_tools(self) -&gt; None:  # noqa: D102\n        reg = self.get_tool_registry()\n        reg.register_tool(self.exec_command)\n        reg.register_tool(self.read_file)\n        reg.register_tool(self.write_file)\n        reg.register_tool(self.request_user_input)\n        reg.register_tool(self.list_files)\n        reg.register_tool(self.query_vector_store)\n\n    def get_last_message(self, role: str = \"user\"):\n        \"\"\"Reads last message from the given role and returns it.\"\"\"\n        for message in reversed(self.list_messages()):\n            if message.get(\"role\") == role:\n                return message\n\n        return None\n\n    def add_message(\n        self,\n        role: str,\n        message: str,\n        attachments: Optional[Iterable[Attachment]] = None,\n        **kwargs: Any,\n    ):\n        \"\"\"Deprecated. Please use `add_reply` instead. Assistant adds a message to the environment.\"\"\"\n        # Prevent agent to save messages on behalf of `user` to avoid adding false memory\n        role = \"assistant\"\n\n        return self._add_message(role, message, attachments, **kwargs)\n\n    def add_system_log(self, log: str, level: int = logging.INFO) -&gt; None:\n        \"\"\"Add system log with timestamp and log level.\"\"\"\n        logger = logging.getLogger(\"system_logger\")\n        if not logger.handlers:\n            # Configure the logger if it hasn't been set up yet\n            logger.setLevel(logging.DEBUG)\n            file_handler = logging.FileHandler(os.path.join(self._path, SYSTEM_LOG_FILENAME))\n            formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n            file_handler.setFormatter(formatter)\n            logger.addHandler(file_handler)\n\n            if self.print_system_log:\n                console_handler = logging.StreamHandler()\n                console_handler.setFormatter(formatter)\n                logger.addHandler(console_handler)\n\n            # Add Thread log handler\n            if self._debug_mode:\n                custom_handler = CustomLogHandler(self.add_reply, \"system\")\n                custom_handler.setFormatter(formatter)\n                logger.addHandler(custom_handler)\n\n        # Log the message\n        logger.log(level, log)\n        # Force the handler to write to disk\n        for handler in logger.handlers:\n            handler.flush()\n\n    def add_agent_log(self, log: str, level: int = logging.INFO) -&gt; None:\n        \"\"\"Add agent log with timestamp and log level.\"\"\"\n        logger = logging.getLogger(\"agent_logger\")\n        if not logger.handlers:\n            # Configure the logger if it hasn't been set up yet\n            logger.setLevel(logging.DEBUG)\n            file_handler = logging.FileHandler(os.path.join(self._path, AGENT_LOG_FILENAME))\n            formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n            file_handler.setFormatter(formatter)\n            logger.addHandler(file_handler)\n\n            # Add Thread log handler\n            if self._debug_mode:\n                custom_handler = CustomLogHandler(self.add_reply, \"agent\")\n                custom_handler.setFormatter(formatter)\n                logger.addHandler(custom_handler)\n\n        # Log the message\n        logger.log(level, log)\n        # Force the handler to write to disk\n        for handler in logger.handlers:\n            handler.flush()\n\n    def add_agent_start_system_log(self, agent_idx: int) -&gt; None:\n        \"\"\"Adds agent start system log.\"\"\"\n        agent = self._agents[agent_idx]\n        message = f\"Running agent {agent.name}\"\n        if agent.model != \"\":\n            model = self.get_model_for_inference(agent.model)\n            self._last_used_model = model\n            message += f\" that will connect to {model}\"\n            if agent.model_temperature:\n                message += f\", temperature={agent.model_temperature}\"\n            if agent.model_max_tokens:\n                message += f\", max_tokens={agent.model_max_tokens}\"\n        self.add_system_log(message)\n\n    def list_terminal_commands(self, filename: str = TERMINAL_FILENAME) -&gt; List[Any]:\n        \"\"\"Returns the terminal commands from the terminal file.\"\"\"\n        path = os.path.join(self._path, filename)\n\n        if not os.path.exists(path):\n            return []\n\n        with open(path, \"r\") as f:\n            return [json.loads(message) for message in f.read().split(DELIMITER) if message]\n\n    def list_messages(\n        self,\n        thread_id: Optional[str] = None,\n        limit: Union[int, NotGiven] = 200,  # api defaults to 20\n        order: Literal[\"asc\", \"desc\"] = \"asc\",\n    ):\n        \"\"\"Backwards compatibility for chat_completions messages.\"\"\"\n        messages = self._list_messages(thread_id=thread_id, limit=limit, order=order)\n\n        # Filter out system and agent log messages when running in debug mode. Agent behavior shouldn't change based on logs.  # noqa: E501\n        messages = [\n            m\n            for m in messages\n            if not (\n                m.metadata\n                and any(m.metadata.get(\"message_type\", \"\").startswith(prefix) for prefix in [\"system:\", \"agent:\"])\n            )\n        ]\n\n        legacy_messages = [\n            {\n                \"id\": m.id,\n                \"content\": \"\\n\".join([c.text.value for c in m.content]),  # type: ignore\n                \"role\": m.role,\n                \"attachments\": m.attachments,\n            }\n            for m in messages\n        ]\n        return legacy_messages\n\n    def verify_message(\n        self,\n        account_id: str,\n        public_key: str,\n        signature: str,\n        message: str,\n        nonce: str,\n        callback_url: str,\n    ) -&gt; near.SignatureVerificationResult:\n        \"\"\"Verifies that the user message is signed with NEAR Account.\"\"\"\n        return near.verify_signed_message(\n            account_id,\n            public_key,\n            signature,\n            message,\n            nonce,\n            self.get_primary_agent().name,\n            callback_url,\n        )\n\n    def list_files(self, path: str, order: Literal[\"asc\", \"desc\"] = \"asc\") -&gt; List[str]:\n        \"\"\"Lists files in the environment.\"\"\"\n        return os.listdir(os.path.join(self.get_primary_agent_temp_dir(), path))\n\n    def get_system_path(self) -&gt; Path:\n        \"\"\"Returns the system path where chat.txt &amp; system_log are stored.\"\"\"\n        return Path(self._path)\n\n    def get_agent_temp_path(self) -&gt; Path:\n        \"\"\"Returns temp dir for primary agent where execution happens.\"\"\"\n        return self.get_primary_agent_temp_dir()\n\n    def read_file(self, filename: str) -&gt; Optional[Union[bytes, str]]:\n        \"\"\"Reads a file from the environment or thread.\"\"\"\n        file_content: Optional[Union[bytes, str]] = None\n        # First try to read from local filesystem\n        local_path = os.path.join(self.get_primary_agent_temp_dir(), filename)\n        print(f\"Read file {filename} from local path: {local_path}\")\n        if os.path.exists(local_path):\n            try:\n                with open(local_path, \"rb\") as local_path_file:\n                    local_file_content = local_path_file.read()\n                    try:\n                        # Try to decode as text\n                        file_content = local_file_content.decode(\"utf-8\")\n                    except UnicodeDecodeError:\n                        # If decoding fails, store as binary\n                        file_content = local_file_content\n            except Exception as e:\n                print(f\"Error with read_file: {e}\")\n\n        if not file_content:\n            # Next check files written out by the agent.\n            # Agent output files take precedence over files packaged with the agent\n            thread_files = self.list_files_from_thread(order=\"desc\")\n\n            # Then try to read from thread, starting from the most recent\n            for f in thread_files:\n                if f.filename == filename:\n                    file_content = self.read_file_by_id(f.id)\n                    break\n\n            if not file_content:\n                # Next check agent file cache\n                # Agent output files &amp; thread files take precedence over cached files\n                file_cache = self.get_primary_agent().file_cache\n                if file_cache:\n                    file_content = file_cache.get(filename, None)\n\n            # Write the file content from the thread or cache to the local filesystem\n            # This allows exec_command to operate on the file\n            if file_content:\n                if not os.path.exists(os.path.dirname(local_path)):\n                    os.makedirs(os.path.dirname(local_path))\n\n                with open(local_path, \"wb\") as local_file:\n                    if isinstance(file_content, bytes):\n                        local_file.write(file_content)\n                    else:\n                        local_file.write(file_content.encode(\"utf-8\"))\n\n        if not file_content:\n            self.add_system_log(f\"Warn: File {filename} not found during read_file operation\")\n\n        return file_content\n\n    def exec_command(self, command: str) -&gt; Dict[str, Union[str, int]]:\n        \"\"\"Executes a command in the environment and logs the output.\n\n        The environment does not allow running interactive programs.\n        It will run a program for 1 second then will interrupt it if it is still running\n        or if it is waiting for user input.\n        command: The command to execute, like 'ls -l' or 'python3 tests.py'\n        \"\"\"\n        approval_function = self._approvals[\"confirm_execution\"] if self._approvals else None\n        if not approval_function:\n            return {\n                \"stderr\": \"Agent runner misconfiguration. No command execution approval function found.\",\n            }\n        if not approval_function(command):\n            return {\n                \"command\": command,\n                \"returncode\": 999,\n                \"stdout\": \"\",\n                \"stderr\": \"Command execution was not approved.\",\n            }\n\n        try:\n            process = subprocess.Popen(\n                shlex.split(command),\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                bufsize=0,\n                universal_newlines=True,\n                cwd=self._path,\n            )\n        except Exception as e:\n            return {\n                \"command\": command,\n                \"returncode\": 999,\n                \"stdout\": \"\",\n                \"stderr\": \"Failed to execute: \" + str(e),\n            }\n\n        msg = \"\"\n\n        def kill_process_tree(p: Any) -&gt; None:\n            nonlocal msg\n            msg = \"Killing process due to timeout\"\n\n            process = psutil.Process(p.pid)\n            for proc in process.children(recursive=True):\n                proc.kill()\n            process.kill()\n\n        timer = threading.Timer(2, kill_process_tree, (process,))\n        timer.start()\n        process.wait()\n        timer.cancel()\n\n        result = {\n            \"command\": command,\n            \"stdout\": process.stdout.read() if process.stdout and hasattr(process.stdout, \"read\") else \"\",\n            \"stderr\": process.stderr.read() if process.stderr and hasattr(process.stderr, \"read\") else \"\",\n            \"returncode\": process.returncode,\n            \"msg\": msg,\n        }\n        with open(os.path.join(self._path, TERMINAL_FILENAME), \"a\") as f:\n            f.write(json.dumps(result) + DELIMITER)\n        return result\n\n    def get_inference_parameters(\n        self,\n        messages: Union[Iterable[ChatCompletionMessageParam], str],\n        model: Union[Iterable[ChatCompletionMessageParam], str],\n        stream: bool,\n        **kwargs: Any,\n    ) -&gt; Tuple[InferenceParameters, Any]:\n        \"\"\"Run inference parameters to run completions.\"\"\"\n        if isinstance(messages, str):\n            self.add_system_log(\n                \"Deprecated completions call. Pass `messages` as a first parameter.\",\n                logging.WARNING,\n            )\n            messages_or_model = messages\n            model_or_messages = model\n            model = cast(str, messages_or_model)\n            messages = cast(Iterable[ChatCompletionMessageParam], model_or_messages)\n        else:\n            model = cast(str, model)\n            messages = cast(Iterable[ChatCompletionMessageParam], messages)\n        model = self.get_model_for_inference(model)\n        if model != self._last_used_model:\n            self._last_used_model = model\n            self.add_system_log(f\"Connecting to {model}\")\n\n        temperature = kwargs.pop(\"temperature\", self.get_primary_agent().model_temperature if self._agents else None)\n        max_tokens = kwargs.pop(\"max_tokens\", self.get_primary_agent().model_max_tokens if self._agents else None)\n\n        params = InferenceParameters(\n            model=model,\n            messages=messages,\n            stream=stream,\n            temperature=temperature,\n            max_tokens=max_tokens,\n        )\n\n        return params, kwargs\n\n    # TODO(286): `messages` may be model and `model` may be messages temporarily to support deprecated API.\n    def completions(\n        self,\n        messages: Union[Iterable[ChatCompletionMessageParam], str],\n        model: Union[Iterable[ChatCompletionMessageParam], str] = \"\",\n        stream: bool = False,\n        **kwargs: Any,\n    ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n        \"\"\"Returns all completions for given messages using the given model.\"\"\"\n        return self._run_inference_completions(messages, model, stream, **kwargs)\n\n    def verify_signed_message(\n        self,\n        completion: str,\n        messages: Union[Iterable[ChatCompletionMessageParam], str],\n        public_key: Union[str, None] = None,\n        signature: Union[str, None] = None,\n        model: Union[Iterable[ChatCompletionMessageParam], str] = \"\",\n        **kwargs: Any,\n    ) -&gt; bool:\n        \"\"\"Verifies a signed message.\"\"\"\n        if public_key is None or signature is None:\n            return False\n\n        params, _ = self.get_inference_parameters(messages, model, False, **kwargs)\n\n        messages_without_ids = [{k: v for k, v in item.items() if k != \"id\"} for item in params.messages]\n        ordered_messages_without_ids = [\n            {\"role\": str(item[\"role\"]), \"content\": str(item[\"content\"])} for item in messages_without_ids\n        ]\n\n        return validate_completion_signature(\n            public_key,\n            signature,\n            CompletionSignaturePayload(\n                agent_name=self.get_primary_agent().get_full_name(),\n                completion=completion,\n                model=params.model,\n                messages=ordered_messages_without_ids,\n                temperature=params.temperature,\n                max_tokens=params.max_tokens,\n            ),\n        )\n\n    def completions_and_run_tools(\n        self,\n        messages: List[ChatCompletionMessageParam],\n        model: str = \"\",\n        tools: Optional[List] = None,\n        add_responses_to_messages: bool = True,\n        agent_role_name=\"assistant\",\n        tool_role_name=\"tool\",\n        **kwargs: Any,\n    ) -&gt; ModelResponse:\n        \"\"\"Returns all completions for given messages using the given model and runs tools.\"\"\"\n        if self._use_llama_tool_syntax(model, tools):\n            tool_prompt = self._llama_tool_prompt(tools)\n            messages.append({\"role\": \"system\", \"content\": tool_prompt})\n        raw_response = self._run_inference_completions(messages, model, stream=False, tools=tools, **kwargs)\n        assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n        response: ModelResponse = raw_response\n        assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n        choices: List[Choices] = response.choices  # type: ignore\n        response_message = choices[0].message\n\n        self._handle_tool_calls(response_message, add_responses_to_messages, agent_role_name, tool_role_name)\n\n        return response\n\n    def _handle_tool_calls(\n        self,\n        response_message,\n        add_responses_to_messages,\n        agent_role_name,\n        tool_role_name,\n    ):\n        (message_without_tool_call, tool_calls) = self._parse_tool_call(response_message)\n        if add_responses_to_messages and response_message.content:\n            self.add_message(agent_role_name, message_without_tool_call)\n        if tool_calls:\n            for tool_call in tool_calls:\n                function_name = tool_call.function.name\n                try:\n                    assert function_name, \"Tool call must have a function name\"\n                    function_signature = self.get_tool_registry().get_tool_definition(function_name)\n                    assert function_signature, f\"Tool {function_name} not found\"\n                    args = tool_call.function.arguments\n                    function_args = tool_json_helper.parse_json_args(function_signature, args)\n                    self.add_system_log(f\"Calling tool {function_name} with args {function_args}\")\n                    function_response = self._tools.call_tool(function_name, **function_args if function_args else {})\n\n                    if function_response:\n                        try:\n                            function_response_json = json.dumps(function_response) if function_response else \"\"\n                            if add_responses_to_messages:\n                                self.add_message(\n                                    tool_role_name,\n                                    function_response_json,\n                                    tool_call_id=tool_call.id,\n                                    name=function_name,\n                                )\n                        except Exception as e:\n                            # some tool responses may not be serializable\n                            error_message = f\"Unable to add tool output as a message {function_name}: {e}\"\n                            self.add_system_log(error_message, level=logging.INFO)\n                except Exception as e:\n                    error_message = f\"Error calling tool {function_name}: {e}\"\n                    self.add_system_log(error_message, level=logging.ERROR)\n                    if add_responses_to_messages:\n                        self.add_message(\n                            tool_role_name,\n                            error_message,\n                            tool_call_id=tool_call.id,\n                            name=function_name,\n                        )\n\n    @staticmethod\n    def _parse_tool_call(\n        response_message,\n    ) -&gt; Tuple[Optional[str], Optional[List[ChatCompletionMessageToolCall]]]:\n        if hasattr(response_message, \"tool_calls\") and response_message.tool_calls:\n            return response_message.content, response_message.tool_calls\n        content = response_message.content\n        if content is None:\n            return None, None\n        content = response_message.content\n        llama_matches = LLAMA_TOOL_FORMAT_PATTERN.findall(content)\n        if llama_matches:\n            text = \"\"\n            tool_calls = []\n            for llama_match in llama_matches:\n                before_call_text, function_name, args, end_tag, after_call_text = llama_match\n                function = Function(name=function_name, arguments=args)\n                tool_call = ChatCompletionMessageToolCall(id=str(uuid.uuid4()), function=function)\n                text += before_call_text + after_call_text\n                tool_calls.append(tool_call)\n            return text, tool_calls\n\n        llama_matches = LLAMA_TOOL_FORMAT_PATTERN2.findall(content)\n        if llama_matches:\n            text = \"\"\n            tool_calls = []\n            for llama_match in llama_matches:\n                before_call_text, function_name_and_args, after_call_text = llama_match\n                try:\n                    parsed_function_name_and_args = json.loads(function_name_and_args)\n                    function_name = parsed_function_name_and_args.get(\"name\")\n                    args = parsed_function_name_and_args.get(\"arguments\")\n                    function = Function(name=function_name, arguments=args)\n                    tool_call = ChatCompletionMessageToolCall(id=str(uuid.uuid4()), function=function)\n                    text += before_call_text + after_call_text\n                    tool_calls.append(tool_call)\n                except json.JSONDecodeError:\n                    print(f\"Error parsing tool_call function name and args: {function_name_and_args}\")\n                    continue\n            return text, tool_calls\n\n        return content, None\n\n    @staticmethod\n    def _use_llama_tool_syntax(model: str, tools: Optional[List]) -&gt; bool:\n        return tools is not None and \"llama\" in model\n\n    @staticmethod\n    def _llama_tool_prompt(tools: Optional[List]) -&gt; str:\n        return (\n            \"\"\"Answer the user's question by making use of the following functions if needed.\n            If none of the function can be used, please say so.\n            Here is a list of functions in JSON format:\"\"\"\n            + json.dumps(tools)\n            + \"\"\"Think very carefully before calling functions.\n            If you choose to call a function ONLY reply in the following format with no prefix or suffix:\n\n            &lt;function=example_function_name&gt;{\"example_name\": \"example_value\"}&lt;/function&gt;\n\n            Reminder:\n            - Function calls MUST follow the specified format, start with &lt;function= and end with &lt;/function&gt;\n            - Function arguments MUST be in JSON format using double quotes\n            - Required parameters MUST be specified\n            - Multiple functions can be called in one message as long as they are on separate lines.\n            - Put the entire function call reply on one line\n        \"\"\"\n        )\n\n    # TODO(286): `messages` may be model and `model` may be messages temporarily to support deprecated API.\n    def completion(\n        self,\n        messages: Union[Iterable[ChatCompletionMessageParam], str],\n        model: Union[Iterable[ChatCompletionMessageParam], str] = \"\",\n        **kwargs: Any,\n    ) -&gt; str:\n        \"\"\"Returns a completion for the given messages using the given model.\"\"\"\n        raw_response = self.completions(messages, model, **kwargs)\n        assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n        response: ModelResponse = raw_response\n        assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n        choices: List[Choices] = response.choices  # type: ignore\n        response_message = choices[0].message.content\n        assert response_message, \"No completions returned\"\n        return response_message\n\n    def signed_completion(\n        self,\n        messages: Union[Iterable[ChatCompletionMessageParam], str],\n        model: Union[Iterable[ChatCompletionMessageParam], str] = \"\",\n        **kwargs: Any,\n    ) -&gt; Dict[str, str]:\n        \"\"\"Returns a completion for the given messages using the given model with the agent signature.\"\"\"\n        # TODO Return signed completions for non-latest versions only?\n        agent_name = self.get_primary_agent().get_full_name()\n        raw_response = self.completions(messages, model, agent_name=agent_name, **kwargs)\n        assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n        response: ModelResponse = raw_response\n\n        signature_data = json.loads(response.system_fingerprint) if response.system_fingerprint else {}\n\n        assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n        choices: List[Choices] = response.choices  # type: ignore\n        response_message = choices[0].message.content\n        assert response_message, \"No completions returned\"\n\n        return {\n            \"response\": response_message,\n            \"signature\": signature_data.get(\"signature\", None),\n            \"public_key\": signature_data.get(\"public_key\", None),\n        }\n\n    def completion_and_get_tools_calls(\n        self,\n        messages: List[ChatCompletionMessageParam],\n        model: str = \"\",\n        **kwargs: Any,\n    ) -&gt; SimpleNamespace:\n        \"\"\"Returns completion message and/or tool calls from OpenAI or Llama tool formats.\"\"\"\n        raw_response = self._run_inference_completions(messages, model, stream=False, **kwargs)\n\n        assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n        response: ModelResponse = raw_response\n        assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n        choices: List[Choices] = response.choices  # type: ignore\n\n        (message_without_tool_call, tool_calls) = self._parse_tool_call(choices[0].message)\n\n        if message_without_tool_call is None:\n            response_message = choices[0].message.content\n            message_without_tool_call = response_message\n\n        return SimpleNamespace(message=message_without_tool_call, tool_calls=tool_calls)\n\n    def completion_and_run_tools(\n        self,\n        messages: List[ChatCompletionMessageParam],\n        model: str = \"\",\n        tools: Optional[List] = None,\n        **kwargs: Any,\n    ) -&gt; Optional[str]:\n        \"\"\"Returns a completion for the given messages using the given model and runs tools.\"\"\"\n        completion_tools_response = self.completions_and_run_tools(messages, model, tools, **kwargs)\n        assert all(\n            map(\n                lambda choice: isinstance(choice, Choices),\n                completion_tools_response.choices,\n            )\n        ), \"Expected Choices\"\n        choices: List[Choices] = completion_tools_response.choices  # type: ignore\n        response_content = choices[0].message.content\n        return response_content\n\n    def call_agent(self, agent_index: int, task: str) -&gt; None:\n        \"\"\"Calls agent with given task.\"\"\"\n        self._agents[agent_index].run(self, task=task)\n\n    def get_agents(self) -&gt; List[Agent]:\n        \"\"\"Returns list of agents available in environment.\"\"\"\n        return self._agents\n\n    def get_primary_agent(self) -&gt; Agent:\n        \"\"\"Returns the agent that is invoked first.\"\"\"\n        return self._agents[0]\n\n    def get_primary_agent_temp_dir(self) -&gt; Path:\n        \"\"\"Returns temp dir for primary agent.\"\"\"\n        return self.get_primary_agent().temp_dir\n\n    def is_done(self) -&gt; bool:  # noqa: D102\n        return self._done\n\n    def create_snapshot(self) -&gt; bytes:\n        \"\"\"Create an in memory snapshot.\"\"\"\n        with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n            with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n                tar.add(self._path, arcname=\".\")\n            f.flush()\n            f.seek(0)\n            snapshot = f.read()\n        return snapshot\n\n    def environment_run_info(self, base_id, run_type) -&gt; dict:\n        \"\"\"Returns the environment run information.\"\"\"\n        if not self._agents or not self.get_primary_agent():\n            raise ValueError(\"Agent not found\")\n        primary_agent = self.get_primary_agent()\n\n        full_agent_name = \"/\".join([primary_agent.namespace, primary_agent.name, primary_agent.version])\n        safe_agent_name = full_agent_name.replace(\"/\", \"_\")\n        uid = uuid.uuid4().hex\n        generated_name = f\"environment_run_{safe_agent_name}_{uid}\"\n        name = generated_name\n\n        timestamp = datetime.now(timezone.utc).isoformat()\n        return {\n            \"name\": name,\n            \"version\": \"0\",\n            \"description\": f\"Agent {run_type} {full_agent_name} {uid} {timestamp}\",\n            \"category\": \"environment\",\n            \"tags\": [\"environment\"],\n            \"details\": {\n                \"base_id\": base_id,\n                \"timestamp\": timestamp,\n                \"agents\": [agent.name for agent in self._agents],\n                \"primary_agent_namespace\": primary_agent.namespace,\n                \"primary_agent_name\": primary_agent.name,\n                \"primary_agent_version\": primary_agent.version,\n                \"run_id\": self._run_id,\n                \"run_type\": run_type,\n            },\n            \"show_entry\": True,\n        }\n\n    def load_snapshot(self, snapshot: bytes) -&gt; None:\n        \"\"\"Load Environment from Snapshot.\"\"\"\n        shutil.rmtree(self._path, ignore_errors=True)\n\n        with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n            f.write(snapshot)\n            f.flush()\n            f.seek(0)\n\n            with tarfile.open(fileobj=f, mode=\"r:gz\") as tar:\n                tar.extractall(self._path)\n\n    def __str__(self) -&gt; str:  # noqa: D105\n        return f\"Environment({self._path})\"\n\n    def clear_temp_agent_files(self, verbose=True) -&gt; None:\n        \"\"\"Remove temp agent files created to be used in `runpy`.\"\"\"\n        for agent in self._agents:\n            if os.path.exists(agent.temp_dir):\n                if verbose:\n                    print(\"removed agent.temp_files\", agent.temp_dir)\n                shutil.rmtree(agent.temp_dir)\n\n    def set_next_actor(self, who: str) -&gt; None:\n        \"\"\"Set the next actor / action in the dialogue.\"\"\"\n        next_action_fn = os.path.join(self._path, \".next_action\")\n        if who == \"agent\":\n            self._done = False\n\n        with open(next_action_fn, \"w\") as f:\n            f.write(who)\n\n    def get_next_actor(self) -&gt; str:  # noqa: D102\n        next_action_fn = os.path.join(self._path, \".next_action\")\n\n        if os.path.exists(next_action_fn):\n            with open(next_action_fn) as f:\n                return f.read().strip(\" \\n\")\n        else:\n            # By default the user starts the conversation.\n            return \"user\"\n\n    def run(\n        self,\n        new_message: Optional[str] = None,\n        max_iterations: int = 10,\n    ) -&gt; None:\n        \"\"\"Runs agent(s) against a new or previously created environment.\"\"\"\n        if new_message:\n            self._add_message(\"user\", new_message)\n\n        iteration = 0\n        self.set_next_actor(\"agent\")\n\n        while iteration &lt; max_iterations and not self.is_done() and self.get_next_actor() != \"user\":\n            iteration += 1\n            if max_iterations &gt; 1:\n                self.add_system_log(\n                    f\"Running agent, iteration {iteration}/{max_iterations}\",\n                    logging.INFO,\n                )\n            try:\n                error_message, traceback_message = self.get_primary_agent().run(self, task=new_message)\n                if self._debug_mode and (error_message or traceback_message):\n                    if self._debug_mode and (error_message or traceback_message):\n                        message_parts = []\n\n                        if error_message:\n                            message_parts.append(f\"Error: \\n ```\\n{error_message}\\n```\")\n\n                        if traceback_message:\n                            message_parts.append(f\"Error Traceback: \\n ```\\n{traceback_message}\\n```\")\n\n                        self.add_reply(\"\\n\\n\".join(message_parts), message_type=\"system:debug\")\n\n            except Exception as e:\n                self.add_system_log(f\"Environment run failed: {e}\", logging.ERROR)\n                self.mark_failed()\n                raise e\n\n        if not self._pending_ext_agent:\n            # If no external agent was called, mark the whole run as done.\n            # Else this environment will stop for now but this run will be continued later.\n            self.mark_done()\n\n    def generate_folder_hash_id(self, path: str) -&gt; str:\n        \"\"\"Returns hash based on files and their contents in path, including subfolders.\"\"\"  # noqa: E501\n        hash_obj = hashlib.md5()\n\n        for root, _dirs, files in os.walk(path):\n            for file in sorted(files):\n                file_path = os.path.join(root, file)\n                with open(file_path, \"rb\") as f:\n                    while chunk := f.read(8192):\n                        hash_obj.update(chunk)\n\n        return hash_obj.hexdigest()\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.__init__","title":"__init__","text":"<pre><code>__init__(\n    path: str,\n    agents: List[Agent],\n    client: InferenceClient,\n    hub_client: OpenAI,\n    thread_id: str,\n    run_id: str,\n    create_files: bool = True,\n    env_vars: Optional[Dict[str, Any]] = None,\n    tool_resources: Optional[Dict[str, Any]] = None,\n    print_system_log: bool = False,\n    agent_runner_user: Optional[str] = None,\n    fastnear_api_key: Optional[str] = None,\n    approvals=None,\n) -&gt; None\n</code></pre> Source code in <code>nearai/agents/environment.py</code> <pre><code>def __init__(  # noqa: D107\n    self,\n    path: str,\n    agents: List[Agent],\n    client: InferenceClient,\n    hub_client: OpenAI,\n    thread_id: str,\n    run_id: str,\n    create_files: bool = True,\n    env_vars: Optional[Dict[str, Any]] = None,\n    tool_resources: Optional[Dict[str, Any]] = None,\n    print_system_log: bool = False,\n    agent_runner_user: Optional[str] = None,\n    fastnear_api_key: Optional[str] = None,\n    approvals=None,\n) -&gt; None:\n    # Warning: never expose `client` or `_hub_client` to agent's environment\n\n    self.base_url = client._config.base_url\n\n    # user_auth is used to authenticate the user in the ts_runner. It will be removed after that in\n    # `nearai/agents/agent.py`\n    auth = client._auth\n    self.user_auth = auth\n\n    # Initialize secure openai clients\n    openai_client_params = {\n        \"api_key\": auth,\n        \"base_url\": client._config.base_url,\n        \"default_headers\": {\"Authorization\": f\"Bearer {auth}\"},\n    }\n    self.openai = SecureOpenAI(**openai_client_params)\n    self.async_openai = SecureAsyncOpenAI(**openai_client_params)\n\n    # Placeholder for solver\n    self.client: Optional[InferenceClient] = None\n\n    self._path = path\n    self._agents = agents\n    self._done = False\n    self._pending_ext_agent = False\n    self.env_vars: Dict[str, Any] = env_vars if env_vars else {}\n    self._last_used_model = \"\"\n    self.tool_resources: Dict[str, Any] = tool_resources if tool_resources else {}\n    self.print_system_log = print_system_log\n    self.agent_runner_user = agent_runner_user\n    self._approvals = approvals if approvals else default_approvals\n    self._thread_id = thread_id\n    self._run_id = run_id\n    self._debug_mode: bool = any(\n        str(value).lower() in (\"true\", \"1\", \"yes\", \"on\")\n        for key, value in self.env_vars.items()\n        if key.lower() == \"debug\"\n    )\n    # Expose the NEAR account_id of a user that signs this request to run an agent.\n    self.signer_account_id: str = client._config.auth.account_id if client._config.auth else \"\"\n\n    if fastnear_api_key:\n        default_mainnet_rpc = f\"https://{fastnear_api_key}@rpc.mainnet.fastnear.com\"\n    else:\n        default_mainnet_rpc = \"https://rpc.mainnet.near.org\"\n\n    class NearAccount(Account):\n        user_rpc_addr: Union[str, None]\n\n        async def view(\n            self,\n            contract_id: str,\n            method_name: str,\n            args: dict,\n            block_id: Optional[int] = None,\n            threshold: Optional[int] = None,\n            max_retries: int = 3,\n        ):\n            \"\"\"Wrapper for the view method of the Account class, adding multiple retry attempts.\n\n            Parameters\n            ----------\n            contract_id : str\n                The ID of the contract to call.\n            method_name : str\n                The name of the method to invoke on the contract.\n            args : dict\n                The arguments to pass to the contract method.\n            block_id : Optional[int]\n                The block ID to query at.\n            threshold : Optional[int]\n                The threshold for the view function.\n            max_retries : int\n                The maximum number of retry attempts.\n\n            Returns\n            -------\n            The result of the contract method call.\n\n            Raises\n            ------\n            Exception\n                If all retry attempts fail, the exception is propagated.\n\n            \"\"\"\n            acc = Account(self.account_id, self.private_key, self.user_rpc_addr or default_mainnet_rpc)\n            await acc.startup()\n            max_retries = min(max_retries, 10)\n\n            for attempt in range(1, max_retries + 1):\n                try:\n                    # Attempt to read the contract view method\n                    return await acc.view_function(contract_id, method_name, args, block_id, threshold)\n                except Exception as e:\n                    # Log the error message for the current attempt\n                    print(\n                        f\"Attempt {attempt}/{max_retries} to view method '{method_name}' on contract \"\n                        f\"'{contract_id}' failed with error: {e}\"\n                    )\n\n                    # If it's the last attempt, re-raise the exception\n                    if attempt == max_retries:\n                        raise\n\n        async def call(\n            self,\n            contract_id: str,\n            method_name: str,\n            args: dict,\n            gas: int = DEFAULT_ATTACHED_GAS,\n            amount: int = 0,\n            nowait: bool = False,\n            included: bool = False,\n            max_retries: int = 1,\n        ):\n            \"\"\"Wrapper for the call method of the Account class, adding multiple retry attempts.\n\n            Parameters\n            ----------\n            contract_id : str\n                The ID of the contract to call.\n            method_name : str\n                The name of the method to invoke on the contract.\n            args : dict\n                The arguments to pass to the contract method.\n            gas : int\n                The amount of gas to attach to the call.\n            amount : int\n                The amount of tokens to attach to the call.\n            nowait : bool\n                If nowait is True, return transaction hash, else wait execution.\n            included : bool\n                If included is True, return transaction hash, else wait execution\n            max_retries : int\n                The maximum number of retry attempts.\n\n            Returns\n            -------\n            The result of the contract method call.\n\n            Raises\n            ------\n            Exception\n                If all retry attempts fail, the exception is propagated.\n\n            \"\"\"\n            acc = Account(self.account_id, self.private_key, self.user_rpc_addr or default_mainnet_rpc)\n            await acc.startup()\n            max_retries = min(max_retries, 10)\n\n            for attempt in range(1, max_retries + 1):\n                try:\n                    # Attempt to call the contract method\n                    return await acc.function_call(contract_id, method_name, args, gas, amount, nowait, included)\n                except Exception as e:\n                    # Log the error message for the current attempt\n                    print(\n                        f\"Attempt {attempt}/{max_retries} to call method '{method_name}' on contract \"\n                        f\"'{contract_id}' failed with error: {e}\"\n                    )\n\n                    # If it's the last attempt, re-raise the exception\n                    if attempt == max_retries:\n                        raise\n\n        async def get_balance(self, account_id: Optional[str] = None) -&gt; int:\n            \"\"\"Retrieves the balance of the specified NEAR account.\n\n            Parameters\n            ----------\n            account_id : Optional[str]\n                The ID of the account to retrieve the balance for. If not provided, the balance of the current\n                account is retrieved.\n\n            Returns\n            -------\n            int\n                The balance of the specified account in yoctoNEAR.\n\n            Raises\n            ------\n            Exception\n                If there is an error retrieving the balance.\n\n            \"\"\"\n            acc = Account(self.account_id, self.private_key, self.user_rpc_addr or default_mainnet_rpc)\n            await acc.startup()\n            return await acc.get_balance(account_id)\n\n        def __init__(\n            self,\n            account_id: Optional[str] = None,\n            private_key: Optional[Union[List[Union[str, bytes]], str, bytes]] = None,\n            rpc_addr: Optional[str] = None,\n        ):\n            self.user_rpc_addr = rpc_addr\n            self.account_id = account_id\n            self.private_key = private_key\n            super().__init__(account_id, private_key, rpc_addr)\n\n    self.set_near = NearAccount\n\n    self._tools = ToolRegistry()\n\n    if create_files:\n        os.makedirs(self._path, exist_ok=True)\n        open(os.path.join(self._path, CHAT_FILENAME), \"a\").close()\n    os.chdir(self._path)\n\n    # Protected client methods\n    def query_vector_store(vector_store_id: str, query: str, full_files: bool = False):\n        \"\"\"Queries a vector store.\n\n        vector_store_id: The id of the vector store to query.\n        query: The query to search for.\n        \"\"\"\n        return client.query_vector_store(vector_store_id, query, full_files)\n\n    self.query_vector_store = query_vector_store\n\n    def upload_file(\n        file_content: str,\n        purpose: Literal[\"assistants\", \"batch\", \"fine-tune\", \"vision\"] = \"assistants\",\n        encoding: Optional[str] = \"utf-8\",\n        file_name: Optional[str] = \"file.txt\",\n        file_type: Optional[str] = \"text/plain\",\n    ):\n        \"\"\"Uploads a file to the registry.\"\"\"\n        return client.upload_file(\n            file_content, purpose, encoding=encoding, file_name=file_name, file_type=file_type\n        )\n\n    self.upload_file = upload_file\n\n    def remove_file(file_id: str):\n        \"\"\"Removes a file from the registry.\"\"\"\n        return client.remove_file(file_id)\n\n    self.remove_file = remove_file\n\n    def create_vector_store_from_source(\n        name: str,\n        source: Union[GitHubSource, GitLabSource],\n        source_auth: Optional[str] = None,\n        chunking_strategy: Optional[ChunkingStrategy] = None,\n        expires_after: Optional[ExpiresAfter] = None,\n        metadata: Optional[Dict[str, str]] = None,\n    ) -&gt; VectorStore:\n        \"\"\"Creates a vector store from the given source.\n\n        Args:\n        ----\n            name: The name of the vector store.\n            source: The source from which to create the vector store.\n            source_auth: The source authentication token.\n            chunking_strategy: The chunking strategy to use.\n            expires_after: The expiration policy.\n            metadata: Additional metadata.\n\n        Returns:\n        -------\n            VectorStore: The created vector store.\n\n        \"\"\"\n        return client.create_vector_store_from_source(\n            name=name,\n            source=source,\n            source_auth=source_auth,\n            chunking_strategy=chunking_strategy,\n            expires_after=expires_after,\n            metadata=metadata,\n        )\n\n    self.create_vector_store_from_source = create_vector_store_from_source\n\n    def add_file_to_vector_store(vector_store_id: str, file_id: str):\n        \"\"\"Adds a file to the vector store.\"\"\"\n        return client.add_file_to_vector_store(vector_store_id, file_id)\n\n    self.add_file_to_vector_store = add_file_to_vector_store\n\n    # positional arguments are not allowed because arguments list will be updated\n    def find_agents(\n        *,\n        owner_id: Optional[str] = None,\n        with_capabilities: Optional[bool] = False,\n        latest_versions_only: Optional[bool] = True,\n        limit: Optional[int] = None,\n        offset: Optional[int] = None,\n    ):\n        \"\"\"Find agents based on various parameters.\"\"\"\n        return client.find_agents(owner_id, with_capabilities, latest_versions_only, limit, offset)\n\n    self.find_agents = find_agents\n\n    def create_vector_store(\n        name: str,\n        file_ids: list,\n        expires_after: Union[ExpiresAfter, NotGiven] = NOT_GIVEN,\n        chunking_strategy: Union[\n            AutoFileChunkingStrategyParam, StaticFileChunkingStrategyObjectParam, NotGiven\n        ] = NOT_GIVEN,\n        metadata: Optional[Dict[str, str]] = None,\n    ) -&gt; VectorStore:\n        \"\"\"Creates a vector store.\n\n        Args:\n        ----\n            name: The name of the vector store.\n            file_ids: List of file ids to create the vector store.\n            chunking_strategy: The chunking strategy to use.\n            expires_after: The expiration policy.\n            metadata: Additional metadata.\n\n        Returns:\n        -------\n            VectorStore: The created vector store.\n\n        \"\"\"\n        return client.create_vector_store(\n            name=name,\n            file_ids=file_ids,\n            chunking_strategy=chunking_strategy,\n            expires_after=expires_after,\n            metadata=metadata,\n        )\n\n    self.create_vector_store = create_vector_store\n\n    def get_vector_store(vector_store_id: str) -&gt; VectorStore:\n        \"\"\"Gets a vector store by id.\"\"\"\n        return client.get_vector_store(vector_store_id)\n\n    self.get_vector_store = get_vector_store\n\n    def get_vector_store_files(vector_store_id: str) -&gt; Optional[List[VectorStoreFile]]:\n        \"\"\"Gets a list of vector store files.\"\"\"\n        return client.get_vector_store_files(vector_store_id)\n\n    self.get_vector_store_files = get_vector_store_files\n\n    # Save cache of requested models for inference to avoid extra server calls\n    self.cached_models_for_inference: Dict[str, str] = {}\n\n    def get_model_for_inference(model: str = \"\") -&gt; str:\n        \"\"\"Returns 'provider::model_full_path'.\"\"\"\n        if self.cached_models_for_inference.get(model, None) is None:\n            provider = self.get_primary_agent().model_provider if self._agents else \"\"\n            if model == \"\":\n                model = self.get_primary_agent().model if self._agents else \"\"\n            if model == \"\":\n                return DEFAULT_PROVIDER_MODEL\n\n            _, model_for_inference = client.provider_models.match_provider_model(model, provider)\n\n            self.cached_models_for_inference[model] = model_for_inference\n\n        return self.cached_models_for_inference[model]\n\n    self.get_model_for_inference = get_model_for_inference\n\n    def _run_inference_completions(\n        messages: Union[Iterable[ChatCompletionMessageParam], str],\n        model: Union[Iterable[ChatCompletionMessageParam], str],\n        stream: bool,\n        **kwargs: Any,\n    ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n        \"\"\"Run inference completions for given parameters.\"\"\"\n        params, kwargs = self.get_inference_parameters(messages, model, stream, **kwargs)\n\n        completions = client.completions(\n            params.model, params.messages, params.stream, params.temperature, params.max_tokens, **kwargs\n        )\n\n        return completions\n\n    self._run_inference_completions = _run_inference_completions\n\n    def get_agent_public_key():\n        \"\"\"Returns public key of the agent.\"\"\"\n        agent_name = self.get_primary_agent().get_full_name()\n\n        return client.get_agent_public_key(agent_name)\n\n    self.get_agent_public_key = get_agent_public_key\n\n    def run_agent(\n        agent_id: str,\n        query: Optional[str] = None,\n        thread_mode: ThreadMode = ThreadMode.FORK,\n        run_mode: RunMode = RunMode.SIMPLE,\n    ):\n        \"\"\"Runs a child agent on the thread.\"\"\"\n        child_thread_id = self._thread_id\n\n        if thread_mode == ThreadMode.SAME:\n            pass\n        elif thread_mode == ThreadMode.FORK:\n            child_thread_id = client.threads_fork(self._thread_id).id\n            self.add_system_log(f\"Forked thread {child_thread_id}\", logging.INFO)\n        elif thread_mode == ThreadMode.CHILD:\n            child_thread_id = client.create_subthread(self._thread_id).id\n            self.add_system_log(f\"Created subthread {child_thread_id}\", logging.INFO)\n\n        if query:\n            client.threads_messages_create(thread_id=child_thread_id, content=query, role=\"user\")\n\n        self.add_system_log(f\"Running agent {agent_id}\", logging.INFO)\n        client.run_agent(\n            parent_run_id=self._run_id,\n            run_on_thread_id=child_thread_id,\n            assistant_id=agent_id,\n            run_mode=run_mode,\n        )\n        self._pending_ext_agent = True\n\n        return child_thread_id\n\n    self.run_agent = run_agent\n\n    def schedule_run(\n        agent: str,\n        input_message: str,\n        run_at: datetime,\n        run_params: Optional[Dict[str, str]] = None,\n        thread_id: Optional[str] = None,\n    ):\n        \"\"\"Schedules a run.\"\"\"\n        return client.schedule_run(agent, input_message, thread_id, run_params, run_at)\n\n    self.schedule_run = schedule_run\n\n    # TODO(https://github.com/nearai/nearai/issues/549): Allow only a subset of agents to access/update user memory.\n    def add_user_memory(memory: str):\n        \"\"\"Add user memory.\"\"\"\n        return client.add_user_memory(memory)\n\n    self.add_user_memory = add_user_memory\n\n    def query_user_memory(query: str):\n        \"\"\"Query user memory.\"\"\"\n        return client.query_user_memory(query)\n\n    self.query_user_memory = query_user_memory\n\n    def generate_image(prompt: str):\n        \"\"\"Generate an image.\"\"\"\n        return client.generate_image(prompt)\n\n    self.generate_image = generate_image\n\n    def save_agent_data(key, data: Dict[str, Any]):\n        \"\"\"Save agent data.\"\"\"\n        try:\n            return client.save_agent_data(key, data)\n        except Exception as ex:\n            self.add_system_log(f\"Error saving agent data by key {key}: {ex}\", logging.ERROR)\n            return None\n\n    self.save_agent_data = save_agent_data\n\n    def get_agent_data():\n        \"\"\"Get agent data.\"\"\"\n        return client.get_agent_data()\n\n    self.get_agent_data = get_agent_data\n\n    def get_agent_data_by_key(key, default=None):\n        \"\"\"Get agent data by key.\"\"\"\n        namespace = self.get_primary_agent().namespace\n        name = self.get_primary_agent().name\n        try:\n            result = client.get_agent_data_by_key(key)\n        except Exception as ex:\n            self.add_system_log(f\"Error getting agent data by key {key}: {ex}\", logging.ERROR)\n            result = None\n        return (\n            result\n            if result\n            else {\n                \"value\": default,\n                \"namespace\": namespace,\n                \"key\": key,\n                \"name\": name,\n                \"updated_at\": \"\",\n                \"created_at\": \"\",\n            }\n        )\n\n    self.get_agent_data_by_key = get_agent_data_by_key\n\n    # HubClient methods\n    def add_reply(\n        message: str,\n        attachments: Optional[Iterable[Attachment]] = None,\n        message_type: Optional[str] = None,\n        thread_id: str = self._thread_id,\n    ):\n        \"\"\"Assistant adds a message to the environment.\"\"\"\n        # NOTE: message from `user` are not stored in the memory\n\n        return hub_client.beta.threads.messages.create(\n            thread_id=thread_id,\n            role=\"assistant\",\n            content=message,\n            extra_body={\n                \"assistant_id\": self.get_primary_agent().identifier,\n                \"run_id\": self._run_id,\n            },\n            attachments=attachments,\n            metadata={\"message_type\": message_type} if message_type else None,\n        )\n\n    self.add_reply = add_reply\n\n    def get_thread(thread_id=self._thread_id):\n        \"\"\"Returns the current Thread object or the requested Thread.\"\"\"\n        return client.get_thread(thread_id)\n\n    self.get_thread = get_thread\n\n    def _add_message(\n        role: str,\n        message: str,\n        attachments: Optional[Iterable[Attachment]] = None,\n        **kwargs: Any,\n    ):\n        return hub_client.beta.threads.messages.create(\n            thread_id=self._thread_id,\n            role=role,  # type: ignore\n            content=message,\n            extra_body={\n                \"assistant_id\": self.get_primary_agent().identifier,\n                \"run_id\": self._run_id,\n            },\n            metadata=kwargs,\n            attachments=attachments,\n        )\n\n    self._add_message = _add_message\n\n    def _list_messages(\n        limit: Union[int, NotGiven] = NOT_GIVEN,\n        order: Literal[\"asc\", \"desc\"] = \"asc\",\n        thread_id: Optional[str] = None,\n    ) -&gt; List[Message]:\n        \"\"\"Returns messages from the environment.\"\"\"\n        messages = hub_client.beta.threads.messages.list(\n            thread_id=thread_id or self._thread_id, limit=limit, order=order\n        )\n        self.add_system_log(f\"Retrieved {len(messages.data)} messages from NEAR AI Hub\")\n        return messages.data\n\n    self._list_messages = _list_messages\n\n    def list_files_from_thread(\n        order: Literal[\"asc\", \"desc\"] = \"asc\", thread_id: Optional[str] = None\n    ) -&gt; List[FileObject]:\n        \"\"\"Lists files in the thread.\"\"\"\n        messages = self._list_messages(order=order)\n        # Extract attachments from messages\n        attachments = [a for m in messages if m.attachments for a in m.attachments]\n        # Extract files from attachments\n        file_ids = [a.file_id for a in attachments]\n        files = [hub_client.files.retrieve(f) for f in file_ids if f]\n        return files\n\n    self.list_files_from_thread = list_files_from_thread\n\n    def read_file_by_id(file_id: str):\n        \"\"\"Read a file from the thread.\"\"\"\n        content = hub_client.files.content(file_id).content.decode(\"utf-8\")\n        print(\"file content returned by api\", content)\n        return content\n\n    self.read_file_by_id = read_file_by_id\n\n    def write_file(\n        filename: str,\n        content: Union[str, bytes],\n        encoding: str = \"utf-8\",\n        filetype: str = \"text/plain\",\n        write_to_disk: bool = True,\n    ) -&gt; FileObject:\n        \"\"\"Writes a file to the environment.\n\n        filename: The name of the file to write to\n        content: The content to write to the file\n        encoding: The encoding to use when writing the file (default is utf-8)\n        filetype: The MIME type of the file (default is text/plain)\n        write_to_disk: If True, write locally to disk (default is True)\n        \"\"\"\n        if write_to_disk:\n            # Write locally\n            path = Path(self.get_primary_agent_temp_dir()) / filename\n            path.parent.mkdir(parents=True, exist_ok=True)\n            if isinstance(content, bytes):\n                with open(path, \"wb\") as f:\n                    f.write(content)\n            else:\n                with open(path, \"w\", encoding=encoding) as f:\n                    f.write(content)\n\n        if isinstance(content, bytes):\n            file_data = content\n        else:\n            file_data = io.BytesIO(content.encode(encoding))  # type:ignore\n\n        # Upload to Hub\n        file = hub_client.files.create(file=(filename, file_data, filetype), purpose=\"assistants\")\n        res = self.add_reply(\n            message=f\"Successfully wrote {len(content) if content else 0} characters to {filename}\",\n            attachments=[{\"file_id\": file.id, \"tools\": [{\"type\": \"file_search\"}]}],\n            message_type=\"system:file_write\",\n        )\n        self.add_system_log(\n            f\"Uploaded file {filename} with {len(content)} characters, id: {file.id}. Added in thread as: {res.id}\"\n        )\n        return file\n\n    self.write_file = write_file\n\n    def mark_done() -&gt; Run:  # noqa: D102\n        self._done = True\n        res = hub_client.beta.threads.runs.update(\n            thread_id=self._thread_id,\n            run_id=self._run_id,\n            extra_body={\n                \"status\": \"completed\",\n                \"completed_at\": datetime.now().isoformat(),\n            },\n        )\n        return res\n\n    self.mark_done = mark_done\n\n    def mark_failed() -&gt; Run:\n        \"\"\"Marks the environment run as failed.\"\"\"\n        self._done = True\n        self.add_system_log(\"Environment run failed\", logging.ERROR)\n        res = hub_client.beta.threads.runs.update(\n            thread_id=self._thread_id,\n            run_id=self._run_id,\n            extra_body={\"status\": \"failed\", \"failed_at\": datetime.now().isoformat()},\n        )\n        return res\n\n    self.mark_failed = mark_failed\n\n    def request_user_input() -&gt; Run:\n        \"\"\"Must be called to request input from the user.\"\"\"\n        return hub_client.beta.threads.runs.update(\n            thread_id=self._thread_id,\n            run_id=self._run_id,\n            extra_body={\"status\": \"requires_action\", \"required_action\": {\"type\": \"user_input\"}},\n        )\n\n    self.request_user_input = request_user_input\n\n    def request_agent_input() -&gt; Run:\n        \"\"\"Mark the run as ready for input from another agent.\"\"\"\n        return hub_client.beta.threads.runs.update(\n            thread_id=self._thread_id,\n            run_id=self._run_id,\n            extra_body={\"status\": \"requires_action\", \"required_action\": {\"type\": \"agent_input\"}},\n        )\n\n    self.request_agent_input = request_agent_input\n\n    # Must be placed after method definitions\n    self.register_standard_tools()\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.add_agent_log","title":"add_agent_log","text":"<pre><code>add_agent_log(log: str, level: int = INFO) -&gt; None\n</code></pre> <p>Add agent log with timestamp and log level.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def add_agent_log(self, log: str, level: int = logging.INFO) -&gt; None:\n    \"\"\"Add agent log with timestamp and log level.\"\"\"\n    logger = logging.getLogger(\"agent_logger\")\n    if not logger.handlers:\n        # Configure the logger if it hasn't been set up yet\n        logger.setLevel(logging.DEBUG)\n        file_handler = logging.FileHandler(os.path.join(self._path, AGENT_LOG_FILENAME))\n        formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n        file_handler.setFormatter(formatter)\n        logger.addHandler(file_handler)\n\n        # Add Thread log handler\n        if self._debug_mode:\n            custom_handler = CustomLogHandler(self.add_reply, \"agent\")\n            custom_handler.setFormatter(formatter)\n            logger.addHandler(custom_handler)\n\n    # Log the message\n    logger.log(level, log)\n    # Force the handler to write to disk\n    for handler in logger.handlers:\n        handler.flush()\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.add_agent_start_system_log","title":"add_agent_start_system_log","text":"<pre><code>add_agent_start_system_log(agent_idx: int) -&gt; None\n</code></pre> <p>Adds agent start system log.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def add_agent_start_system_log(self, agent_idx: int) -&gt; None:\n    \"\"\"Adds agent start system log.\"\"\"\n    agent = self._agents[agent_idx]\n    message = f\"Running agent {agent.name}\"\n    if agent.model != \"\":\n        model = self.get_model_for_inference(agent.model)\n        self._last_used_model = model\n        message += f\" that will connect to {model}\"\n        if agent.model_temperature:\n            message += f\", temperature={agent.model_temperature}\"\n        if agent.model_max_tokens:\n            message += f\", max_tokens={agent.model_max_tokens}\"\n    self.add_system_log(message)\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.add_message","title":"add_message","text":"<pre><code>add_message(\n    role: str,\n    message: str,\n    attachments: Optional[Iterable[Attachment]] = None,\n    **kwargs: Any,\n)\n</code></pre> <p>Deprecated. Please use <code>add_reply</code> instead. Assistant adds a message to the environment.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def add_message(\n    self,\n    role: str,\n    message: str,\n    attachments: Optional[Iterable[Attachment]] = None,\n    **kwargs: Any,\n):\n    \"\"\"Deprecated. Please use `add_reply` instead. Assistant adds a message to the environment.\"\"\"\n    # Prevent agent to save messages on behalf of `user` to avoid adding false memory\n    role = \"assistant\"\n\n    return self._add_message(role, message, attachments, **kwargs)\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.add_system_log","title":"add_system_log","text":"<pre><code>add_system_log(log: str, level: int = INFO) -&gt; None\n</code></pre> <p>Add system log with timestamp and log level.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def add_system_log(self, log: str, level: int = logging.INFO) -&gt; None:\n    \"\"\"Add system log with timestamp and log level.\"\"\"\n    logger = logging.getLogger(\"system_logger\")\n    if not logger.handlers:\n        # Configure the logger if it hasn't been set up yet\n        logger.setLevel(logging.DEBUG)\n        file_handler = logging.FileHandler(os.path.join(self._path, SYSTEM_LOG_FILENAME))\n        formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n        file_handler.setFormatter(formatter)\n        logger.addHandler(file_handler)\n\n        if self.print_system_log:\n            console_handler = logging.StreamHandler()\n            console_handler.setFormatter(formatter)\n            logger.addHandler(console_handler)\n\n        # Add Thread log handler\n        if self._debug_mode:\n            custom_handler = CustomLogHandler(self.add_reply, \"system\")\n            custom_handler.setFormatter(formatter)\n            logger.addHandler(custom_handler)\n\n    # Log the message\n    logger.log(level, log)\n    # Force the handler to write to disk\n    for handler in logger.handlers:\n        handler.flush()\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.call_agent","title":"call_agent","text":"<pre><code>call_agent(agent_index: int, task: str) -&gt; None\n</code></pre> <p>Calls agent with given task.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def call_agent(self, agent_index: int, task: str) -&gt; None:\n    \"\"\"Calls agent with given task.\"\"\"\n    self._agents[agent_index].run(self, task=task)\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.clear_temp_agent_files","title":"clear_temp_agent_files","text":"<pre><code>clear_temp_agent_files(verbose=True) -&gt; None\n</code></pre> <p>Remove temp agent files created to be used in <code>runpy</code>.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def clear_temp_agent_files(self, verbose=True) -&gt; None:\n    \"\"\"Remove temp agent files created to be used in `runpy`.\"\"\"\n    for agent in self._agents:\n        if os.path.exists(agent.temp_dir):\n            if verbose:\n                print(\"removed agent.temp_files\", agent.temp_dir)\n            shutil.rmtree(agent.temp_dir)\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.completion","title":"completion","text":"<pre><code>completion(\n    messages: Union[\n        Iterable[ChatCompletionMessageParam], str\n    ],\n    model: Union[\n        Iterable[ChatCompletionMessageParam], str\n    ] = \"\",\n    **kwargs: Any,\n) -&gt; str\n</code></pre> <p>Returns a completion for the given messages using the given model.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def completion(\n    self,\n    messages: Union[Iterable[ChatCompletionMessageParam], str],\n    model: Union[Iterable[ChatCompletionMessageParam], str] = \"\",\n    **kwargs: Any,\n) -&gt; str:\n    \"\"\"Returns a completion for the given messages using the given model.\"\"\"\n    raw_response = self.completions(messages, model, **kwargs)\n    assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n    response: ModelResponse = raw_response\n    assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n    choices: List[Choices] = response.choices  # type: ignore\n    response_message = choices[0].message.content\n    assert response_message, \"No completions returned\"\n    return response_message\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.completion_and_get_tools_calls","title":"completion_and_get_tools_calls","text":"<pre><code>completion_and_get_tools_calls(\n    messages: List[ChatCompletionMessageParam],\n    model: str = \"\",\n    **kwargs: Any,\n) -&gt; SimpleNamespace\n</code></pre> <p>Returns completion message and/or tool calls from OpenAI or Llama tool formats.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def completion_and_get_tools_calls(\n    self,\n    messages: List[ChatCompletionMessageParam],\n    model: str = \"\",\n    **kwargs: Any,\n) -&gt; SimpleNamespace:\n    \"\"\"Returns completion message and/or tool calls from OpenAI or Llama tool formats.\"\"\"\n    raw_response = self._run_inference_completions(messages, model, stream=False, **kwargs)\n\n    assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n    response: ModelResponse = raw_response\n    assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n    choices: List[Choices] = response.choices  # type: ignore\n\n    (message_without_tool_call, tool_calls) = self._parse_tool_call(choices[0].message)\n\n    if message_without_tool_call is None:\n        response_message = choices[0].message.content\n        message_without_tool_call = response_message\n\n    return SimpleNamespace(message=message_without_tool_call, tool_calls=tool_calls)\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.completion_and_run_tools","title":"completion_and_run_tools","text":"<pre><code>completion_and_run_tools(\n    messages: List[ChatCompletionMessageParam],\n    model: str = \"\",\n    tools: Optional[List] = None,\n    **kwargs: Any,\n) -&gt; Optional[str]\n</code></pre> <p>Returns a completion for the given messages using the given model and runs tools.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def completion_and_run_tools(\n    self,\n    messages: List[ChatCompletionMessageParam],\n    model: str = \"\",\n    tools: Optional[List] = None,\n    **kwargs: Any,\n) -&gt; Optional[str]:\n    \"\"\"Returns a completion for the given messages using the given model and runs tools.\"\"\"\n    completion_tools_response = self.completions_and_run_tools(messages, model, tools, **kwargs)\n    assert all(\n        map(\n            lambda choice: isinstance(choice, Choices),\n            completion_tools_response.choices,\n        )\n    ), \"Expected Choices\"\n    choices: List[Choices] = completion_tools_response.choices  # type: ignore\n    response_content = choices[0].message.content\n    return response_content\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.completions","title":"completions","text":"<pre><code>completions(\n    messages: Union[\n        Iterable[ChatCompletionMessageParam], str\n    ],\n    model: Union[\n        Iterable[ChatCompletionMessageParam], str\n    ] = \"\",\n    stream: bool = False,\n    **kwargs: Any,\n) -&gt; Union[ModelResponse, CustomStreamWrapper]\n</code></pre> <p>Returns all completions for given messages using the given model.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def completions(\n    self,\n    messages: Union[Iterable[ChatCompletionMessageParam], str],\n    model: Union[Iterable[ChatCompletionMessageParam], str] = \"\",\n    stream: bool = False,\n    **kwargs: Any,\n) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n    \"\"\"Returns all completions for given messages using the given model.\"\"\"\n    return self._run_inference_completions(messages, model, stream, **kwargs)\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.completions_and_run_tools","title":"completions_and_run_tools","text":"<pre><code>completions_and_run_tools(\n    messages: List[ChatCompletionMessageParam],\n    model: str = \"\",\n    tools: Optional[List] = None,\n    add_responses_to_messages: bool = True,\n    agent_role_name=\"assistant\",\n    tool_role_name=\"tool\",\n    **kwargs: Any,\n) -&gt; ModelResponse\n</code></pre> <p>Returns all completions for given messages using the given model and runs tools.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def completions_and_run_tools(\n    self,\n    messages: List[ChatCompletionMessageParam],\n    model: str = \"\",\n    tools: Optional[List] = None,\n    add_responses_to_messages: bool = True,\n    agent_role_name=\"assistant\",\n    tool_role_name=\"tool\",\n    **kwargs: Any,\n) -&gt; ModelResponse:\n    \"\"\"Returns all completions for given messages using the given model and runs tools.\"\"\"\n    if self._use_llama_tool_syntax(model, tools):\n        tool_prompt = self._llama_tool_prompt(tools)\n        messages.append({\"role\": \"system\", \"content\": tool_prompt})\n    raw_response = self._run_inference_completions(messages, model, stream=False, tools=tools, **kwargs)\n    assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n    response: ModelResponse = raw_response\n    assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n    choices: List[Choices] = response.choices  # type: ignore\n    response_message = choices[0].message\n\n    self._handle_tool_calls(response_message, add_responses_to_messages, agent_role_name, tool_role_name)\n\n    return response\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.create_snapshot","title":"create_snapshot","text":"<pre><code>create_snapshot() -&gt; bytes\n</code></pre> <p>Create an in memory snapshot.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def create_snapshot(self) -&gt; bytes:\n    \"\"\"Create an in memory snapshot.\"\"\"\n    with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n        with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n            tar.add(self._path, arcname=\".\")\n        f.flush()\n        f.seek(0)\n        snapshot = f.read()\n    return snapshot\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.environment_run_info","title":"environment_run_info","text":"<pre><code>environment_run_info(base_id, run_type) -&gt; dict\n</code></pre> <p>Returns the environment run information.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def environment_run_info(self, base_id, run_type) -&gt; dict:\n    \"\"\"Returns the environment run information.\"\"\"\n    if not self._agents or not self.get_primary_agent():\n        raise ValueError(\"Agent not found\")\n    primary_agent = self.get_primary_agent()\n\n    full_agent_name = \"/\".join([primary_agent.namespace, primary_agent.name, primary_agent.version])\n    safe_agent_name = full_agent_name.replace(\"/\", \"_\")\n    uid = uuid.uuid4().hex\n    generated_name = f\"environment_run_{safe_agent_name}_{uid}\"\n    name = generated_name\n\n    timestamp = datetime.now(timezone.utc).isoformat()\n    return {\n        \"name\": name,\n        \"version\": \"0\",\n        \"description\": f\"Agent {run_type} {full_agent_name} {uid} {timestamp}\",\n        \"category\": \"environment\",\n        \"tags\": [\"environment\"],\n        \"details\": {\n            \"base_id\": base_id,\n            \"timestamp\": timestamp,\n            \"agents\": [agent.name for agent in self._agents],\n            \"primary_agent_namespace\": primary_agent.namespace,\n            \"primary_agent_name\": primary_agent.name,\n            \"primary_agent_version\": primary_agent.version,\n            \"run_id\": self._run_id,\n            \"run_type\": run_type,\n        },\n        \"show_entry\": True,\n    }\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.exec_command","title":"exec_command","text":"<pre><code>exec_command(command: str) -&gt; Dict[str, Union[str, int]]\n</code></pre> <p>Executes a command in the environment and logs the output.</p> <p>The environment does not allow running interactive programs. It will run a program for 1 second then will interrupt it if it is still running or if it is waiting for user input. command: The command to execute, like 'ls -l' or 'python3 tests.py'</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def exec_command(self, command: str) -&gt; Dict[str, Union[str, int]]:\n    \"\"\"Executes a command in the environment and logs the output.\n\n    The environment does not allow running interactive programs.\n    It will run a program for 1 second then will interrupt it if it is still running\n    or if it is waiting for user input.\n    command: The command to execute, like 'ls -l' or 'python3 tests.py'\n    \"\"\"\n    approval_function = self._approvals[\"confirm_execution\"] if self._approvals else None\n    if not approval_function:\n        return {\n            \"stderr\": \"Agent runner misconfiguration. No command execution approval function found.\",\n        }\n    if not approval_function(command):\n        return {\n            \"command\": command,\n            \"returncode\": 999,\n            \"stdout\": \"\",\n            \"stderr\": \"Command execution was not approved.\",\n        }\n\n    try:\n        process = subprocess.Popen(\n            shlex.split(command),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            bufsize=0,\n            universal_newlines=True,\n            cwd=self._path,\n        )\n    except Exception as e:\n        return {\n            \"command\": command,\n            \"returncode\": 999,\n            \"stdout\": \"\",\n            \"stderr\": \"Failed to execute: \" + str(e),\n        }\n\n    msg = \"\"\n\n    def kill_process_tree(p: Any) -&gt; None:\n        nonlocal msg\n        msg = \"Killing process due to timeout\"\n\n        process = psutil.Process(p.pid)\n        for proc in process.children(recursive=True):\n            proc.kill()\n        process.kill()\n\n    timer = threading.Timer(2, kill_process_tree, (process,))\n    timer.start()\n    process.wait()\n    timer.cancel()\n\n    result = {\n        \"command\": command,\n        \"stdout\": process.stdout.read() if process.stdout and hasattr(process.stdout, \"read\") else \"\",\n        \"stderr\": process.stderr.read() if process.stderr and hasattr(process.stderr, \"read\") else \"\",\n        \"returncode\": process.returncode,\n        \"msg\": msg,\n    }\n    with open(os.path.join(self._path, TERMINAL_FILENAME), \"a\") as f:\n        f.write(json.dumps(result) + DELIMITER)\n    return result\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.generate_folder_hash_id","title":"generate_folder_hash_id","text":"<pre><code>generate_folder_hash_id(path: str) -&gt; str\n</code></pre> <p>Returns hash based on files and their contents in path, including subfolders.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def generate_folder_hash_id(self, path: str) -&gt; str:\n    \"\"\"Returns hash based on files and their contents in path, including subfolders.\"\"\"  # noqa: E501\n    hash_obj = hashlib.md5()\n\n    for root, _dirs, files in os.walk(path):\n        for file in sorted(files):\n            file_path = os.path.join(root, file)\n            with open(file_path, \"rb\") as f:\n                while chunk := f.read(8192):\n                    hash_obj.update(chunk)\n\n    return hash_obj.hexdigest()\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.get_agent_temp_path","title":"get_agent_temp_path","text":"<pre><code>get_agent_temp_path() -&gt; Path\n</code></pre> <p>Returns temp dir for primary agent where execution happens.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def get_agent_temp_path(self) -&gt; Path:\n    \"\"\"Returns temp dir for primary agent where execution happens.\"\"\"\n    return self.get_primary_agent_temp_dir()\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.get_agents","title":"get_agents","text":"<pre><code>get_agents() -&gt; List[Agent]\n</code></pre> <p>Returns list of agents available in environment.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def get_agents(self) -&gt; List[Agent]:\n    \"\"\"Returns list of agents available in environment.\"\"\"\n    return self._agents\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.get_inference_parameters","title":"get_inference_parameters","text":"<pre><code>get_inference_parameters(\n    messages: Union[\n        Iterable[ChatCompletionMessageParam], str\n    ],\n    model: Union[Iterable[ChatCompletionMessageParam], str],\n    stream: bool,\n    **kwargs: Any,\n) -&gt; Tuple[InferenceParameters, Any]\n</code></pre> <p>Run inference parameters to run completions.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def get_inference_parameters(\n    self,\n    messages: Union[Iterable[ChatCompletionMessageParam], str],\n    model: Union[Iterable[ChatCompletionMessageParam], str],\n    stream: bool,\n    **kwargs: Any,\n) -&gt; Tuple[InferenceParameters, Any]:\n    \"\"\"Run inference parameters to run completions.\"\"\"\n    if isinstance(messages, str):\n        self.add_system_log(\n            \"Deprecated completions call. Pass `messages` as a first parameter.\",\n            logging.WARNING,\n        )\n        messages_or_model = messages\n        model_or_messages = model\n        model = cast(str, messages_or_model)\n        messages = cast(Iterable[ChatCompletionMessageParam], model_or_messages)\n    else:\n        model = cast(str, model)\n        messages = cast(Iterable[ChatCompletionMessageParam], messages)\n    model = self.get_model_for_inference(model)\n    if model != self._last_used_model:\n        self._last_used_model = model\n        self.add_system_log(f\"Connecting to {model}\")\n\n    temperature = kwargs.pop(\"temperature\", self.get_primary_agent().model_temperature if self._agents else None)\n    max_tokens = kwargs.pop(\"max_tokens\", self.get_primary_agent().model_max_tokens if self._agents else None)\n\n    params = InferenceParameters(\n        model=model,\n        messages=messages,\n        stream=stream,\n        temperature=temperature,\n        max_tokens=max_tokens,\n    )\n\n    return params, kwargs\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.get_last_message","title":"get_last_message","text":"<pre><code>get_last_message(role: str = 'user')\n</code></pre> <p>Reads last message from the given role and returns it.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def get_last_message(self, role: str = \"user\"):\n    \"\"\"Reads last message from the given role and returns it.\"\"\"\n    for message in reversed(self.list_messages()):\n        if message.get(\"role\") == role:\n            return message\n\n    return None\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.get_primary_agent","title":"get_primary_agent","text":"<pre><code>get_primary_agent() -&gt; Agent\n</code></pre> <p>Returns the agent that is invoked first.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def get_primary_agent(self) -&gt; Agent:\n    \"\"\"Returns the agent that is invoked first.\"\"\"\n    return self._agents[0]\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.get_primary_agent_temp_dir","title":"get_primary_agent_temp_dir","text":"<pre><code>get_primary_agent_temp_dir() -&gt; Path\n</code></pre> <p>Returns temp dir for primary agent.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def get_primary_agent_temp_dir(self) -&gt; Path:\n    \"\"\"Returns temp dir for primary agent.\"\"\"\n    return self.get_primary_agent().temp_dir\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.get_system_path","title":"get_system_path","text":"<pre><code>get_system_path() -&gt; Path\n</code></pre> <p>Returns the system path where chat.txt &amp; system_log are stored.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def get_system_path(self) -&gt; Path:\n    \"\"\"Returns the system path where chat.txt &amp; system_log are stored.\"\"\"\n    return Path(self._path)\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.get_tool_registry","title":"get_tool_registry","text":"<pre><code>get_tool_registry(new: bool = False) -&gt; ToolRegistry\n</code></pre> <p>Returns the tool registry, a dictionary of tools that can be called by the agent.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def get_tool_registry(self, new: bool = False) -&gt; ToolRegistry:\n    \"\"\"Returns the tool registry, a dictionary of tools that can be called by the agent.\"\"\"\n    if new:\n        self._tools = ToolRegistry()\n    return self._tools\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.list_files","title":"list_files","text":"<pre><code>list_files(\n    path: str, order: Literal[\"asc\", \"desc\"] = \"asc\"\n) -&gt; List[str]\n</code></pre> <p>Lists files in the environment.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def list_files(self, path: str, order: Literal[\"asc\", \"desc\"] = \"asc\") -&gt; List[str]:\n    \"\"\"Lists files in the environment.\"\"\"\n    return os.listdir(os.path.join(self.get_primary_agent_temp_dir(), path))\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.list_messages","title":"list_messages","text":"<pre><code>list_messages(\n    thread_id: Optional[str] = None,\n    limit: Union[int, NotGiven] = 200,\n    order: Literal[\"asc\", \"desc\"] = \"asc\",\n)\n</code></pre> <p>Backwards compatibility for chat_completions messages.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def list_messages(\n    self,\n    thread_id: Optional[str] = None,\n    limit: Union[int, NotGiven] = 200,  # api defaults to 20\n    order: Literal[\"asc\", \"desc\"] = \"asc\",\n):\n    \"\"\"Backwards compatibility for chat_completions messages.\"\"\"\n    messages = self._list_messages(thread_id=thread_id, limit=limit, order=order)\n\n    # Filter out system and agent log messages when running in debug mode. Agent behavior shouldn't change based on logs.  # noqa: E501\n    messages = [\n        m\n        for m in messages\n        if not (\n            m.metadata\n            and any(m.metadata.get(\"message_type\", \"\").startswith(prefix) for prefix in [\"system:\", \"agent:\"])\n        )\n    ]\n\n    legacy_messages = [\n        {\n            \"id\": m.id,\n            \"content\": \"\\n\".join([c.text.value for c in m.content]),  # type: ignore\n            \"role\": m.role,\n            \"attachments\": m.attachments,\n        }\n        for m in messages\n    ]\n    return legacy_messages\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.list_terminal_commands","title":"list_terminal_commands","text":"<pre><code>list_terminal_commands(\n    filename: str = TERMINAL_FILENAME,\n) -&gt; List[Any]\n</code></pre> <p>Returns the terminal commands from the terminal file.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def list_terminal_commands(self, filename: str = TERMINAL_FILENAME) -&gt; List[Any]:\n    \"\"\"Returns the terminal commands from the terminal file.\"\"\"\n    path = os.path.join(self._path, filename)\n\n    if not os.path.exists(path):\n        return []\n\n    with open(path, \"r\") as f:\n        return [json.loads(message) for message in f.read().split(DELIMITER) if message]\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.load_snapshot","title":"load_snapshot","text":"<pre><code>load_snapshot(snapshot: bytes) -&gt; None\n</code></pre> <p>Load Environment from Snapshot.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def load_snapshot(self, snapshot: bytes) -&gt; None:\n    \"\"\"Load Environment from Snapshot.\"\"\"\n    shutil.rmtree(self._path, ignore_errors=True)\n\n    with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n        f.write(snapshot)\n        f.flush()\n        f.seek(0)\n\n        with tarfile.open(fileobj=f, mode=\"r:gz\") as tar:\n            tar.extractall(self._path)\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.read_file","title":"read_file","text":"<pre><code>read_file(filename: str) -&gt; Optional[Union[bytes, str]]\n</code></pre> <p>Reads a file from the environment or thread.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def read_file(self, filename: str) -&gt; Optional[Union[bytes, str]]:\n    \"\"\"Reads a file from the environment or thread.\"\"\"\n    file_content: Optional[Union[bytes, str]] = None\n    # First try to read from local filesystem\n    local_path = os.path.join(self.get_primary_agent_temp_dir(), filename)\n    print(f\"Read file {filename} from local path: {local_path}\")\n    if os.path.exists(local_path):\n        try:\n            with open(local_path, \"rb\") as local_path_file:\n                local_file_content = local_path_file.read()\n                try:\n                    # Try to decode as text\n                    file_content = local_file_content.decode(\"utf-8\")\n                except UnicodeDecodeError:\n                    # If decoding fails, store as binary\n                    file_content = local_file_content\n        except Exception as e:\n            print(f\"Error with read_file: {e}\")\n\n    if not file_content:\n        # Next check files written out by the agent.\n        # Agent output files take precedence over files packaged with the agent\n        thread_files = self.list_files_from_thread(order=\"desc\")\n\n        # Then try to read from thread, starting from the most recent\n        for f in thread_files:\n            if f.filename == filename:\n                file_content = self.read_file_by_id(f.id)\n                break\n\n        if not file_content:\n            # Next check agent file cache\n            # Agent output files &amp; thread files take precedence over cached files\n            file_cache = self.get_primary_agent().file_cache\n            if file_cache:\n                file_content = file_cache.get(filename, None)\n\n        # Write the file content from the thread or cache to the local filesystem\n        # This allows exec_command to operate on the file\n        if file_content:\n            if not os.path.exists(os.path.dirname(local_path)):\n                os.makedirs(os.path.dirname(local_path))\n\n            with open(local_path, \"wb\") as local_file:\n                if isinstance(file_content, bytes):\n                    local_file.write(file_content)\n                else:\n                    local_file.write(file_content.encode(\"utf-8\"))\n\n    if not file_content:\n        self.add_system_log(f\"Warn: File {filename} not found during read_file operation\")\n\n    return file_content\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.run","title":"run","text":"<pre><code>run(\n    new_message: Optional[str] = None,\n    max_iterations: int = 10,\n) -&gt; None\n</code></pre> <p>Runs agent(s) against a new or previously created environment.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def run(\n    self,\n    new_message: Optional[str] = None,\n    max_iterations: int = 10,\n) -&gt; None:\n    \"\"\"Runs agent(s) against a new or previously created environment.\"\"\"\n    if new_message:\n        self._add_message(\"user\", new_message)\n\n    iteration = 0\n    self.set_next_actor(\"agent\")\n\n    while iteration &lt; max_iterations and not self.is_done() and self.get_next_actor() != \"user\":\n        iteration += 1\n        if max_iterations &gt; 1:\n            self.add_system_log(\n                f\"Running agent, iteration {iteration}/{max_iterations}\",\n                logging.INFO,\n            )\n        try:\n            error_message, traceback_message = self.get_primary_agent().run(self, task=new_message)\n            if self._debug_mode and (error_message or traceback_message):\n                if self._debug_mode and (error_message or traceback_message):\n                    message_parts = []\n\n                    if error_message:\n                        message_parts.append(f\"Error: \\n ```\\n{error_message}\\n```\")\n\n                    if traceback_message:\n                        message_parts.append(f\"Error Traceback: \\n ```\\n{traceback_message}\\n```\")\n\n                    self.add_reply(\"\\n\\n\".join(message_parts), message_type=\"system:debug\")\n\n        except Exception as e:\n            self.add_system_log(f\"Environment run failed: {e}\", logging.ERROR)\n            self.mark_failed()\n            raise e\n\n    if not self._pending_ext_agent:\n        # If no external agent was called, mark the whole run as done.\n        # Else this environment will stop for now but this run will be continued later.\n        self.mark_done()\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.set_next_actor","title":"set_next_actor","text":"<pre><code>set_next_actor(who: str) -&gt; None\n</code></pre> <p>Set the next actor / action in the dialogue.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def set_next_actor(self, who: str) -&gt; None:\n    \"\"\"Set the next actor / action in the dialogue.\"\"\"\n    next_action_fn = os.path.join(self._path, \".next_action\")\n    if who == \"agent\":\n        self._done = False\n\n    with open(next_action_fn, \"w\") as f:\n        f.write(who)\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.signed_completion","title":"signed_completion","text":"<pre><code>signed_completion(\n    messages: Union[\n        Iterable[ChatCompletionMessageParam], str\n    ],\n    model: Union[\n        Iterable[ChatCompletionMessageParam], str\n    ] = \"\",\n    **kwargs: Any,\n) -&gt; Dict[str, str]\n</code></pre> <p>Returns a completion for the given messages using the given model with the agent signature.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def signed_completion(\n    self,\n    messages: Union[Iterable[ChatCompletionMessageParam], str],\n    model: Union[Iterable[ChatCompletionMessageParam], str] = \"\",\n    **kwargs: Any,\n) -&gt; Dict[str, str]:\n    \"\"\"Returns a completion for the given messages using the given model with the agent signature.\"\"\"\n    # TODO Return signed completions for non-latest versions only?\n    agent_name = self.get_primary_agent().get_full_name()\n    raw_response = self.completions(messages, model, agent_name=agent_name, **kwargs)\n    assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n    response: ModelResponse = raw_response\n\n    signature_data = json.loads(response.system_fingerprint) if response.system_fingerprint else {}\n\n    assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n    choices: List[Choices] = response.choices  # type: ignore\n    response_message = choices[0].message.content\n    assert response_message, \"No completions returned\"\n\n    return {\n        \"response\": response_message,\n        \"signature\": signature_data.get(\"signature\", None),\n        \"public_key\": signature_data.get(\"public_key\", None),\n    }\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.verify_message","title":"verify_message","text":"<pre><code>verify_message(\n    account_id: str,\n    public_key: str,\n    signature: str,\n    message: str,\n    nonce: str,\n    callback_url: str,\n) -&gt; SignatureVerificationResult\n</code></pre> <p>Verifies that the user message is signed with NEAR Account.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def verify_message(\n    self,\n    account_id: str,\n    public_key: str,\n    signature: str,\n    message: str,\n    nonce: str,\n    callback_url: str,\n) -&gt; near.SignatureVerificationResult:\n    \"\"\"Verifies that the user message is signed with NEAR Account.\"\"\"\n    return near.verify_signed_message(\n        account_id,\n        public_key,\n        signature,\n        message,\n        nonce,\n        self.get_primary_agent().name,\n        callback_url,\n    )\n</code></pre>"},{"location":"api/#nearai.agents.environment.Environment.verify_signed_message","title":"verify_signed_message","text":"<pre><code>verify_signed_message(\n    completion: str,\n    messages: Union[\n        Iterable[ChatCompletionMessageParam], str\n    ],\n    public_key: Union[str, None] = None,\n    signature: Union[str, None] = None,\n    model: Union[\n        Iterable[ChatCompletionMessageParam], str\n    ] = \"\",\n    **kwargs: Any,\n) -&gt; bool\n</code></pre> <p>Verifies a signed message.</p> Source code in <code>nearai/agents/environment.py</code> <pre><code>def verify_signed_message(\n    self,\n    completion: str,\n    messages: Union[Iterable[ChatCompletionMessageParam], str],\n    public_key: Union[str, None] = None,\n    signature: Union[str, None] = None,\n    model: Union[Iterable[ChatCompletionMessageParam], str] = \"\",\n    **kwargs: Any,\n) -&gt; bool:\n    \"\"\"Verifies a signed message.\"\"\"\n    if public_key is None or signature is None:\n        return False\n\n    params, _ = self.get_inference_parameters(messages, model, False, **kwargs)\n\n    messages_without_ids = [{k: v for k, v in item.items() if k != \"id\"} for item in params.messages]\n    ordered_messages_without_ids = [\n        {\"role\": str(item[\"role\"]), \"content\": str(item[\"content\"])} for item in messages_without_ids\n    ]\n\n    return validate_completion_signature(\n        public_key,\n        signature,\n        CompletionSignaturePayload(\n            agent_name=self.get_primary_agent().get_full_name(),\n            completion=completion,\n            model=params.model,\n            messages=ordered_messages_without_ids,\n            temperature=params.temperature,\n            max_tokens=params.max_tokens,\n        ),\n    )\n</code></pre>"},{"location":"api/#nearai.agents.tool_json_helper","title":"tool_json_helper","text":""},{"location":"api/#nearai.agents.tool_json_helper.parse_json_args","title":"parse_json_args","text":"<pre><code>parse_json_args(signature: dict, args: str)\n</code></pre> <p>Parses LLM generated JSON args, trying various repair strategies if args are not valid JSON.</p> Source code in <code>nearai/agents/tool_json_helper.py</code> <pre><code>def parse_json_args(signature: dict, args: str):\n    \"\"\"Parses LLM generated JSON args, trying various repair strategies if args are not valid JSON.\"\"\"\n    # if args is empty or an empty json object check if the function has no arguments\n    if not args or args == \"{}\":\n        if not signature[\"function\"][\"parameters\"][\"required\"]:\n            return {}\n        else:\n            raise ValueError(\"Function requires arguments\")\n\n    transforms = [\n        lambda x: json.loads(x),\n        _ending_transform,\n        lambda x: parse_json_args_based_on_signature(signature, x),\n    ]\n\n    for transform in transforms:\n        try:\n            result = transform(args)\n            # check that all result keys are valid properties in the signature\n            for key in result.keys():\n                if key not in signature[\"function\"][\"parameters\"][\"properties\"]:\n                    raise json.JSONDecodeError(f\"Unknown parameter {key}\", args, 0)\n            return result\n        except json.JSONDecodeError:\n            continue\n        except Exception as err:\n            raise json.JSONDecodeError(\"Error parsing function args\", args, 0) from err\n</code></pre>"},{"location":"api/#nearai.agents.tool_json_helper.parse_json_args_based_on_signature","title":"parse_json_args_based_on_signature","text":"<pre><code>parse_json_args_based_on_signature(\n    signature: dict, args: str\n)\n</code></pre> <p>Finds parameter names based on the signature and tries to extract the values in between from the args string.</p> Source code in <code>nearai/agents/tool_json_helper.py</code> <pre><code>def parse_json_args_based_on_signature(signature: dict, args: str):\n    \"\"\"Finds parameter names based on the signature and tries to extract the values in between from the args string.\"\"\"\n    parameter_names = list(signature[\"function\"][\"parameters\"][\"properties\"].keys())\n    # find each parameter name in the args string\n    #   assuming each parameter name is surrounded by \"s, followed by a colon and optionally preceded by a comma,\n    #   extract the intervening values as values\n    parameter_positions = {}\n    parameter_values = {}\n    for param in parameter_names:\n        match = re.search(f',?\\\\s*\"({param})\"\\\\s*:', args)\n        if not match:\n            raise ValueError(f\"Parameter {param} not found in args {args}\")\n        parameter_positions[param] = (match.start(), match.end())\n    # sort the parameter positions by start position\n    sorted_positions = sorted(parameter_positions.items(), key=lambda x: x[1][0])\n    # for each parameter, extract the value from the args string\n    for i, (param, (start, end)) in enumerate(sorted_positions):  # noqa B007\n        # if this is the last parameter, extract the value from the start position to the end of the string\n        if i == len(sorted_positions) - 1:\n            raw_value = args[end:-1]\n            if raw_value.endswith(\"}\"):\n                raw_value = raw_value[:-1]\n        # otherwise, extract the value from the start position to the start position of the next parameter\n        else:\n            next_start = sorted_positions[i + 1][1][0]\n            raw_value = args[end:next_start]\n        raw_value = raw_value.strip()\n        if raw_value.startswith('\"') and raw_value.endswith('\"'):\n            raw_value = raw_value[1:-1]\n        parameter_values[param] = raw_value\n    return parameter_values\n</code></pre>"},{"location":"api/#nearai.agents.tool_registry","title":"tool_registry","text":""},{"location":"api/#nearai.agents.tool_registry.ToolRegistry","title":"ToolRegistry","text":"<p>A registry for tools that can be called by the agent.</p> <p>Tool definitions follow this structure:</p> <pre><code>{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n                },\n                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n            },\n            \"required\": [\"location\"],\n        },\n    },\n}\n</code></pre> Source code in <code>nearai/agents/tool_registry.py</code> <pre><code>class ToolRegistry:\n    \"\"\"A registry for tools that can be called by the agent.\n\n    Tool definitions follow this structure:\n\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"get_current_weather\",\n                \"description\": \"Get the current weather in a given location\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"location\": {\n                            \"type\": \"string\",\n                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n                        },\n                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n                    },\n                    \"required\": [\"location\"],\n                },\n            },\n        }\n\n    \"\"\"\n\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.tools: Dict[str, Callable] = {}\n\n    def register_tool(self, tool: Callable) -&gt; None:  # noqa: D102\n        \"\"\"Register a tool.\"\"\"\n        self.tools[tool.__name__] = tool\n\n    def register_mcp_tool(self, mcp_tool: MCPTool, call_tool: Callable) -&gt; None:  # noqa: D102\n        \"\"\"Register a tool callable from its definition.\"\"\"\n\n        async def tool(**kwargs):\n            try:\n                return await call_tool(mcp_tool.name, kwargs)\n            except Exception as e:\n                raise Exception(f\"Error calling tool {mcp_tool.name} with arguments {kwargs}: {e}\") from e\n\n        tool.__name__ = mcp_tool.name\n        tool.__doc__ = mcp_tool.description\n        tool.__setattr__(\"__schema__\", mcp_tool.inputSchema)\n\n        self.tools[mcp_tool.name] = tool\n\n    def get_tool(self, name: str) -&gt; Optional[Callable]:  # noqa: D102\n        \"\"\"Get a tool by name.\"\"\"\n        return self.tools.get(name)\n\n    def get_all_tools(self) -&gt; Dict[str, Callable]:  # noqa: D102\n        \"\"\"Get all tools.\"\"\"\n        return self.tools\n\n    def call_tool(self, name: str, **kwargs: Any) -&gt; Any:  # noqa: D102\n        \"\"\"Call a tool by name.\"\"\"\n        tool = self.get_tool(name)\n        if tool is None:\n            raise ValueError(f\"Tool '{name}' not found.\")\n        return tool(**kwargs)\n\n    def get_tool_definition(self, name: str) -&gt; Optional[Dict]:  # noqa: D102\n        \"\"\"Get the definition of a tool by name.\"\"\"\n        tool = self.get_tool(name)\n        if tool is None:\n            return None\n\n        assert tool.__doc__ is not None, f\"Docstring missing for tool '{name}'.\"\n        docstring = tool.__doc__.strip().split(\"\\n\")\n\n        # The first line of the docstring is the function description\n        function_description = docstring[0].strip()\n\n        # The rest of the lines contain parameter descriptions\n        param_descriptions = docstring[1:]\n\n        # Extract parameter names and types\n        signature = inspect.signature(tool)\n        type_hints = get_type_hints(tool)\n\n        parameters: Dict[str, Any] = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n\n        if hasattr(tool, \"__schema__\"):\n            return {\n                \"type\": \"function\",\n                \"function\": {\"name\": tool.__name__, \"description\": function_description, \"parameters\": tool.__schema__},\n            }\n\n        # Iterate through function parameters\n        for param in signature.parameters.values():\n            param_name = param.name\n            param_type = type_hints.get(param_name, str)  # Default to str if type hint is missing\n            param_description = \"\"\n\n            # Find the parameter description in the docstring\n            for line in param_descriptions:\n                if line.strip().startswith(param_name):\n                    param_description = line.strip().split(\":\", 1)[1].strip()\n                    break\n\n            # Convert type hint to JSON Schema type\n            if isinstance(param_type, _GenericAlias) and param_type.__origin__ is Literal:\n                json_type = \"string\"\n            else:\n                json_type = param_type.__name__.lower()\n\n            if json_type == \"union\":\n                json_type = [t.__name__.lower() for t in param_type.__args__][0]\n\n            json_type = {\"int\": \"integer\", \"float\": \"number\", \"str\": \"string\", \"bool\": \"boolean\"}.get(\n                json_type, \"string\"\n            )\n\n            # Add parameter to the definition\n            parameters[\"properties\"][param_name] = {\"description\": param_description, \"type\": json_type}\n\n            # Params without default values are required params\n            if param.default == inspect.Parameter.empty:\n                parameters[\"required\"].append(param_name)\n\n        return {\n            \"type\": \"function\",\n            \"function\": {\"name\": tool.__name__, \"description\": function_description, \"parameters\": parameters},\n        }\n\n    def get_all_tool_definitions(self) -&gt; list[Dict]:  # noqa: D102\n        definitions = []\n        for tool_name, _tool in self.tools.items():\n            definition = self.get_tool_definition(tool_name)\n            if definition is not None:\n                definitions.append(definition)\n        return definitions\n</code></pre>"},{"location":"api/#nearai.agents.tool_registry.ToolRegistry.call_tool","title":"call_tool","text":"<pre><code>call_tool(name: str, **kwargs: Any) -&gt; Any\n</code></pre> <p>Call a tool by name.</p> Source code in <code>nearai/agents/tool_registry.py</code> <pre><code>def call_tool(self, name: str, **kwargs: Any) -&gt; Any:  # noqa: D102\n    \"\"\"Call a tool by name.\"\"\"\n    tool = self.get_tool(name)\n    if tool is None:\n        raise ValueError(f\"Tool '{name}' not found.\")\n    return tool(**kwargs)\n</code></pre>"},{"location":"api/#nearai.agents.tool_registry.ToolRegistry.get_all_tools","title":"get_all_tools","text":"<pre><code>get_all_tools() -&gt; Dict[str, Callable]\n</code></pre> <p>Get all tools.</p> Source code in <code>nearai/agents/tool_registry.py</code> <pre><code>def get_all_tools(self) -&gt; Dict[str, Callable]:  # noqa: D102\n    \"\"\"Get all tools.\"\"\"\n    return self.tools\n</code></pre>"},{"location":"api/#nearai.agents.tool_registry.ToolRegistry.get_tool","title":"get_tool","text":"<pre><code>get_tool(name: str) -&gt; Optional[Callable]\n</code></pre> <p>Get a tool by name.</p> Source code in <code>nearai/agents/tool_registry.py</code> <pre><code>def get_tool(self, name: str) -&gt; Optional[Callable]:  # noqa: D102\n    \"\"\"Get a tool by name.\"\"\"\n    return self.tools.get(name)\n</code></pre>"},{"location":"api/#nearai.agents.tool_registry.ToolRegistry.get_tool_definition","title":"get_tool_definition","text":"<pre><code>get_tool_definition(name: str) -&gt; Optional[Dict]\n</code></pre> <p>Get the definition of a tool by name.</p> Source code in <code>nearai/agents/tool_registry.py</code> <pre><code>def get_tool_definition(self, name: str) -&gt; Optional[Dict]:  # noqa: D102\n    \"\"\"Get the definition of a tool by name.\"\"\"\n    tool = self.get_tool(name)\n    if tool is None:\n        return None\n\n    assert tool.__doc__ is not None, f\"Docstring missing for tool '{name}'.\"\n    docstring = tool.__doc__.strip().split(\"\\n\")\n\n    # The first line of the docstring is the function description\n    function_description = docstring[0].strip()\n\n    # The rest of the lines contain parameter descriptions\n    param_descriptions = docstring[1:]\n\n    # Extract parameter names and types\n    signature = inspect.signature(tool)\n    type_hints = get_type_hints(tool)\n\n    parameters: Dict[str, Any] = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n\n    if hasattr(tool, \"__schema__\"):\n        return {\n            \"type\": \"function\",\n            \"function\": {\"name\": tool.__name__, \"description\": function_description, \"parameters\": tool.__schema__},\n        }\n\n    # Iterate through function parameters\n    for param in signature.parameters.values():\n        param_name = param.name\n        param_type = type_hints.get(param_name, str)  # Default to str if type hint is missing\n        param_description = \"\"\n\n        # Find the parameter description in the docstring\n        for line in param_descriptions:\n            if line.strip().startswith(param_name):\n                param_description = line.strip().split(\":\", 1)[1].strip()\n                break\n\n        # Convert type hint to JSON Schema type\n        if isinstance(param_type, _GenericAlias) and param_type.__origin__ is Literal:\n            json_type = \"string\"\n        else:\n            json_type = param_type.__name__.lower()\n\n        if json_type == \"union\":\n            json_type = [t.__name__.lower() for t in param_type.__args__][0]\n\n        json_type = {\"int\": \"integer\", \"float\": \"number\", \"str\": \"string\", \"bool\": \"boolean\"}.get(\n            json_type, \"string\"\n        )\n\n        # Add parameter to the definition\n        parameters[\"properties\"][param_name] = {\"description\": param_description, \"type\": json_type}\n\n        # Params without default values are required params\n        if param.default == inspect.Parameter.empty:\n            parameters[\"required\"].append(param_name)\n\n    return {\n        \"type\": \"function\",\n        \"function\": {\"name\": tool.__name__, \"description\": function_description, \"parameters\": parameters},\n    }\n</code></pre>"},{"location":"api/#nearai.agents.tool_registry.ToolRegistry.register_mcp_tool","title":"register_mcp_tool","text":"<pre><code>register_mcp_tool(\n    mcp_tool: MCPTool, call_tool: Callable\n) -&gt; None\n</code></pre> <p>Register a tool callable from its definition.</p> Source code in <code>nearai/agents/tool_registry.py</code> <pre><code>def register_mcp_tool(self, mcp_tool: MCPTool, call_tool: Callable) -&gt; None:  # noqa: D102\n    \"\"\"Register a tool callable from its definition.\"\"\"\n\n    async def tool(**kwargs):\n        try:\n            return await call_tool(mcp_tool.name, kwargs)\n        except Exception as e:\n            raise Exception(f\"Error calling tool {mcp_tool.name} with arguments {kwargs}: {e}\") from e\n\n    tool.__name__ = mcp_tool.name\n    tool.__doc__ = mcp_tool.description\n    tool.__setattr__(\"__schema__\", mcp_tool.inputSchema)\n\n    self.tools[mcp_tool.name] = tool\n</code></pre>"},{"location":"api/#nearai.agents.tool_registry.ToolRegistry.register_tool","title":"register_tool","text":"<pre><code>register_tool(tool: Callable) -&gt; None\n</code></pre> <p>Register a tool.</p> Source code in <code>nearai/agents/tool_registry.py</code> <pre><code>def register_tool(self, tool: Callable) -&gt; None:  # noqa: D102\n    \"\"\"Register a tool.\"\"\"\n    self.tools[tool.__name__] = tool\n</code></pre>"},{"location":"api/#nearai.cli","title":"cli","text":""},{"location":"api/#nearai.cli.AgentCli","title":"AgentCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class AgentCli:\n    def dev(self) -&gt; int:\n        \"\"\"Run local UI for development of agents that have their own UI.\"\"\"\n        if not os.path.exists(\"hub/demo/.env\"):\n            shutil.copy(\"hub/demo/.env.example\", \"hub/demo/.env\")\n\n        ret_val = os.system(\"npm install --prefix hub/demo\")\n        if ret_val != 0:\n            print(\"Node.js is required to run the development server.\")\n            print(\"Please install Node.js from https://nodejs.org/\")\n        ret_val = os.system(\"npm run dev --prefix hub/demo\")\n        return ret_val\n\n    def inspect(self, path: str) -&gt; None:\n        \"\"\"Inspect environment from given path.\"\"\"\n        import subprocess\n\n        filename = Path(os.path.abspath(__file__)).parent / \"streamlit_inspect.py\"\n        subprocess.call([\"streamlit\", \"run\", filename, \"--\", path])\n\n    def interactive(\n        self,\n        agent: Optional[str] = None,\n        thread_id: Optional[str] = None,\n        tool_resources: Optional[Dict[str, Any]] = None,\n        local: bool = False,\n        verbose: bool = False,\n        env_vars: Optional[Dict[str, Any]] = None,\n    ) -&gt; None:\n        \"\"\"Runs agent interactively.\n\n        Args:\n        ----\n            agent: Optional path to the agent directory. If not provided, will show agent selection menu\n            thread_id: Optional thread ID to continue an existing conversation\n            tool_resources: Optional tool resources to pass to the agent\n            local: Whether to run the agent locally (default: False)\n            verbose: Whether to show detailed debug information during execution\n            env_vars: Optional environment variables to pass to the agent\n\n        \"\"\"\n        assert_user_auth()\n\n        if agent is None:\n            local = True\n            # List available agents in the registry folder\n            registry_path = Path(get_registry_folder())\n            if not registry_path.exists():\n                print(\"Error: Registry folder not found. Please create an agent first.\")\n                return\n\n            agents = []\n            # Walk through registry to find agents\n            for namespace in registry_path.iterdir():\n                if namespace.is_dir():\n                    for agent_name in namespace.iterdir():\n                        if agent_name.is_dir():\n                            for version in agent_name.iterdir():\n                                if version.is_dir():\n                                    agents.append(version)\n\n            if not agents:\n                print(\"No agents found. Please create an agent first with 'nearai agent create'\")\n                return\n\n            # Sort agents by namespace then name\n            agents = sorted(agents, key=lambda x: (x.parts[-3], x.parts[-2]))\n            display_agents_in_columns(agents)\n\n            while True:\n                try:\n                    choice = int(Prompt.ask(\"[blue bold]Select an agent (enter number)\")) - 1\n                    if 0 &lt;= choice &lt; len(agents):\n                        agent = str(agents[choice])\n                        break\n                    print(\"Invalid selection. Please try again.\")\n                except ValueError:\n                    print(\"Please enter a valid number.\")\n                except KeyboardInterrupt:\n                    print(\"\\nOperation cancelled.\")\n                    return\n\n        # Convert agent path to Path object if it's a string\n        agent_path = Path(agent)\n        if local:\n            agent_path = resolve_local_path(agent_path)\n        else:\n            try:\n                parse_location(str(agent_path))\n            except Exception:\n                print(\n                    f'Registry entry format is &lt;namespace&gt;/&lt;name&gt;/&lt;version&gt;, but \"{agent_path}\" was provided. Did you mean to run with a flag --local?'  # noqa: E501\n                )\n                exit(1)\n\n        agent_id = get_agent_id(agent_path, local)\n\n        last_message_id = None\n        print(f\"\\n=== Starting interactive session with agent: {agent_id} ===\")\n        print(\"\")\n        print(\"Type 'exit' to end the session\")\n        print(\"Type 'multiline' to enter multiline mode\")\n        print(\"\")\n\n        metadata = get_metadata(agent_path, local)\n        title = metadata.get(\"details\", {}).get(\"agent\", {}).get(\"welcome\", {}).get(\"title\")\n        if title:\n            print(title)\n        description = metadata.get(\"details\", {}).get(\"agent\", {}).get(\"welcome\", {}).get(\"description\")\n        if description:\n            print(description)\n\n        multiline = False\n\n        def print_multiline_prompt():\n            print(\"On Linux/macOS: To submit, press Ctrl+D at the beginning of a new line after your prompt\")\n            print(\"On Windows: Press Ctrl+Z followed by Enter\")\n\n        while True:\n            first_line = input(\"&gt; \")\n            if first_line.lower() == \"exit\":\n                break\n            if not multiline and first_line.lower() == \"multiline\":\n                multiline = True\n                print_multiline_prompt()\n                continue\n            lines = [first_line]\n\n            # NOTE: the code below tries to catch copy-paste by calling has_pending_input().\n            # This is OS-specific functionality and has been tested on Unix/Linux/Mac:\n            # 1. Works well with blocks of text of 3 lines and more.\n            # 2. Alas, does not trigger with text of 2 lines or less.\n            pending_input_on_this_line = has_pending_input()\n            if multiline or pending_input_on_this_line:\n                try:\n                    pending_input_on_prev_line = pending_input_on_this_line\n                    while True:\n                        pending_input_on_this_line = has_pending_input()\n                        if pending_input_on_prev_line or pending_input_on_this_line:\n                            line = input(\"\")\n                        else:\n                            if not multiline:\n                                multiline = True\n                                print_multiline_prompt()\n                            line = input(\"&gt; \")\n                        lines.append(line)\n                        pending_input_on_prev_line = pending_input_on_this_line\n                except EOFError:\n                    print(\"\")\n\n            new_message = \"\\n\".join(lines)\n\n            last_message_id = self._task(\n                agent=agent_id,\n                task=new_message,\n                thread_id=thread_id,\n                tool_resources=tool_resources,\n                last_message_id=last_message_id,\n                local_path=agent_path if local else None,\n                verbose=verbose,\n                env_vars=env_vars,\n            )\n\n            # Update thread_id for the next iteration\n            if thread_id is None:\n                thread_id = self.last_thread_id\n\n    def task(\n        self,\n        agent: str,\n        task: str,\n        thread_id: Optional[str] = None,\n        tool_resources: Optional[Dict[str, Any]] = None,\n        file_ids: Optional[List[str]] = None,\n        local: bool = False,\n        verbose: bool = False,\n        env_vars: Optional[Dict[str, Any]] = None,\n    ) -&gt; None:\n        \"\"\"CLI wrapper for the _task method.\"\"\"\n        last_message_id = self._task(\n            agent=agent,\n            task=task,\n            thread_id=thread_id,\n            tool_resources=tool_resources,\n            file_ids=file_ids,\n            local_path=resolve_local_path(Path(agent)) if local else None,\n            verbose=verbose,\n            env_vars=env_vars,\n        )\n        if last_message_id:\n            print(f\"Task completed. Thread ID: {self.last_thread_id}\")\n            print(f\"Last message ID: {last_message_id}\")\n\n    def _task(\n        self,\n        agent: str,\n        task: str,\n        thread_id: Optional[str] = None,\n        tool_resources: Optional[Dict[str, Any]] = None,\n        file_ids: Optional[List[str]] = None,\n        last_message_id: Optional[str] = None,\n        local_path: Optional[Path] = None,\n        verbose: bool = False,\n        env_vars: Optional[Dict[str, Any]] = None,\n    ) -&gt; Optional[str]:\n        \"\"\"Runs agent non-interactively with a single task.\"\"\"\n        assert_user_auth()\n\n        hub_client = get_hub_client()\n        if thread_id:\n            thread = hub_client.beta.threads.retrieve(thread_id)\n        else:\n            thread = hub_client.beta.threads.create(\n                tool_resources=tool_resources,\n            )\n\n        hub_client.beta.threads.messages.create(\n            thread_id=thread.id,\n            role=\"user\",\n            content=task,\n            attachments=[Attachment(file_id=file_id) for file_id in file_ids] if file_ids else None,\n        )\n\n        if not local_path:\n            hub_client.beta.threads.runs.create_and_poll(\n                thread_id=thread.id,\n                assistant_id=agent,\n            )\n        else:\n            run = hub_client.beta.threads.runs.create(\n                thread_id=thread.id,\n                assistant_id=agent,\n                extra_body={\"delegate_execution\": True},\n            )\n            params = {\n                \"api_url\": CONFIG.api_url,\n                \"tool_resources\": run.tools,\n                \"data_source\": \"local_files\",\n                \"user_env_vars\": env_vars,\n                \"agent_env_vars\": {},\n                \"verbose\": verbose,\n            }\n            auth = CONFIG.auth\n            assert auth is not None\n            LocalRunner(str(local_path), agent, thread.id, run.id, auth, params)\n\n        # List new messages\n        messages = hub_client.beta.threads.messages.list(thread_id=thread.id, after=last_message_id, order=\"asc\")\n        message_list = list(messages)\n        if message_list:\n            for msg in message_list:\n                if msg.metadata and msg.metadata.get(\"message_type\"):\n                    continue\n                if msg.role == \"assistant\":\n                    print(f\"Assistant: {msg.content[0].text.value}\")\n            last_message_id = message_list[-1].id\n        else:\n            print(\"No new messages\")\n\n        # Store the thread_id for potential use in interactive mode\n        self.last_thread_id = thread.id\n\n        return last_message_id\n\n    def create(self, name: Optional[str] = None, description: Optional[str] = None, fork: Optional[str] = None) -&gt; None:\n        \"\"\"Create a new agent or fork an existing one.\n\n        Usage:\n          nearai agent create  # Enters interactive mode\n          nearai agent create --name &lt;agent_name&gt; --description &lt;description&gt;\n          nearai agent create --fork &lt;namespace/agent_name/version&gt; [--name &lt;new_agent_name&gt;]\n\n        Options:\n          --name          Name of the new agent (optional).\n          --description   Description of the new agent (optional).\n          --fork          Fork an existing agent specified by namespace/agent_name/version.\n\n        Examples\n        --------\n          nearai agent create   # Enters interactive mode\n          nearai agent create --name my_agent --description \"My new agent\"\n          nearai agent create --fork agentic.near/summary/0.0.3 --name new_summary_agent\n\n        \"\"\"\n        # Check if the user is authenticated\n        if CONFIG.auth is None or CONFIG.auth.namespace is None:\n            print(\"Please login with `nearai login` before creating an agent.\")\n            return\n\n        namespace = CONFIG.auth.namespace\n\n        # Import the agent creator functions\n        from nearai.agent_creator import create_new_agent, fork_agent\n\n        if fork:\n            # Fork an existing agent\n            fork_agent(fork, namespace, name)\n        else:\n            # Create a new agent from scratch\n            create_new_agent(namespace, name, description)\n\n    def upload(\n        self, local_path: str = \".\", bump: bool = False, minor_bump: bool = False, major_bump: bool = False\n    ) -&gt; Optional[EntryLocation]:\n        \"\"\"Upload agent to the registry.\n\n        This is an alias for 'nearai registry upload'.\n\n        Args:\n        ----\n            local_path: Path to the directory containing the agent to upload\n            bump: If True, automatically increment patch version if it already exists\n            minor_bump: If True, bump with minor version increment (0.1.0 \u2192 0.2.0)\n            major_bump: If True, bump with major version increment (0.1.0 \u2192 1.0.0)\n\n        Returns:\n        -------\n            EntryLocation if upload was successful, None otherwise\n\n        \"\"\"\n        assert_user_auth()\n        # Create an instance of RegistryCli and call its upload method\n        registry_cli = RegistryCli()\n        return registry_cli.upload(local_path, bump, minor_bump, major_bump)\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli._task","title":"_task","text":"<pre><code>_task(\n    agent: str,\n    task: str,\n    thread_id: Optional[str] = None,\n    tool_resources: Optional[Dict[str, Any]] = None,\n    file_ids: Optional[List[str]] = None,\n    last_message_id: Optional[str] = None,\n    local_path: Optional[Path] = None,\n    verbose: bool = False,\n    env_vars: Optional[Dict[str, Any]] = None,\n) -&gt; Optional[str]\n</code></pre> <p>Runs agent non-interactively with a single task.</p> Source code in <code>nearai/cli.py</code> <pre><code>def _task(\n    self,\n    agent: str,\n    task: str,\n    thread_id: Optional[str] = None,\n    tool_resources: Optional[Dict[str, Any]] = None,\n    file_ids: Optional[List[str]] = None,\n    last_message_id: Optional[str] = None,\n    local_path: Optional[Path] = None,\n    verbose: bool = False,\n    env_vars: Optional[Dict[str, Any]] = None,\n) -&gt; Optional[str]:\n    \"\"\"Runs agent non-interactively with a single task.\"\"\"\n    assert_user_auth()\n\n    hub_client = get_hub_client()\n    if thread_id:\n        thread = hub_client.beta.threads.retrieve(thread_id)\n    else:\n        thread = hub_client.beta.threads.create(\n            tool_resources=tool_resources,\n        )\n\n    hub_client.beta.threads.messages.create(\n        thread_id=thread.id,\n        role=\"user\",\n        content=task,\n        attachments=[Attachment(file_id=file_id) for file_id in file_ids] if file_ids else None,\n    )\n\n    if not local_path:\n        hub_client.beta.threads.runs.create_and_poll(\n            thread_id=thread.id,\n            assistant_id=agent,\n        )\n    else:\n        run = hub_client.beta.threads.runs.create(\n            thread_id=thread.id,\n            assistant_id=agent,\n            extra_body={\"delegate_execution\": True},\n        )\n        params = {\n            \"api_url\": CONFIG.api_url,\n            \"tool_resources\": run.tools,\n            \"data_source\": \"local_files\",\n            \"user_env_vars\": env_vars,\n            \"agent_env_vars\": {},\n            \"verbose\": verbose,\n        }\n        auth = CONFIG.auth\n        assert auth is not None\n        LocalRunner(str(local_path), agent, thread.id, run.id, auth, params)\n\n    # List new messages\n    messages = hub_client.beta.threads.messages.list(thread_id=thread.id, after=last_message_id, order=\"asc\")\n    message_list = list(messages)\n    if message_list:\n        for msg in message_list:\n            if msg.metadata and msg.metadata.get(\"message_type\"):\n                continue\n            if msg.role == \"assistant\":\n                print(f\"Assistant: {msg.content[0].text.value}\")\n        last_message_id = message_list[-1].id\n    else:\n        print(\"No new messages\")\n\n    # Store the thread_id for potential use in interactive mode\n    self.last_thread_id = thread.id\n\n    return last_message_id\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.create","title":"create","text":"<pre><code>create(\n    name: Optional[str] = None,\n    description: Optional[str] = None,\n    fork: Optional[str] = None,\n) -&gt; None\n</code></pre> <p>Create a new agent or fork an existing one.</p> Usage <p>nearai agent create  # Enters interactive mode nearai agent create --name  --description  nearai agent create --fork  [--name ] Options <p>--name          Name of the new agent (optional). --description   Description of the new agent (optional). --fork          Fork an existing agent specified by namespace/agent_name/version.</p>"},{"location":"api/#nearai.cli.AgentCli.create--examples","title":"Examples","text":"<p>nearai agent create   # Enters interactive mode   nearai agent create --name my_agent --description \"My new agent\"   nearai agent create --fork agentic.near/summary/0.0.3 --name new_summary_agent</p> Source code in <code>nearai/cli.py</code> <pre><code>def create(self, name: Optional[str] = None, description: Optional[str] = None, fork: Optional[str] = None) -&gt; None:\n    \"\"\"Create a new agent or fork an existing one.\n\n    Usage:\n      nearai agent create  # Enters interactive mode\n      nearai agent create --name &lt;agent_name&gt; --description &lt;description&gt;\n      nearai agent create --fork &lt;namespace/agent_name/version&gt; [--name &lt;new_agent_name&gt;]\n\n    Options:\n      --name          Name of the new agent (optional).\n      --description   Description of the new agent (optional).\n      --fork          Fork an existing agent specified by namespace/agent_name/version.\n\n    Examples\n    --------\n      nearai agent create   # Enters interactive mode\n      nearai agent create --name my_agent --description \"My new agent\"\n      nearai agent create --fork agentic.near/summary/0.0.3 --name new_summary_agent\n\n    \"\"\"\n    # Check if the user is authenticated\n    if CONFIG.auth is None or CONFIG.auth.namespace is None:\n        print(\"Please login with `nearai login` before creating an agent.\")\n        return\n\n    namespace = CONFIG.auth.namespace\n\n    # Import the agent creator functions\n    from nearai.agent_creator import create_new_agent, fork_agent\n\n    if fork:\n        # Fork an existing agent\n        fork_agent(fork, namespace, name)\n    else:\n        # Create a new agent from scratch\n        create_new_agent(namespace, name, description)\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.dev","title":"dev","text":"<pre><code>dev() -&gt; int\n</code></pre> <p>Run local UI for development of agents that have their own UI.</p> Source code in <code>nearai/cli.py</code> <pre><code>def dev(self) -&gt; int:\n    \"\"\"Run local UI for development of agents that have their own UI.\"\"\"\n    if not os.path.exists(\"hub/demo/.env\"):\n        shutil.copy(\"hub/demo/.env.example\", \"hub/demo/.env\")\n\n    ret_val = os.system(\"npm install --prefix hub/demo\")\n    if ret_val != 0:\n        print(\"Node.js is required to run the development server.\")\n        print(\"Please install Node.js from https://nodejs.org/\")\n    ret_val = os.system(\"npm run dev --prefix hub/demo\")\n    return ret_val\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.inspect","title":"inspect","text":"<pre><code>inspect(path: str) -&gt; None\n</code></pre> <p>Inspect environment from given path.</p> Source code in <code>nearai/cli.py</code> <pre><code>def inspect(self, path: str) -&gt; None:\n    \"\"\"Inspect environment from given path.\"\"\"\n    import subprocess\n\n    filename = Path(os.path.abspath(__file__)).parent / \"streamlit_inspect.py\"\n    subprocess.call([\"streamlit\", \"run\", filename, \"--\", path])\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.interactive","title":"interactive","text":"<pre><code>interactive(\n    agent: Optional[str] = None,\n    thread_id: Optional[str] = None,\n    tool_resources: Optional[Dict[str, Any]] = None,\n    local: bool = False,\n    verbose: bool = False,\n    env_vars: Optional[Dict[str, Any]] = None,\n) -&gt; None\n</code></pre> <p>Runs agent interactively.</p> <pre><code>agent: Optional path to the agent directory. If not provided, will show agent selection menu\nthread_id: Optional thread ID to continue an existing conversation\ntool_resources: Optional tool resources to pass to the agent\nlocal: Whether to run the agent locally (default: False)\nverbose: Whether to show detailed debug information during execution\nenv_vars: Optional environment variables to pass to the agent\n</code></pre> Source code in <code>nearai/cli.py</code> <pre><code>def interactive(\n    self,\n    agent: Optional[str] = None,\n    thread_id: Optional[str] = None,\n    tool_resources: Optional[Dict[str, Any]] = None,\n    local: bool = False,\n    verbose: bool = False,\n    env_vars: Optional[Dict[str, Any]] = None,\n) -&gt; None:\n    \"\"\"Runs agent interactively.\n\n    Args:\n    ----\n        agent: Optional path to the agent directory. If not provided, will show agent selection menu\n        thread_id: Optional thread ID to continue an existing conversation\n        tool_resources: Optional tool resources to pass to the agent\n        local: Whether to run the agent locally (default: False)\n        verbose: Whether to show detailed debug information during execution\n        env_vars: Optional environment variables to pass to the agent\n\n    \"\"\"\n    assert_user_auth()\n\n    if agent is None:\n        local = True\n        # List available agents in the registry folder\n        registry_path = Path(get_registry_folder())\n        if not registry_path.exists():\n            print(\"Error: Registry folder not found. Please create an agent first.\")\n            return\n\n        agents = []\n        # Walk through registry to find agents\n        for namespace in registry_path.iterdir():\n            if namespace.is_dir():\n                for agent_name in namespace.iterdir():\n                    if agent_name.is_dir():\n                        for version in agent_name.iterdir():\n                            if version.is_dir():\n                                agents.append(version)\n\n        if not agents:\n            print(\"No agents found. Please create an agent first with 'nearai agent create'\")\n            return\n\n        # Sort agents by namespace then name\n        agents = sorted(agents, key=lambda x: (x.parts[-3], x.parts[-2]))\n        display_agents_in_columns(agents)\n\n        while True:\n            try:\n                choice = int(Prompt.ask(\"[blue bold]Select an agent (enter number)\")) - 1\n                if 0 &lt;= choice &lt; len(agents):\n                    agent = str(agents[choice])\n                    break\n                print(\"Invalid selection. Please try again.\")\n            except ValueError:\n                print(\"Please enter a valid number.\")\n            except KeyboardInterrupt:\n                print(\"\\nOperation cancelled.\")\n                return\n\n    # Convert agent path to Path object if it's a string\n    agent_path = Path(agent)\n    if local:\n        agent_path = resolve_local_path(agent_path)\n    else:\n        try:\n            parse_location(str(agent_path))\n        except Exception:\n            print(\n                f'Registry entry format is &lt;namespace&gt;/&lt;name&gt;/&lt;version&gt;, but \"{agent_path}\" was provided. Did you mean to run with a flag --local?'  # noqa: E501\n            )\n            exit(1)\n\n    agent_id = get_agent_id(agent_path, local)\n\n    last_message_id = None\n    print(f\"\\n=== Starting interactive session with agent: {agent_id} ===\")\n    print(\"\")\n    print(\"Type 'exit' to end the session\")\n    print(\"Type 'multiline' to enter multiline mode\")\n    print(\"\")\n\n    metadata = get_metadata(agent_path, local)\n    title = metadata.get(\"details\", {}).get(\"agent\", {}).get(\"welcome\", {}).get(\"title\")\n    if title:\n        print(title)\n    description = metadata.get(\"details\", {}).get(\"agent\", {}).get(\"welcome\", {}).get(\"description\")\n    if description:\n        print(description)\n\n    multiline = False\n\n    def print_multiline_prompt():\n        print(\"On Linux/macOS: To submit, press Ctrl+D at the beginning of a new line after your prompt\")\n        print(\"On Windows: Press Ctrl+Z followed by Enter\")\n\n    while True:\n        first_line = input(\"&gt; \")\n        if first_line.lower() == \"exit\":\n            break\n        if not multiline and first_line.lower() == \"multiline\":\n            multiline = True\n            print_multiline_prompt()\n            continue\n        lines = [first_line]\n\n        # NOTE: the code below tries to catch copy-paste by calling has_pending_input().\n        # This is OS-specific functionality and has been tested on Unix/Linux/Mac:\n        # 1. Works well with blocks of text of 3 lines and more.\n        # 2. Alas, does not trigger with text of 2 lines or less.\n        pending_input_on_this_line = has_pending_input()\n        if multiline or pending_input_on_this_line:\n            try:\n                pending_input_on_prev_line = pending_input_on_this_line\n                while True:\n                    pending_input_on_this_line = has_pending_input()\n                    if pending_input_on_prev_line or pending_input_on_this_line:\n                        line = input(\"\")\n                    else:\n                        if not multiline:\n                            multiline = True\n                            print_multiline_prompt()\n                        line = input(\"&gt; \")\n                    lines.append(line)\n                    pending_input_on_prev_line = pending_input_on_this_line\n            except EOFError:\n                print(\"\")\n\n        new_message = \"\\n\".join(lines)\n\n        last_message_id = self._task(\n            agent=agent_id,\n            task=new_message,\n            thread_id=thread_id,\n            tool_resources=tool_resources,\n            last_message_id=last_message_id,\n            local_path=agent_path if local else None,\n            verbose=verbose,\n            env_vars=env_vars,\n        )\n\n        # Update thread_id for the next iteration\n        if thread_id is None:\n            thread_id = self.last_thread_id\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.task","title":"task","text":"<pre><code>task(\n    agent: str,\n    task: str,\n    thread_id: Optional[str] = None,\n    tool_resources: Optional[Dict[str, Any]] = None,\n    file_ids: Optional[List[str]] = None,\n    local: bool = False,\n    verbose: bool = False,\n    env_vars: Optional[Dict[str, Any]] = None,\n) -&gt; None\n</code></pre> <p>CLI wrapper for the _task method.</p> Source code in <code>nearai/cli.py</code> <pre><code>def task(\n    self,\n    agent: str,\n    task: str,\n    thread_id: Optional[str] = None,\n    tool_resources: Optional[Dict[str, Any]] = None,\n    file_ids: Optional[List[str]] = None,\n    local: bool = False,\n    verbose: bool = False,\n    env_vars: Optional[Dict[str, Any]] = None,\n) -&gt; None:\n    \"\"\"CLI wrapper for the _task method.\"\"\"\n    last_message_id = self._task(\n        agent=agent,\n        task=task,\n        thread_id=thread_id,\n        tool_resources=tool_resources,\n        file_ids=file_ids,\n        local_path=resolve_local_path(Path(agent)) if local else None,\n        verbose=verbose,\n        env_vars=env_vars,\n    )\n    if last_message_id:\n        print(f\"Task completed. Thread ID: {self.last_thread_id}\")\n        print(f\"Last message ID: {last_message_id}\")\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.upload","title":"upload","text":"<pre><code>upload(\n    local_path: str = \".\",\n    bump: bool = False,\n    minor_bump: bool = False,\n    major_bump: bool = False,\n) -&gt; Optional[EntryLocation]\n</code></pre> <p>Upload agent to the registry.</p> <p>This is an alias for 'nearai registry upload'.</p> <pre><code>local_path: Path to the directory containing the agent to upload\nbump: If True, automatically increment patch version if it already exists\nminor_bump: If True, bump with minor version increment (0.1.0 \u2192 0.2.0)\nmajor_bump: If True, bump with major version increment (0.1.0 \u2192 1.0.0)\n</code></pre> <pre><code>EntryLocation if upload was successful, None otherwise\n</code></pre> Source code in <code>nearai/cli.py</code> <pre><code>def upload(\n    self, local_path: str = \".\", bump: bool = False, minor_bump: bool = False, major_bump: bool = False\n) -&gt; Optional[EntryLocation]:\n    \"\"\"Upload agent to the registry.\n\n    This is an alias for 'nearai registry upload'.\n\n    Args:\n    ----\n        local_path: Path to the directory containing the agent to upload\n        bump: If True, automatically increment patch version if it already exists\n        minor_bump: If True, bump with minor version increment (0.1.0 \u2192 0.2.0)\n        major_bump: If True, bump with major version increment (0.1.0 \u2192 1.0.0)\n\n    Returns:\n    -------\n        EntryLocation if upload was successful, None otherwise\n\n    \"\"\"\n    assert_user_auth()\n    # Create an instance of RegistryCli and call its upload method\n    registry_cli = RegistryCli()\n    return registry_cli.upload(local_path, bump, minor_bump, major_bump)\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli","title":"BenchmarkCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class BenchmarkCli:\n    def __init__(self):\n        \"\"\"Initialize Benchmark API.\"\"\"\n        self.client = BenchmarkApi()\n\n    def _get_or_create_benchmark(self, benchmark_name: str, solver_name: str, args: Dict[str, Any], force: bool) -&gt; int:\n        if CONFIG.auth is None:\n            print(\"Please login with `nearai login`\")\n            exit(1)\n        namespace = CONFIG.auth.namespace\n\n        # Sort the args to have a consistent representation.\n        solver_args = json.dumps(OrderedDict(sorted(args.items())))\n\n        benchmark_id = self.client.get_benchmark_v1_benchmark_get_get(\n            namespace=namespace,\n            benchmark_name=benchmark_name,\n            solver_name=solver_name,\n            solver_args=solver_args,\n        )\n\n        if benchmark_id == -1 or force:\n            benchmark_id = self.client.create_benchmark_v1_benchmark_create_get(\n                benchmark_name=benchmark_name,\n                solver_name=solver_name,\n                solver_args=solver_args,\n            )\n\n        assert benchmark_id != -1\n        return benchmark_id\n\n    def run(\n        self,\n        dataset: str,\n        solver_strategy: str,\n        max_concurrent: int = 2,\n        force: bool = False,\n        subset: Optional[str] = None,\n        check_compatibility: bool = True,\n        record: bool = False,\n        num_inference_retries: int = 10,\n        **solver_args: Any,\n    ) -&gt; None:\n        \"\"\"Run benchmark on a dataset with a solver strategy.\n\n        It will cache the results in the database and subsequent runs will pull the results from the cache.\n        If force is set to True, it will run the benchmark again and update the cache.\n        \"\"\"\n        from nearai.benchmark import BenchmarkExecutor, DatasetInfo\n        from nearai.dataset import get_dataset, load_dataset\n        from nearai.solvers import SolverScoringMethod, SolverStrategy, SolverStrategyRegistry\n\n        CONFIG.num_inference_retries = num_inference_retries\n\n        args = dict(solver_args)\n        if subset is not None:\n            args[\"subset\"] = subset\n\n        benchmark_id = self._get_or_create_benchmark(\n            benchmark_name=dataset,\n            solver_name=solver_strategy,\n            args=args,\n            force=force,\n        )\n\n        solver_strategy_class: Union[SolverStrategy, None] = SolverStrategyRegistry.get(solver_strategy, None)\n        assert solver_strategy_class, (\n            f\"Solver strategy {solver_strategy} not found. Available strategies: {list(SolverStrategyRegistry.keys())}\"\n        )\n\n        name = dataset\n        if solver_strategy_class.scoring_method == SolverScoringMethod.Custom:\n            dataset = str(get_dataset(dataset))\n        else:\n            dataset = load_dataset(dataset)\n\n        solver_strategy_obj: SolverStrategy = solver_strategy_class(dataset_ref=dataset, **solver_args)  # type: ignore\n        if check_compatibility:\n            assert name in solver_strategy_obj.compatible_datasets() or any(\n                map(lambda n: n in name, solver_strategy_obj.compatible_datasets())\n            ), f\"Solver strategy {solver_strategy} is not compatible with dataset {name}\"\n\n        dest_path = get_registry_folder() / name\n        metadata_path = dest_path / \"metadata.json\"\n        with open(metadata_path, \"r\") as file:\n            metadata = json.load(file)\n\n        be = BenchmarkExecutor(\n            DatasetInfo(name, subset, dataset, metadata), solver_strategy_obj, benchmark_id=benchmark_id\n        )\n\n        cpu_count = os.cpu_count()\n        max_concurrent = (cpu_count if cpu_count is not None else 1) if max_concurrent &lt; 0 else max_concurrent\n        be.run(max_concurrent=max_concurrent, record=record)\n\n    def list(\n        self,\n        namespace: Optional[str] = None,\n        benchmark: Optional[str] = None,\n        solver: Optional[str] = None,\n        args: Optional[str] = None,\n        total: int = 32,\n        offset: int = 0,\n    ):\n        \"\"\"List all executed benchmarks.\"\"\"\n        result = self.client.list_benchmarks_v1_benchmark_list_get(\n            namespace=namespace,\n            benchmark_name=benchmark,\n            solver_name=solver,\n            solver_args=args,\n            total=total,\n            offset=offset,\n        )\n\n        header = [\"id\", \"namespace\", \"benchmark\", \"solver\", \"args\", \"score\", \"solved\", \"total\"]\n        table = []\n        for benchmark_output in result:\n            score = 100 * benchmark_output.solved / benchmark_output.total\n            table.append(\n                [\n                    fill(str(benchmark_output.id)),\n                    fill(benchmark_output.namespace),\n                    fill(benchmark_output.benchmark),\n                    fill(benchmark_output.solver),\n                    fill(benchmark_output.args),\n                    fill(f\"{score:.2f}%\"),\n                    fill(str(benchmark_output.solved)),\n                    fill(str(benchmark_output.total)),\n                ]\n            )\n\n        print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize Benchmark API.</p> Source code in <code>nearai/cli.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize Benchmark API.\"\"\"\n    self.client = BenchmarkApi()\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli.list","title":"list","text":"<pre><code>list(\n    namespace: Optional[str] = None,\n    benchmark: Optional[str] = None,\n    solver: Optional[str] = None,\n    args: Optional[str] = None,\n    total: int = 32,\n    offset: int = 0,\n)\n</code></pre> <p>List all executed benchmarks.</p> Source code in <code>nearai/cli.py</code> <pre><code>def list(\n    self,\n    namespace: Optional[str] = None,\n    benchmark: Optional[str] = None,\n    solver: Optional[str] = None,\n    args: Optional[str] = None,\n    total: int = 32,\n    offset: int = 0,\n):\n    \"\"\"List all executed benchmarks.\"\"\"\n    result = self.client.list_benchmarks_v1_benchmark_list_get(\n        namespace=namespace,\n        benchmark_name=benchmark,\n        solver_name=solver,\n        solver_args=args,\n        total=total,\n        offset=offset,\n    )\n\n    header = [\"id\", \"namespace\", \"benchmark\", \"solver\", \"args\", \"score\", \"solved\", \"total\"]\n    table = []\n    for benchmark_output in result:\n        score = 100 * benchmark_output.solved / benchmark_output.total\n        table.append(\n            [\n                fill(str(benchmark_output.id)),\n                fill(benchmark_output.namespace),\n                fill(benchmark_output.benchmark),\n                fill(benchmark_output.solver),\n                fill(benchmark_output.args),\n                fill(f\"{score:.2f}%\"),\n                fill(str(benchmark_output.solved)),\n                fill(str(benchmark_output.total)),\n            ]\n        )\n\n    print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli.run","title":"run","text":"<pre><code>run(\n    dataset: str,\n    solver_strategy: str,\n    max_concurrent: int = 2,\n    force: bool = False,\n    subset: Optional[str] = None,\n    check_compatibility: bool = True,\n    record: bool = False,\n    num_inference_retries: int = 10,\n    **solver_args: Any,\n) -&gt; None\n</code></pre> <p>Run benchmark on a dataset with a solver strategy.</p> <p>It will cache the results in the database and subsequent runs will pull the results from the cache. If force is set to True, it will run the benchmark again and update the cache.</p> Source code in <code>nearai/cli.py</code> <pre><code>def run(\n    self,\n    dataset: str,\n    solver_strategy: str,\n    max_concurrent: int = 2,\n    force: bool = False,\n    subset: Optional[str] = None,\n    check_compatibility: bool = True,\n    record: bool = False,\n    num_inference_retries: int = 10,\n    **solver_args: Any,\n) -&gt; None:\n    \"\"\"Run benchmark on a dataset with a solver strategy.\n\n    It will cache the results in the database and subsequent runs will pull the results from the cache.\n    If force is set to True, it will run the benchmark again and update the cache.\n    \"\"\"\n    from nearai.benchmark import BenchmarkExecutor, DatasetInfo\n    from nearai.dataset import get_dataset, load_dataset\n    from nearai.solvers import SolverScoringMethod, SolverStrategy, SolverStrategyRegistry\n\n    CONFIG.num_inference_retries = num_inference_retries\n\n    args = dict(solver_args)\n    if subset is not None:\n        args[\"subset\"] = subset\n\n    benchmark_id = self._get_or_create_benchmark(\n        benchmark_name=dataset,\n        solver_name=solver_strategy,\n        args=args,\n        force=force,\n    )\n\n    solver_strategy_class: Union[SolverStrategy, None] = SolverStrategyRegistry.get(solver_strategy, None)\n    assert solver_strategy_class, (\n        f\"Solver strategy {solver_strategy} not found. Available strategies: {list(SolverStrategyRegistry.keys())}\"\n    )\n\n    name = dataset\n    if solver_strategy_class.scoring_method == SolverScoringMethod.Custom:\n        dataset = str(get_dataset(dataset))\n    else:\n        dataset = load_dataset(dataset)\n\n    solver_strategy_obj: SolverStrategy = solver_strategy_class(dataset_ref=dataset, **solver_args)  # type: ignore\n    if check_compatibility:\n        assert name in solver_strategy_obj.compatible_datasets() or any(\n            map(lambda n: n in name, solver_strategy_obj.compatible_datasets())\n        ), f\"Solver strategy {solver_strategy} is not compatible with dataset {name}\"\n\n    dest_path = get_registry_folder() / name\n    metadata_path = dest_path / \"metadata.json\"\n    with open(metadata_path, \"r\") as file:\n        metadata = json.load(file)\n\n    be = BenchmarkExecutor(\n        DatasetInfo(name, subset, dataset, metadata), solver_strategy_obj, benchmark_id=benchmark_id\n    )\n\n    cpu_count = os.cpu_count()\n    max_concurrent = (cpu_count if cpu_count is not None else 1) if max_concurrent &lt; 0 else max_concurrent\n    be.run(max_concurrent=max_concurrent, record=record)\n</code></pre>"},{"location":"api/#nearai.cli.CLI","title":"CLI","text":"Source code in <code>nearai/cli.py</code> <pre><code>class CLI:\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.registry = RegistryCli()\n        self.login = LoginCLI()\n        self.logout = LogoutCLI()\n        self.hub = HubCLI()\n        self.log = LogCLI()\n\n        self.config = ConfigCli()\n        self.benchmark = BenchmarkCli()\n        self.evaluation = EvaluationCli()\n        self.agent = AgentCli()\n        self.finetune = FinetuneCli()\n        self.tensorboard = TensorboardCli()\n        self.vllm = VllmCli()\n        self.permission = PermissionCli()\n\n    def submit(self, path: Optional[str] = None, worker_kind: str = WorkerKind.GPU_8_A100.value):\n        \"\"\"Submit a task to be executed by a worker.\"\"\"\n        if path is None:\n            path = os.getcwd()\n\n        worker_kind_t = WorkerKind(worker_kind)\n\n        location = self.registry.upload(path)\n\n        if location is None:\n            print(\"Error: Failed to upload entry\")\n            return\n\n        delegation_api = DelegationApi()\n        delegation_api.delegate_v1_delegation_delegate_post(\n            delegate_account_id=CONFIG.scheduler_account_id,\n            expires_at=datetime.now() + timedelta(days=1),\n        )\n\n        try:\n            client = JobsApi()\n            client.add_job_v1_jobs_add_job_post(\n                worker_kind_t,\n                BodyAddJobV1JobsAddJobPost(entry_location=location),\n            )\n        except Exception as e:\n            print(\"Error: \", e)\n            delegation_api.revoke_delegation_v1_delegation_revoke_delegation_post(\n                delegate_account_id=CONFIG.scheduler_account_id,\n            )\n\n    def location(self) -&gt; None:  # noqa: D102\n        \"\"\"Show location where nearai is installed.\"\"\"\n        from nearai import cli_path\n\n        print(cli_path())\n\n    def version(self):\n        \"\"\"Show nearai version.\"\"\"\n        print(importlib.metadata.version(\"nearai\"))\n\n    def task(self, *args, **kwargs):\n        \"\"\"CLI command for running a single task.\"\"\"\n        self.agent.task_cli(*args, **kwargs)\n</code></pre>"},{"location":"api/#nearai.cli.CLI.location","title":"location","text":"<pre><code>location() -&gt; None\n</code></pre> <p>Show location where nearai is installed.</p> Source code in <code>nearai/cli.py</code> <pre><code>def location(self) -&gt; None:  # noqa: D102\n    \"\"\"Show location where nearai is installed.\"\"\"\n    from nearai import cli_path\n\n    print(cli_path())\n</code></pre>"},{"location":"api/#nearai.cli.CLI.submit","title":"submit","text":"<pre><code>submit(\n    path: Optional[str] = None,\n    worker_kind: str = GPU_8_A100.value,\n)\n</code></pre> <p>Submit a task to be executed by a worker.</p> Source code in <code>nearai/cli.py</code> <pre><code>def submit(self, path: Optional[str] = None, worker_kind: str = WorkerKind.GPU_8_A100.value):\n    \"\"\"Submit a task to be executed by a worker.\"\"\"\n    if path is None:\n        path = os.getcwd()\n\n    worker_kind_t = WorkerKind(worker_kind)\n\n    location = self.registry.upload(path)\n\n    if location is None:\n        print(\"Error: Failed to upload entry\")\n        return\n\n    delegation_api = DelegationApi()\n    delegation_api.delegate_v1_delegation_delegate_post(\n        delegate_account_id=CONFIG.scheduler_account_id,\n        expires_at=datetime.now() + timedelta(days=1),\n    )\n\n    try:\n        client = JobsApi()\n        client.add_job_v1_jobs_add_job_post(\n            worker_kind_t,\n            BodyAddJobV1JobsAddJobPost(entry_location=location),\n        )\n    except Exception as e:\n        print(\"Error: \", e)\n        delegation_api.revoke_delegation_v1_delegation_revoke_delegation_post(\n            delegate_account_id=CONFIG.scheduler_account_id,\n        )\n</code></pre>"},{"location":"api/#nearai.cli.CLI.task","title":"task","text":"<pre><code>task(*args, **kwargs)\n</code></pre> <p>CLI command for running a single task.</p> Source code in <code>nearai/cli.py</code> <pre><code>def task(self, *args, **kwargs):\n    \"\"\"CLI command for running a single task.\"\"\"\n    self.agent.task_cli(*args, **kwargs)\n</code></pre>"},{"location":"api/#nearai.cli.CLI.version","title":"version","text":"<pre><code>version()\n</code></pre> <p>Show nearai version.</p> Source code in <code>nearai/cli.py</code> <pre><code>def version(self):\n    \"\"\"Show nearai version.\"\"\"\n    print(importlib.metadata.version(\"nearai\"))\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli","title":"ConfigCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class ConfigCli:\n    def set(self, key: str, value: str, local: bool = False) -&gt; None:\n        \"\"\"Add key-value pair to the config file.\"\"\"\n        update_config(key, value, local)\n\n    def get(self, key: str) -&gt; None:\n        \"\"\"Get value of a key in the config file.\"\"\"\n        print(CONFIG.get(key))\n\n    def show(self) -&gt; None:  # noqa: D102\n        for key, value in asdict(CONFIG).items():\n            print(f\"{key}: {value}\")\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli.get","title":"get","text":"<pre><code>get(key: str) -&gt; None\n</code></pre> <p>Get value of a key in the config file.</p> Source code in <code>nearai/cli.py</code> <pre><code>def get(self, key: str) -&gt; None:\n    \"\"\"Get value of a key in the config file.\"\"\"\n    print(CONFIG.get(key))\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli.set","title":"set","text":"<pre><code>set(key: str, value: str, local: bool = False) -&gt; None\n</code></pre> <p>Add key-value pair to the config file.</p> Source code in <code>nearai/cli.py</code> <pre><code>def set(self, key: str, value: str, local: bool = False) -&gt; None:\n    \"\"\"Add key-value pair to the config file.\"\"\"\n    update_config(key, value, local)\n</code></pre>"},{"location":"api/#nearai.cli.EvaluationCli","title":"EvaluationCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class EvaluationCli:\n    def table(\n        self,\n        all_key_columns: bool = False,\n        all_metrics: bool = False,\n        num_columns: int = 6,\n        metric_name_max_length: int = 30,\n    ) -&gt; None:\n        \"\"\"Prints table of evaluations.\"\"\"\n        from nearai.evaluation import print_evaluation_table\n\n        api = EvaluationApi()\n        table = api.table_v1_evaluation_table_get()\n\n        print_evaluation_table(\n            table.rows,\n            table.columns,\n            table.important_columns,\n            all_key_columns,\n            all_metrics,\n            num_columns,\n            metric_name_max_length,\n        )\n\n    def read_solutions(self, entry: str, status: Optional[bool] = None, verbose: bool = False) -&gt; None:\n        \"\"\"Reads solutions.json from evaluation entry.\"\"\"\n        entry_path = registry.download(entry)\n        solutions_file = entry_path / \"solutions.json\"\n\n        if not solutions_file.exists():\n            print(f\"No solutions file found for entry: {entry}\")\n            return\n\n        try:\n            with open(solutions_file) as f:\n                solutions = json.load(f)\n        except json.JSONDecodeError:\n            print(f\"Error reading solutions file for entry: {entry}\")\n            return\n\n        # Filter solutions if status is specified\n        if status is not None:\n            solutions = [s for s in solutions if s.get(\"status\") == status]\n        if not solutions:\n            print(\"No solutions found matching criteria\")\n            return\n        print(f\"\\nFound {len(solutions)} solutions{' with status=' + str(status) if status is not None else ''}\")\n\n        for i, solution in enumerate(solutions, 1):\n            print(\"-\" * 80)\n            print(f\"\\nSolution {i}/{len(solutions)}:\")\n            datum = solution.get(\"datum\")\n            print(f\"datum: {json.dumps(datum, indent=2, ensure_ascii=False)}\")\n            status = solution.get(\"status\")\n            print(f\"status: {status}\")\n            info: dict = solution.get(\"info\", {})\n            if not verbose and isinstance(info, dict):\n                info.pop(\"verbose\", {})\n            print(f\"info: {json.dumps(info, indent=2, ensure_ascii=False)}\")\n            if i == 1:\n                print(\"Enter to continue, type 'exit' to quit.\")\n            new_message = input(\"&gt; \")\n            if new_message.lower() == \"exit\":\n                break\n</code></pre>"},{"location":"api/#nearai.cli.EvaluationCli.read_solutions","title":"read_solutions","text":"<pre><code>read_solutions(\n    entry: str,\n    status: Optional[bool] = None,\n    verbose: bool = False,\n) -&gt; None\n</code></pre> <p>Reads solutions.json from evaluation entry.</p> Source code in <code>nearai/cli.py</code> <pre><code>def read_solutions(self, entry: str, status: Optional[bool] = None, verbose: bool = False) -&gt; None:\n    \"\"\"Reads solutions.json from evaluation entry.\"\"\"\n    entry_path = registry.download(entry)\n    solutions_file = entry_path / \"solutions.json\"\n\n    if not solutions_file.exists():\n        print(f\"No solutions file found for entry: {entry}\")\n        return\n\n    try:\n        with open(solutions_file) as f:\n            solutions = json.load(f)\n    except json.JSONDecodeError:\n        print(f\"Error reading solutions file for entry: {entry}\")\n        return\n\n    # Filter solutions if status is specified\n    if status is not None:\n        solutions = [s for s in solutions if s.get(\"status\") == status]\n    if not solutions:\n        print(\"No solutions found matching criteria\")\n        return\n    print(f\"\\nFound {len(solutions)} solutions{' with status=' + str(status) if status is not None else ''}\")\n\n    for i, solution in enumerate(solutions, 1):\n        print(\"-\" * 80)\n        print(f\"\\nSolution {i}/{len(solutions)}:\")\n        datum = solution.get(\"datum\")\n        print(f\"datum: {json.dumps(datum, indent=2, ensure_ascii=False)}\")\n        status = solution.get(\"status\")\n        print(f\"status: {status}\")\n        info: dict = solution.get(\"info\", {})\n        if not verbose and isinstance(info, dict):\n            info.pop(\"verbose\", {})\n        print(f\"info: {json.dumps(info, indent=2, ensure_ascii=False)}\")\n        if i == 1:\n            print(\"Enter to continue, type 'exit' to quit.\")\n        new_message = input(\"&gt; \")\n        if new_message.lower() == \"exit\":\n            break\n</code></pre>"},{"location":"api/#nearai.cli.EvaluationCli.table","title":"table","text":"<pre><code>table(\n    all_key_columns: bool = False,\n    all_metrics: bool = False,\n    num_columns: int = 6,\n    metric_name_max_length: int = 30,\n) -&gt; None\n</code></pre> <p>Prints table of evaluations.</p> Source code in <code>nearai/cli.py</code> <pre><code>def table(\n    self,\n    all_key_columns: bool = False,\n    all_metrics: bool = False,\n    num_columns: int = 6,\n    metric_name_max_length: int = 30,\n) -&gt; None:\n    \"\"\"Prints table of evaluations.\"\"\"\n    from nearai.evaluation import print_evaluation_table\n\n    api = EvaluationApi()\n    table = api.table_v1_evaluation_table_get()\n\n    print_evaluation_table(\n        table.rows,\n        table.columns,\n        table.important_columns,\n        all_key_columns,\n        all_metrics,\n        num_columns,\n        metric_name_max_length,\n    )\n</code></pre>"},{"location":"api/#nearai.cli.HubCLI","title":"HubCLI","text":"Source code in <code>nearai/cli.py</code> <pre><code>class HubCLI:\n    def chat(self, **kwargs):\n        \"\"\"Chat with model from NEAR AI hub.\n\n        Args:\n        ----\n            query (str): User's query to model\n            endpoint (str): NEAR AI HUB's url\n            model (str): Name of a model\n            provider (str): Name of a provider\n            info (bool): Display system info\n            kwargs (Dict[str, Any]): All cli keyword arguments\n\n        \"\"\"\n        from nearai.hub import Hub\n\n        hub = Hub(CONFIG)\n        hub.chat(kwargs)\n</code></pre>"},{"location":"api/#nearai.cli.HubCLI.chat","title":"chat","text":"<pre><code>chat(**kwargs)\n</code></pre> <p>Chat with model from NEAR AI hub.</p> <pre><code>query (str): User's query to model\nendpoint (str): NEAR AI HUB's url\nmodel (str): Name of a model\nprovider (str): Name of a provider\ninfo (bool): Display system info\nkwargs (Dict[str, Any]): All cli keyword arguments\n</code></pre> Source code in <code>nearai/cli.py</code> <pre><code>def chat(self, **kwargs):\n    \"\"\"Chat with model from NEAR AI hub.\n\n    Args:\n    ----\n        query (str): User's query to model\n        endpoint (str): NEAR AI HUB's url\n        model (str): Name of a model\n        provider (str): Name of a provider\n        info (bool): Display system info\n        kwargs (Dict[str, Any]): All cli keyword arguments\n\n    \"\"\"\n    from nearai.hub import Hub\n\n    hub = Hub(CONFIG)\n    hub.chat(kwargs)\n</code></pre>"},{"location":"api/#nearai.cli.LoginCLI","title":"LoginCLI","text":"Source code in <code>nearai/cli.py</code> <pre><code>class LoginCLI:\n    def __call__(self, **kwargs):\n        \"\"\"Login with NEAR Mainnet account.\n\n        Args:\n        ----\n            remote (bool): Remote login allows signing message with NEAR Account on a remote machine\n            auth_url (str): Url to the auth portal\n            accountId (str): AccountId in .near-credentials folder to signMessage\n            privateKey (str): Private Key to sign a message\n            kwargs (Dict[str, Any]): All cli keyword arguments\n\n        \"\"\"\n        from nearai.login import generate_and_save_signature, login_with_file_credentials, login_with_near_auth\n\n        remote = kwargs.get(\"remote\", False)\n        account_id = kwargs.get(\"accountId\", None)\n        private_key = kwargs.get(\"privateKey\", None)\n\n        if not remote and account_id and private_key:\n            generate_and_save_signature(account_id, private_key)\n        elif not remote and account_id:\n            login_with_file_credentials(account_id)\n        else:\n            auth_url = kwargs.get(\"auth_url\", \"https://auth.near.ai\")\n            login_with_near_auth(remote, auth_url)\n\n    def status(self):\n        \"\"\"Load NEAR account authorization data.\"\"\"\n        from nearai.login import print_login_status\n\n        print_login_status()\n\n    def save(self, **kwargs):\n        \"\"\"Save NEAR account authorization data.\n\n        Args:\n        ----\n            accountId (str): Near Account\n            signature (str): Signature\n            publicKey (str): Public Key used to sign\n            callbackUrl (str): Callback Url\n            nonce (str): nonce\n            kwargs (Dict[str, Any]): All cli keyword arguments\n\n        \"\"\"\n        from nearai.login import update_auth_config\n\n        account_id = kwargs.get(\"accountId\")\n        signature = kwargs.get(\"signature\")\n        public_key = kwargs.get(\"publicKey\")\n        callback_url = kwargs.get(\"callbackUrl\")\n        nonce = kwargs.get(\"nonce\")\n\n        if account_id and signature and public_key and callback_url and nonce:\n            update_auth_config(account_id, signature, public_key, callback_url, nonce)\n        else:\n            print(\"Missing data\")\n</code></pre>"},{"location":"api/#nearai.cli.LoginCLI.__call__","title":"__call__","text":"<pre><code>__call__(**kwargs)\n</code></pre> <p>Login with NEAR Mainnet account.</p> <pre><code>remote (bool): Remote login allows signing message with NEAR Account on a remote machine\nauth_url (str): Url to the auth portal\naccountId (str): AccountId in .near-credentials folder to signMessage\nprivateKey (str): Private Key to sign a message\nkwargs (Dict[str, Any]): All cli keyword arguments\n</code></pre> Source code in <code>nearai/cli.py</code> <pre><code>def __call__(self, **kwargs):\n    \"\"\"Login with NEAR Mainnet account.\n\n    Args:\n    ----\n        remote (bool): Remote login allows signing message with NEAR Account on a remote machine\n        auth_url (str): Url to the auth portal\n        accountId (str): AccountId in .near-credentials folder to signMessage\n        privateKey (str): Private Key to sign a message\n        kwargs (Dict[str, Any]): All cli keyword arguments\n\n    \"\"\"\n    from nearai.login import generate_and_save_signature, login_with_file_credentials, login_with_near_auth\n\n    remote = kwargs.get(\"remote\", False)\n    account_id = kwargs.get(\"accountId\", None)\n    private_key = kwargs.get(\"privateKey\", None)\n\n    if not remote and account_id and private_key:\n        generate_and_save_signature(account_id, private_key)\n    elif not remote and account_id:\n        login_with_file_credentials(account_id)\n    else:\n        auth_url = kwargs.get(\"auth_url\", \"https://auth.near.ai\")\n        login_with_near_auth(remote, auth_url)\n</code></pre>"},{"location":"api/#nearai.cli.LoginCLI.save","title":"save","text":"<pre><code>save(**kwargs)\n</code></pre> <p>Save NEAR account authorization data.</p> <pre><code>accountId (str): Near Account\nsignature (str): Signature\npublicKey (str): Public Key used to sign\ncallbackUrl (str): Callback Url\nnonce (str): nonce\nkwargs (Dict[str, Any]): All cli keyword arguments\n</code></pre> Source code in <code>nearai/cli.py</code> <pre><code>def save(self, **kwargs):\n    \"\"\"Save NEAR account authorization data.\n\n    Args:\n    ----\n        accountId (str): Near Account\n        signature (str): Signature\n        publicKey (str): Public Key used to sign\n        callbackUrl (str): Callback Url\n        nonce (str): nonce\n        kwargs (Dict[str, Any]): All cli keyword arguments\n\n    \"\"\"\n    from nearai.login import update_auth_config\n\n    account_id = kwargs.get(\"accountId\")\n    signature = kwargs.get(\"signature\")\n    public_key = kwargs.get(\"publicKey\")\n    callback_url = kwargs.get(\"callbackUrl\")\n    nonce = kwargs.get(\"nonce\")\n\n    if account_id and signature and public_key and callback_url and nonce:\n        update_auth_config(account_id, signature, public_key, callback_url, nonce)\n    else:\n        print(\"Missing data\")\n</code></pre>"},{"location":"api/#nearai.cli.LoginCLI.status","title":"status","text":"<pre><code>status()\n</code></pre> <p>Load NEAR account authorization data.</p> Source code in <code>nearai/cli.py</code> <pre><code>def status(self):\n    \"\"\"Load NEAR account authorization data.\"\"\"\n    from nearai.login import print_login_status\n\n    print_login_status()\n</code></pre>"},{"location":"api/#nearai.cli.LogoutCLI","title":"LogoutCLI","text":"Source code in <code>nearai/cli.py</code> <pre><code>class LogoutCLI:\n    def __call__(self, **kwargs):\n        \"\"\"Clear NEAR account auth data.\"\"\"\n        from nearai.config import load_config_file, save_config_file\n\n        config = load_config_file()\n        if not config.get(\"auth\") or not config[\"auth\"].get(\"account_id\"):\n            print(\"Auth data does not exist.\")\n        else:\n            config.pop(\"auth\", None)\n            save_config_file(config)\n            print(\"Auth data removed\")\n</code></pre>"},{"location":"api/#nearai.cli.LogoutCLI.__call__","title":"__call__","text":"<pre><code>__call__(**kwargs)\n</code></pre> <p>Clear NEAR account auth data.</p> Source code in <code>nearai/cli.py</code> <pre><code>def __call__(self, **kwargs):\n    \"\"\"Clear NEAR account auth data.\"\"\"\n    from nearai.config import load_config_file, save_config_file\n\n    config = load_config_file()\n    if not config.get(\"auth\") or not config[\"auth\"].get(\"account_id\"):\n        print(\"Auth data does not exist.\")\n    else:\n        config.pop(\"auth\", None)\n        save_config_file(config)\n        print(\"Auth data removed\")\n</code></pre>"},{"location":"api/#nearai.cli.PermissionCli","title":"PermissionCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class PermissionCli:\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.client = PermissionsApi()\n\n    def grant(self, account_id: str, permission: str):\n        \"\"\"Grant permission to an account.\"\"\"\n        self.client.grant_permission_v1_permissions_grant_permission_post(account_id, permission)\n\n    def revoke(self, account_id: str, permission: str = \"\"):\n        \"\"\"Revoke permission from an account. If permission is empty all permissions are revoked.\"\"\"\n        self.client.revoke_permission_v1_permissions_revoke_permission_post(account_id, permission)\n</code></pre>"},{"location":"api/#nearai.cli.PermissionCli.grant","title":"grant","text":"<pre><code>grant(account_id: str, permission: str)\n</code></pre> <p>Grant permission to an account.</p> Source code in <code>nearai/cli.py</code> <pre><code>def grant(self, account_id: str, permission: str):\n    \"\"\"Grant permission to an account.\"\"\"\n    self.client.grant_permission_v1_permissions_grant_permission_post(account_id, permission)\n</code></pre>"},{"location":"api/#nearai.cli.PermissionCli.revoke","title":"revoke","text":"<pre><code>revoke(account_id: str, permission: str = '')\n</code></pre> <p>Revoke permission from an account. If permission is empty all permissions are revoked.</p> Source code in <code>nearai/cli.py</code> <pre><code>def revoke(self, account_id: str, permission: str = \"\"):\n    \"\"\"Revoke permission from an account. If permission is empty all permissions are revoked.\"\"\"\n    self.client.revoke_permission_v1_permissions_revoke_permission_post(account_id, permission)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli","title":"RegistryCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class RegistryCli:\n    def info(self, entry: str) -&gt; None:\n        \"\"\"Show information about an item.\"\"\"\n        entry_location = parse_location(entry)\n        metadata = registry.info(entry_location)\n\n        if metadata is None:\n            print(f\"Entry {entry} not found.\")\n            return\n\n        print(metadata.model_dump_json(indent=2))\n        if metadata.category == \"model\":\n            available_provider_matches = ProviderModels(CONFIG.get_client_config()).available_provider_matches(\n                NamespacedName(name=metadata.name, namespace=entry_location.namespace)\n            )\n            if len(available_provider_matches) &gt; 0:\n                header = [\"provider\", \"name\"]\n\n                table = []\n                for provider, name in available_provider_matches.items():\n                    table.append(\n                        [\n                            fill(provider),\n                            fill(name),\n                        ]\n                    )\n                print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n\n    def metadata_template(self, local_path: str = \".\", category: str = \"\", description: str = \"\"):\n        \"\"\"Create a metadata template.\"\"\"\n        path = resolve_local_path(Path(local_path))\n\n        metadata_path = path / \"metadata.json\"\n\n        version = path.name\n        # Validate version format\n        is_valid, error = validate_version(version)\n        if not is_valid:\n            print(error)\n            return\n\n        name = path.parent.name\n        assert not re.match(PATTERN, name), f\"Invalid agent name: {name}\"\n        assert \" \" not in name\n\n        with open(metadata_path, \"w\") as f:\n            metadata: Dict[str, Any] = {\n                \"name\": name,\n                \"version\": version,\n                \"description\": description,\n                \"category\": category,\n                \"tags\": [],\n                \"details\": {},\n                \"show_entry\": True,\n            }\n\n            if category == \"agent\":\n                metadata[\"details\"][\"agent\"] = {}\n                metadata[\"details\"][\"agent\"][\"welcome\"] = {\n                    \"title\": name,\n                    \"description\": description,\n                }\n                metadata[\"details\"][\"agent\"][\"defaults\"] = {\n                    \"model\": DEFAULT_MODEL,\n                    \"model_provider\": DEFAULT_PROVIDER,\n                    \"model_temperature\": DEFAULT_MODEL_TEMPERATURE,\n                    \"model_max_tokens\": DEFAULT_MODEL_MAX_TOKENS,\n                    \"max_iterations\": 1,\n                }\n                metadata[\"details\"][\"agent\"][\"framework\"] = \"minimal\"\n\n            json.dump(metadata, f, indent=2)\n\n    def list(\n        self,\n        namespace: str = \"\",\n        category: str = \"\",\n        tags: str = \"\",\n        total: int = 32,\n        offset: int = 0,\n        show_all: bool = False,\n        show_latest_version: bool = True,\n        star: str = \"\",\n    ) -&gt; None:\n        \"\"\"List available items.\"\"\"\n        # Make sure tags is a comma-separated list of tags\n        tags_l = parse_tags(tags)\n        tags = \",\".join(tags_l)\n\n        entries = registry.list(\n            namespace=namespace,\n            category=category,\n            tags=tags,\n            total=total + 1,\n            offset=offset,\n            show_all=show_all,\n            show_latest_version=show_latest_version,\n            starred_by=star,\n        )\n\n        more_rows = len(entries) &gt; total\n        entries = entries[:total]\n\n        header = [\"entry\", \"category\", \"description\", \"tags\"]\n\n        table = []\n        for entry in entries:\n            table.append(\n                [\n                    fill(f\"{entry.namespace}/{entry.name}/{entry.version}\"),\n                    fill(entry.category, 20),\n                    fill(entry.description, 50),\n                    fill(\", \".join(entry.tags), 20),\n                ]\n            )\n\n        if more_rows:\n            table.append([\"...\", \"...\", \"...\", \"...\"])\n\n        print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n\n        if category == \"model\" and len(entries) &lt; total and namespace == \"\" and tags == \"\" and star == \"\":\n            unregistered_common_provider_models = ProviderModels(\n                CONFIG.get_client_config()\n            ).get_unregistered_common_provider_models(registry.dict_models())\n            if len(unregistered_common_provider_models):\n                print(\n                    f\"There are unregistered common provider models: {unregistered_common_provider_models}. Run 'nearai registry upload-unregistered-common-provider-models' to update registry.\"  # noqa: E501\n                )\n\n    def update(self, local_path: str = \".\") -&gt; None:\n        \"\"\"Update metadata of a registry item.\"\"\"\n        path = resolve_local_path(Path(local_path))\n\n        if CONFIG.auth is None:\n            print(\"Please login with `nearai login`\")\n            exit(1)\n\n        metadata_path = path / \"metadata.json\"\n        check_metadata_present(metadata_path)\n\n        with open(metadata_path) as f:\n            metadata: Dict[str, Any] = json.load(f)\n\n        namespace = CONFIG.auth.namespace\n\n        entry_location = EntryLocation.model_validate(\n            dict(\n                namespace=namespace,\n                name=metadata.pop(\"name\"),\n                version=metadata.pop(\"version\"),\n            )\n        )\n        assert \" \" not in entry_location.name\n\n        entry_metadata = EntryMetadataInput.model_validate(metadata)\n        result = registry.update(entry_location, entry_metadata)\n        print(json.dumps(result, indent=2))\n\n    def upload_unregistered_common_provider_models(self, dry_run: bool = True) -&gt; None:\n        \"\"\"Creates new registry items for unregistered common provider models.\"\"\"\n        provider_matches_list = ProviderModels(CONFIG.get_client_config()).get_unregistered_common_provider_models(\n            registry.dict_models()\n        )\n        if len(provider_matches_list) == 0:\n            print(\"No new models to upload.\")\n            return\n\n        print(\"Going to create new registry items:\")\n        header = [\"entry\", \"description\"]\n        table = []\n        paths = []\n        for provider_matches in provider_matches_list:\n            provider_model = provider_matches.get(DEFAULT_PROVIDER) or next(iter(provider_matches.values()))\n            _, model = get_provider_namespaced_model(provider_model)\n            assert model.namespace == \"\"\n            model.name = create_registry_name(model.name)\n            model.namespace = DEFAULT_NAMESPACE\n            version = \"1.0.0\"\n            description = \" &amp; \".join(provider_matches.values())\n            table.append(\n                [\n                    fill(f\"{model.namespace}/{model.name}/{version}\"),\n                    fill(description, 50),\n                ]\n            )\n\n            path = get_registry_folder() / model.namespace / model.name / version\n            path.mkdir(parents=True, exist_ok=True)\n            paths.append(path)\n            metadata_path = path / \"metadata.json\"\n            with open(metadata_path, \"w\") as f:\n                metadata: Dict[str, Any] = {\n                    \"name\": model.name,\n                    \"version\": version,\n                    \"description\": description,\n                    \"category\": \"model\",\n                    \"tags\": [],\n                    \"details\": {},\n                    \"show_entry\": True,\n                }\n                json.dump(metadata, f, indent=2)\n\n        print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n        if dry_run:\n            print(\"Please verify, then repeat the command with --dry_run=False\")\n        else:\n            for path in paths:\n                self.upload(str(path))\n\n    def upload(\n        self, local_path: str = \".\", bump: bool = False, minor_bump: bool = False, major_bump: bool = False\n    ) -&gt; Optional[EntryLocation]:\n        \"\"\"Upload item to the registry.\n\n        Args:\n        ----\n            local_path: Path to the directory containing the agent to upload\n            bump: If True, automatically increment patch version if it already exists\n            minor_bump: If True, bump with minor version increment (0.1.0 \u2192 0.2.0)\n            major_bump: If True, bump with major version increment (0.1.0 \u2192 1.0.0)\n\n        Returns:\n        -------\n            EntryLocation if upload was successful, None otherwise\n\n        \"\"\"\n        console = Console()\n        path = resolve_local_path(Path(local_path))\n        metadata_path = path / \"metadata.json\"\n\n        # Load and validate metadata\n        metadata, error = load_and_validate_metadata(metadata_path)\n        if error:\n            console.print(\n                Panel(Text(error, style=\"bold red\"), title=\"Metadata Error\", border_style=\"red\", padding=(1, 2))\n            )\n            return None\n\n        # At this point, metadata is guaranteed to be not None\n        assert metadata is not None, \"Metadata should not be None if error is None\"\n\n        name = metadata[\"name\"]\n        version = metadata[\"version\"]\n\n        # Get namespace using the function from registry.py\n        try:\n            namespace = get_namespace(path)\n        except ValueError:\n            console.print(\n                Panel(\n                    Text(\"Please login with `nearai login` before uploading\", style=\"bold red\"),\n                    title=\"Authentication Error\",\n                    border_style=\"red\",\n                    padding=(1, 2),\n                )\n            )\n            return None\n\n        # Check if this version already exists\n        exists, error = check_version_exists(namespace, name, version)\n\n        if error:\n            console.print(\n                Panel(Text(error, style=\"bold red\"), title=\"Registry Error\", border_style=\"red\", padding=(1, 2))\n            )\n            return None\n\n        # Display the version check result\n        display_version_check(namespace, name, version, exists)\n\n        bump_requested = bump or minor_bump or major_bump\n\n        if exists and bump_requested:\n            # Handle version bump\n            old_version = version\n\n            # Determine increment type based on flags\n            if major_bump:\n                increment_type = \"major\"\n            elif minor_bump:\n                increment_type = \"minor\"\n            else:\n                increment_type = \"patch\"  # Default for bump\n\n            version = increment_version_by_type(version, increment_type)\n\n            # Enhanced version update message\n            update_panel = Panel(\n                Text.assemble(\n                    (\"Updating Version...\\n\\n\", \"bold\"),\n                    (\"Previous version: \", \"dim\"),\n                    (f\"{old_version}\\n\", \"yellow\"),\n                    (\"New version:     \", \"dim\"),\n                    (f\"{version}\", \"green bold\"),\n                    (\"\\n\\nIncrement type: \", \"dim\"),\n                    (f\"{increment_type}\", \"cyan\"),\n                ),\n                title=\"Bump\",\n                border_style=\"green\",\n                padding=(1, 2),\n            )\n            console.print(update_panel)\n\n            # Update metadata.json with new version\n            metadata[\"version\"] = version\n            with open(metadata_path, \"w\") as f:\n                json.dump(metadata, f, indent=2)\n\n            console.print(f\"\\n\u2705 Updated [bold]{metadata_path}[/bold] with new version\\n\")\n            console.print(Rule(style=\"dim\"))\n\n        elif exists and not bump_requested:\n            # Show error panel for version conflict\n            error_panel = Panel(\n                Text.assemble(\n                    (\"To upload a new version:\\n\", \"yellow\"),\n                    (f\"1. Edit {metadata_path}\\n\", \"dim\"),\n                    ('2. Update the \"version\" field (e.g., increment from \"0.0.1\" to \"0.0.2\")\\n', \"dim\"),\n                    (\"3. Try uploading again\\n\\n\", \"dim\"),\n                    (\"Or use the following flags:\\n\", \"yellow\"),\n                    (\"  --bump          # Patch update (0.0.1 \u2192 0.0.2)\\n\", \"green\"),\n                    (\"  --minor-bump    # Minor update (0.0.1 \u2192 0.1.0)\\n\", \"green\"),\n                    (\"  --major-bump    # Major update (0.0.1 \u2192 1.0.0)\\n\", \"green\"),\n                ),\n                title=\"Version Conflict\",\n                border_style=\"red\",\n            )\n            console.print(error_panel)\n            return None\n\n        # Version doesn't exist or has been bumped, proceed with upload\n        console.print(\n            f\"\\n\ud83d\udcc2 [bold]Uploading[/bold] version [green bold]{version}[/green bold] of [blue bold]{name}[/blue bold] to [cyan bold]{namespace}[/cyan bold]...\\n\"  # noqa: E501\n        )\n\n        try:\n            result = registry.upload(path, show_progress=True)\n\n            if result:\n                success_panel = Panel(\n                    Text.assemble(\n                        (\"Upload completed successfully! \ud83d\ude80 \\n\\n\", \"bold green\"),\n                        (\"Name:      \", \"dim\"),\n                        (f\"{result.name}\\n\", \"cyan\"),\n                        (\"Version:   \", \"dim\"),\n                        (f\"{result.version}\\n\", \"cyan\"),\n                        (\"Namespace: \", \"dim\"),\n                        (f\"{result.namespace}\", \"cyan\"),\n                    ),\n                    title=\"Success\",\n                    border_style=\"green\",\n                    padding=(1, 2),\n                )\n                console.print(success_panel)\n                return result\n            else:\n                console.print(\n                    Panel(\n                        Text(\"Upload failed for unknown reasons\", style=\"bold red\"),\n                        title=\"Upload Error\",\n                        border_style=\"red\",\n                        padding=(1, 2),\n                    )\n                )\n                return None\n\n        except Exception as e:\n            console.print(\n                Panel(\n                    Text(f\"Error during upload: {str(e)}\", style=\"bold red\"),\n                    title=\"Upload Error\",\n                    border_style=\"red\",\n                    padding=(1, 2),\n                )\n            )\n            return None\n\n    def download(self, entry_location: str, force: bool = False) -&gt; None:\n        \"\"\"Download item.\"\"\"\n        registry.download(entry_location, force=force, show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.download","title":"download","text":"<pre><code>download(entry_location: str, force: bool = False) -&gt; None\n</code></pre> <p>Download item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def download(self, entry_location: str, force: bool = False) -&gt; None:\n    \"\"\"Download item.\"\"\"\n    registry.download(entry_location, force=force, show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.info","title":"info","text":"<pre><code>info(entry: str) -&gt; None\n</code></pre> <p>Show information about an item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def info(self, entry: str) -&gt; None:\n    \"\"\"Show information about an item.\"\"\"\n    entry_location = parse_location(entry)\n    metadata = registry.info(entry_location)\n\n    if metadata is None:\n        print(f\"Entry {entry} not found.\")\n        return\n\n    print(metadata.model_dump_json(indent=2))\n    if metadata.category == \"model\":\n        available_provider_matches = ProviderModels(CONFIG.get_client_config()).available_provider_matches(\n            NamespacedName(name=metadata.name, namespace=entry_location.namespace)\n        )\n        if len(available_provider_matches) &gt; 0:\n            header = [\"provider\", \"name\"]\n\n            table = []\n            for provider, name in available_provider_matches.items():\n                table.append(\n                    [\n                        fill(provider),\n                        fill(name),\n                    ]\n                )\n            print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.list","title":"list","text":"<pre><code>list(\n    namespace: str = \"\",\n    category: str = \"\",\n    tags: str = \"\",\n    total: int = 32,\n    offset: int = 0,\n    show_all: bool = False,\n    show_latest_version: bool = True,\n    star: str = \"\",\n) -&gt; None\n</code></pre> <p>List available items.</p> Source code in <code>nearai/cli.py</code> <pre><code>def list(\n    self,\n    namespace: str = \"\",\n    category: str = \"\",\n    tags: str = \"\",\n    total: int = 32,\n    offset: int = 0,\n    show_all: bool = False,\n    show_latest_version: bool = True,\n    star: str = \"\",\n) -&gt; None:\n    \"\"\"List available items.\"\"\"\n    # Make sure tags is a comma-separated list of tags\n    tags_l = parse_tags(tags)\n    tags = \",\".join(tags_l)\n\n    entries = registry.list(\n        namespace=namespace,\n        category=category,\n        tags=tags,\n        total=total + 1,\n        offset=offset,\n        show_all=show_all,\n        show_latest_version=show_latest_version,\n        starred_by=star,\n    )\n\n    more_rows = len(entries) &gt; total\n    entries = entries[:total]\n\n    header = [\"entry\", \"category\", \"description\", \"tags\"]\n\n    table = []\n    for entry in entries:\n        table.append(\n            [\n                fill(f\"{entry.namespace}/{entry.name}/{entry.version}\"),\n                fill(entry.category, 20),\n                fill(entry.description, 50),\n                fill(\", \".join(entry.tags), 20),\n            ]\n        )\n\n    if more_rows:\n        table.append([\"...\", \"...\", \"...\", \"...\"])\n\n    print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n\n    if category == \"model\" and len(entries) &lt; total and namespace == \"\" and tags == \"\" and star == \"\":\n        unregistered_common_provider_models = ProviderModels(\n            CONFIG.get_client_config()\n        ).get_unregistered_common_provider_models(registry.dict_models())\n        if len(unregistered_common_provider_models):\n            print(\n                f\"There are unregistered common provider models: {unregistered_common_provider_models}. Run 'nearai registry upload-unregistered-common-provider-models' to update registry.\"  # noqa: E501\n            )\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.metadata_template","title":"metadata_template","text":"<pre><code>metadata_template(\n    local_path: str = \".\",\n    category: str = \"\",\n    description: str = \"\",\n)\n</code></pre> <p>Create a metadata template.</p> Source code in <code>nearai/cli.py</code> <pre><code>def metadata_template(self, local_path: str = \".\", category: str = \"\", description: str = \"\"):\n    \"\"\"Create a metadata template.\"\"\"\n    path = resolve_local_path(Path(local_path))\n\n    metadata_path = path / \"metadata.json\"\n\n    version = path.name\n    # Validate version format\n    is_valid, error = validate_version(version)\n    if not is_valid:\n        print(error)\n        return\n\n    name = path.parent.name\n    assert not re.match(PATTERN, name), f\"Invalid agent name: {name}\"\n    assert \" \" not in name\n\n    with open(metadata_path, \"w\") as f:\n        metadata: Dict[str, Any] = {\n            \"name\": name,\n            \"version\": version,\n            \"description\": description,\n            \"category\": category,\n            \"tags\": [],\n            \"details\": {},\n            \"show_entry\": True,\n        }\n\n        if category == \"agent\":\n            metadata[\"details\"][\"agent\"] = {}\n            metadata[\"details\"][\"agent\"][\"welcome\"] = {\n                \"title\": name,\n                \"description\": description,\n            }\n            metadata[\"details\"][\"agent\"][\"defaults\"] = {\n                \"model\": DEFAULT_MODEL,\n                \"model_provider\": DEFAULT_PROVIDER,\n                \"model_temperature\": DEFAULT_MODEL_TEMPERATURE,\n                \"model_max_tokens\": DEFAULT_MODEL_MAX_TOKENS,\n                \"max_iterations\": 1,\n            }\n            metadata[\"details\"][\"agent\"][\"framework\"] = \"minimal\"\n\n        json.dump(metadata, f, indent=2)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.update","title":"update","text":"<pre><code>update(local_path: str = '.') -&gt; None\n</code></pre> <p>Update metadata of a registry item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def update(self, local_path: str = \".\") -&gt; None:\n    \"\"\"Update metadata of a registry item.\"\"\"\n    path = resolve_local_path(Path(local_path))\n\n    if CONFIG.auth is None:\n        print(\"Please login with `nearai login`\")\n        exit(1)\n\n    metadata_path = path / \"metadata.json\"\n    check_metadata_present(metadata_path)\n\n    with open(metadata_path) as f:\n        metadata: Dict[str, Any] = json.load(f)\n\n    namespace = CONFIG.auth.namespace\n\n    entry_location = EntryLocation.model_validate(\n        dict(\n            namespace=namespace,\n            name=metadata.pop(\"name\"),\n            version=metadata.pop(\"version\"),\n        )\n    )\n    assert \" \" not in entry_location.name\n\n    entry_metadata = EntryMetadataInput.model_validate(metadata)\n    result = registry.update(entry_location, entry_metadata)\n    print(json.dumps(result, indent=2))\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.upload","title":"upload","text":"<pre><code>upload(\n    local_path: str = \".\",\n    bump: bool = False,\n    minor_bump: bool = False,\n    major_bump: bool = False,\n) -&gt; Optional[EntryLocation]\n</code></pre> <p>Upload item to the registry.</p> <pre><code>local_path: Path to the directory containing the agent to upload\nbump: If True, automatically increment patch version if it already exists\nminor_bump: If True, bump with minor version increment (0.1.0 \u2192 0.2.0)\nmajor_bump: If True, bump with major version increment (0.1.0 \u2192 1.0.0)\n</code></pre> <pre><code>EntryLocation if upload was successful, None otherwise\n</code></pre> Source code in <code>nearai/cli.py</code> <pre><code>def upload(\n    self, local_path: str = \".\", bump: bool = False, minor_bump: bool = False, major_bump: bool = False\n) -&gt; Optional[EntryLocation]:\n    \"\"\"Upload item to the registry.\n\n    Args:\n    ----\n        local_path: Path to the directory containing the agent to upload\n        bump: If True, automatically increment patch version if it already exists\n        minor_bump: If True, bump with minor version increment (0.1.0 \u2192 0.2.0)\n        major_bump: If True, bump with major version increment (0.1.0 \u2192 1.0.0)\n\n    Returns:\n    -------\n        EntryLocation if upload was successful, None otherwise\n\n    \"\"\"\n    console = Console()\n    path = resolve_local_path(Path(local_path))\n    metadata_path = path / \"metadata.json\"\n\n    # Load and validate metadata\n    metadata, error = load_and_validate_metadata(metadata_path)\n    if error:\n        console.print(\n            Panel(Text(error, style=\"bold red\"), title=\"Metadata Error\", border_style=\"red\", padding=(1, 2))\n        )\n        return None\n\n    # At this point, metadata is guaranteed to be not None\n    assert metadata is not None, \"Metadata should not be None if error is None\"\n\n    name = metadata[\"name\"]\n    version = metadata[\"version\"]\n\n    # Get namespace using the function from registry.py\n    try:\n        namespace = get_namespace(path)\n    except ValueError:\n        console.print(\n            Panel(\n                Text(\"Please login with `nearai login` before uploading\", style=\"bold red\"),\n                title=\"Authentication Error\",\n                border_style=\"red\",\n                padding=(1, 2),\n            )\n        )\n        return None\n\n    # Check if this version already exists\n    exists, error = check_version_exists(namespace, name, version)\n\n    if error:\n        console.print(\n            Panel(Text(error, style=\"bold red\"), title=\"Registry Error\", border_style=\"red\", padding=(1, 2))\n        )\n        return None\n\n    # Display the version check result\n    display_version_check(namespace, name, version, exists)\n\n    bump_requested = bump or minor_bump or major_bump\n\n    if exists and bump_requested:\n        # Handle version bump\n        old_version = version\n\n        # Determine increment type based on flags\n        if major_bump:\n            increment_type = \"major\"\n        elif minor_bump:\n            increment_type = \"minor\"\n        else:\n            increment_type = \"patch\"  # Default for bump\n\n        version = increment_version_by_type(version, increment_type)\n\n        # Enhanced version update message\n        update_panel = Panel(\n            Text.assemble(\n                (\"Updating Version...\\n\\n\", \"bold\"),\n                (\"Previous version: \", \"dim\"),\n                (f\"{old_version}\\n\", \"yellow\"),\n                (\"New version:     \", \"dim\"),\n                (f\"{version}\", \"green bold\"),\n                (\"\\n\\nIncrement type: \", \"dim\"),\n                (f\"{increment_type}\", \"cyan\"),\n            ),\n            title=\"Bump\",\n            border_style=\"green\",\n            padding=(1, 2),\n        )\n        console.print(update_panel)\n\n        # Update metadata.json with new version\n        metadata[\"version\"] = version\n        with open(metadata_path, \"w\") as f:\n            json.dump(metadata, f, indent=2)\n\n        console.print(f\"\\n\u2705 Updated [bold]{metadata_path}[/bold] with new version\\n\")\n        console.print(Rule(style=\"dim\"))\n\n    elif exists and not bump_requested:\n        # Show error panel for version conflict\n        error_panel = Panel(\n            Text.assemble(\n                (\"To upload a new version:\\n\", \"yellow\"),\n                (f\"1. Edit {metadata_path}\\n\", \"dim\"),\n                ('2. Update the \"version\" field (e.g., increment from \"0.0.1\" to \"0.0.2\")\\n', \"dim\"),\n                (\"3. Try uploading again\\n\\n\", \"dim\"),\n                (\"Or use the following flags:\\n\", \"yellow\"),\n                (\"  --bump          # Patch update (0.0.1 \u2192 0.0.2)\\n\", \"green\"),\n                (\"  --minor-bump    # Minor update (0.0.1 \u2192 0.1.0)\\n\", \"green\"),\n                (\"  --major-bump    # Major update (0.0.1 \u2192 1.0.0)\\n\", \"green\"),\n            ),\n            title=\"Version Conflict\",\n            border_style=\"red\",\n        )\n        console.print(error_panel)\n        return None\n\n    # Version doesn't exist or has been bumped, proceed with upload\n    console.print(\n        f\"\\n\ud83d\udcc2 [bold]Uploading[/bold] version [green bold]{version}[/green bold] of [blue bold]{name}[/blue bold] to [cyan bold]{namespace}[/cyan bold]...\\n\"  # noqa: E501\n    )\n\n    try:\n        result = registry.upload(path, show_progress=True)\n\n        if result:\n            success_panel = Panel(\n                Text.assemble(\n                    (\"Upload completed successfully! \ud83d\ude80 \\n\\n\", \"bold green\"),\n                    (\"Name:      \", \"dim\"),\n                    (f\"{result.name}\\n\", \"cyan\"),\n                    (\"Version:   \", \"dim\"),\n                    (f\"{result.version}\\n\", \"cyan\"),\n                    (\"Namespace: \", \"dim\"),\n                    (f\"{result.namespace}\", \"cyan\"),\n                ),\n                title=\"Success\",\n                border_style=\"green\",\n                padding=(1, 2),\n            )\n            console.print(success_panel)\n            return result\n        else:\n            console.print(\n                Panel(\n                    Text(\"Upload failed for unknown reasons\", style=\"bold red\"),\n                    title=\"Upload Error\",\n                    border_style=\"red\",\n                    padding=(1, 2),\n                )\n            )\n            return None\n\n    except Exception as e:\n        console.print(\n            Panel(\n                Text(f\"Error during upload: {str(e)}\", style=\"bold red\"),\n                title=\"Upload Error\",\n                border_style=\"red\",\n                padding=(1, 2),\n            )\n        )\n        return None\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.upload_unregistered_common_provider_models","title":"upload_unregistered_common_provider_models","text":"<pre><code>upload_unregistered_common_provider_models(\n    dry_run: bool = True,\n) -&gt; None\n</code></pre> <p>Creates new registry items for unregistered common provider models.</p> Source code in <code>nearai/cli.py</code> <pre><code>def upload_unregistered_common_provider_models(self, dry_run: bool = True) -&gt; None:\n    \"\"\"Creates new registry items for unregistered common provider models.\"\"\"\n    provider_matches_list = ProviderModels(CONFIG.get_client_config()).get_unregistered_common_provider_models(\n        registry.dict_models()\n    )\n    if len(provider_matches_list) == 0:\n        print(\"No new models to upload.\")\n        return\n\n    print(\"Going to create new registry items:\")\n    header = [\"entry\", \"description\"]\n    table = []\n    paths = []\n    for provider_matches in provider_matches_list:\n        provider_model = provider_matches.get(DEFAULT_PROVIDER) or next(iter(provider_matches.values()))\n        _, model = get_provider_namespaced_model(provider_model)\n        assert model.namespace == \"\"\n        model.name = create_registry_name(model.name)\n        model.namespace = DEFAULT_NAMESPACE\n        version = \"1.0.0\"\n        description = \" &amp; \".join(provider_matches.values())\n        table.append(\n            [\n                fill(f\"{model.namespace}/{model.name}/{version}\"),\n                fill(description, 50),\n            ]\n        )\n\n        path = get_registry_folder() / model.namespace / model.name / version\n        path.mkdir(parents=True, exist_ok=True)\n        paths.append(path)\n        metadata_path = path / \"metadata.json\"\n        with open(metadata_path, \"w\") as f:\n            metadata: Dict[str, Any] = {\n                \"name\": model.name,\n                \"version\": version,\n                \"description\": description,\n                \"category\": \"model\",\n                \"tags\": [],\n                \"details\": {},\n                \"show_entry\": True,\n            }\n            json.dump(metadata, f, indent=2)\n\n    print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n    if dry_run:\n        print(\"Please verify, then repeat the command with --dry_run=False\")\n    else:\n        for path in paths:\n            self.upload(str(path))\n</code></pre>"},{"location":"api/#nearai.cli.check_update","title":"check_update","text":"<pre><code>check_update()\n</code></pre> <p>Check if there is a new version of nearai CLI available.</p> Source code in <code>nearai/cli.py</code> <pre><code>def check_update():\n    \"\"\"Check if there is a new version of nearai CLI available.\"\"\"\n    try:\n        api = DefaultApi()\n        latest = api.version_v1_version_get()\n        current = importlib.metadata.version(\"nearai\")\n\n        if latest != current:\n            print(f\"New version of nearai CLI available: {latest}. Current version: {current}\")\n            print(\"Run `pip install --upgrade nearai` to update.\")\n\n    except Exception as _:\n        pass\n</code></pre>"},{"location":"api/#nearai.cli_helpers","title":"cli_helpers","text":""},{"location":"api/#nearai.cli_helpers.assert_user_auth","title":"assert_user_auth","text":"<pre><code>assert_user_auth() -&gt; None\n</code></pre> <p>Ensure the user is authenticated.</p>"},{"location":"api/#nearai.cli_helpers.assert_user_auth--raises","title":"Raises","text":"<pre><code>SystemExit: If the user is not authenticated\n</code></pre> Source code in <code>nearai/cli_helpers.py</code> <pre><code>def assert_user_auth() -&gt; None:\n    \"\"\"Ensure the user is authenticated.\n\n    Raises\n    ------\n        SystemExit: If the user is not authenticated\n\n    \"\"\"\n    from nearai.config import CONFIG\n\n    if CONFIG.auth is None:\n        print(\"Please login with `nearai login` first\")\n        exit(1)\n</code></pre>"},{"location":"api/#nearai.cli_helpers.display_agents_in_columns","title":"display_agents_in_columns","text":"<pre><code>display_agents_in_columns(agents: list[Path]) -&gt; None\n</code></pre> <p>Display agents in a rich table format.</p> <pre><code>agents: List of Path objects pointing to agent locations (pre-sorted)\n</code></pre> Source code in <code>nearai/cli_helpers.py</code> <pre><code>def display_agents_in_columns(agents: list[Path]) -&gt; None:\n    \"\"\"Display agents in a rich table format.\n\n    Args:\n    ----\n        agents: List of Path objects pointing to agent locations (pre-sorted)\n\n    \"\"\"\n    # Create table\n    table = Table(title=\"Available Agents\", show_header=True, header_style=\"bold\", show_lines=True, expand=True)\n\n    # Add columns\n    table.add_column(\"#\", style=\"bold\", width=4)\n    table.add_column(\"Namespace\", style=\"blue\")\n    table.add_column(\"Agent Name\", style=\"cyan\")\n    table.add_column(\"Version\", style=\"green\")\n    table.add_column(\"Description\", style=\"white\")\n    table.add_column(\"Tags\", style=\"yellow\")\n\n    # Add rows\n    for idx, agent_path in enumerate(agents, 1):\n        try:\n            # Read metadata for additional info\n            with open(agent_path / \"metadata.json\") as f:\n                metadata = json.load(f)\n                description = metadata.get(\"description\", \"No description\")\n                tags = metadata.get(\"tags\", [])\n        except (FileNotFoundError, json.JSONDecodeError):\n            description = \"Unable to load metadata\"\n            tags = []\n\n        # Add row to table with separated path components\n        table.add_row(\n            str(idx),\n            agent_path.parts[-3],  # namespace\n            agent_path.parts[-2],  # agent name\n            agent_path.parts[-1],  # version\n            description,\n            \", \".join(tags) if tags else \"\u2014\",\n        )\n\n    # Display table\n    console = Console()\n    console.print(\"\\n\")\n    console.print(table)\n    console.print(\"\\n\")\n</code></pre>"},{"location":"api/#nearai.cli_helpers.display_version_check","title":"display_version_check","text":"<pre><code>display_version_check(\n    namespace: str, name: str, version: str, exists: bool\n) -&gt; None\n</code></pre> <p>Display formatted message about version existence check.</p> <pre><code>namespace: The namespace\nname: The agent name\nversion: The version being checked\nexists: Whether the version exists\n</code></pre> Source code in <code>nearai/cli_helpers.py</code> <pre><code>def display_version_check(namespace: str, name: str, version: str, exists: bool) -&gt; None:\n    \"\"\"Display formatted message about version existence check.\n\n    Args:\n    ----\n        namespace: The namespace\n        name: The agent name\n        version: The version being checked\n        exists: Whether the version exists\n\n    \"\"\"\n    console = Console()\n    console.print(\n        Text.assemble(\n            (\"\\n\ud83d\udd0e Checking if version \", \"white\"),\n            (f\"{version}\", \"green bold\"),\n            (\" exists for \", \"white\"),\n            (f\"{name} \", \"blue bold\"),\n            (\"in the registry under \", \"white\"),\n            (f\"{namespace}\", \"cyan bold\"),\n            (\"...\", \"white\"),\n        )\n    )\n\n    if exists:\n        console.print(f\"\\n\u274c [yellow]Version [cyan]{version}[/cyan] already exists.[/yellow]\")\n    else:\n        console.print(f\"\\n\u2705 [green]Version [cyan]{version}[/cyan] is available.[/green]\")\n</code></pre>"},{"location":"api/#nearai.cli_helpers.has_pending_input","title":"has_pending_input","text":"<pre><code>has_pending_input()\n</code></pre> <p>Check if there's input waiting to be read without blocking.</p> Source code in <code>nearai/cli_helpers.py</code> <pre><code>def has_pending_input():\n    \"\"\"Check if there's input waiting to be read without blocking.\"\"\"\n    if os.name == \"nt\":  # Windows\n        import msvcrt\n\n        return msvcrt.kbhit()\n    else:  # Unix/Linux/Mac\n        rlist, _, _ = select.select([sys.stdin], [], [], 0)\n        return bool(rlist)\n</code></pre>"},{"location":"api/#nearai.cli_helpers.load_and_validate_metadata","title":"load_and_validate_metadata","text":"<pre><code>load_and_validate_metadata(\n    metadata_path: Path,\n) -&gt; Tuple[Optional[Dict[str, Any]], Optional[str]]\n</code></pre> <p>Load and validate metadata file, including version format.</p> <pre><code>metadata_path: Path to metadata.json file\n</code></pre> <pre><code>Tuple of (metadata_dict, error_message)\n</code></pre> Source code in <code>nearai/cli_helpers.py</code> <pre><code>def load_and_validate_metadata(metadata_path: Path) -&gt; Tuple[Optional[Dict[str, Any]], Optional[str]]:\n    \"\"\"Load and validate metadata file, including version format.\n\n    Args:\n    ----\n        metadata_path: Path to metadata.json file\n\n    Returns:\n    -------\n        Tuple of (metadata_dict, error_message)\n\n    \"\"\"\n    try:\n        with open(metadata_path) as f:\n            metadata = json.load(f)\n\n        # Validate version format\n        if \"version\" not in metadata:\n            return None, \"Metadata file must contain a 'version' field\"\n\n        is_valid, error = validate_version(metadata[\"version\"])\n        if not is_valid:\n            return None, error\n\n        return metadata, None\n    except FileNotFoundError:\n        return None, f\"Metadata file not found at {metadata_path}\"\n    except json.JSONDecodeError:\n        return None, f\"Invalid JSON in metadata file at {metadata_path}\"\n    except Exception as e:\n        return None, f\"Error reading metadata file: {str(e)}\"\n</code></pre>"},{"location":"api/#nearai.config","title":"config","text":""},{"location":"api/#nearai.config.Config","title":"Config","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/config.py</code> <pre><code>class Config(BaseModel):\n    origin: Optional[str] = None\n    api_url: Optional[str] = \"https://api.near.ai\"\n    inference_url: str = \"http://localhost:5000/v1/\"\n    inference_api_key: str = \"n/a\"\n    scheduler_account_id: str = \"nearaischeduler.near\"\n    nearai_hub: NearAiHubConfig = NearAiHubConfig()\n    confirm_commands: bool = True\n    auth: Optional[AuthData] = None\n    num_inference_retries: int = 1\n\n    def update_with(self, extra_config: Dict[str, Any], map_key: Callable[[str], str] = lambda x: x) -&gt; \"Config\":\n        \"\"\"Update the config with the given dictionary.\"\"\"\n        dict_repr = self.model_dump()\n        keys = list(map(map_key, dict_repr.keys()))\n\n        for key in keys:\n            value = extra_config.get(key, None)\n\n            if value:\n                # This will skip empty values, even if they are set in the `extra_config`\n                dict_repr[key] = value\n\n        return Config.model_validate(dict_repr)\n\n    def get(self, key: str, default: Optional[Any] = None) -&gt; Optional[Any]:\n        \"\"\"Get the value of a key in the config if it exists.\"\"\"\n        return getattr(self, key, default)\n\n    def get_client_config(self) -&gt; ClientConfig:  # noqa: D102\n        return ClientConfig(\n            base_url=self.nearai_hub.base_url,\n            auth=self.auth,\n            custom_llm_provider=self.nearai_hub.custom_llm_provider,\n            default_provider=self.nearai_hub.default_provider,\n            num_inference_retries=self.num_inference_retries,\n        )\n</code></pre>"},{"location":"api/#nearai.config.Config.get","title":"get","text":"<pre><code>get(\n    key: str, default: Optional[Any] = None\n) -&gt; Optional[Any]\n</code></pre> <p>Get the value of a key in the config if it exists.</p> Source code in <code>nearai/config.py</code> <pre><code>def get(self, key: str, default: Optional[Any] = None) -&gt; Optional[Any]:\n    \"\"\"Get the value of a key in the config if it exists.\"\"\"\n    return getattr(self, key, default)\n</code></pre>"},{"location":"api/#nearai.config.Config.update_with","title":"update_with","text":"<pre><code>update_with(\n    extra_config: Dict[str, Any],\n    map_key: Callable[[str], str] = lambda x: x,\n) -&gt; Config\n</code></pre> <p>Update the config with the given dictionary.</p> Source code in <code>nearai/config.py</code> <pre><code>def update_with(self, extra_config: Dict[str, Any], map_key: Callable[[str], str] = lambda x: x) -&gt; \"Config\":\n    \"\"\"Update the config with the given dictionary.\"\"\"\n    dict_repr = self.model_dump()\n    keys = list(map(map_key, dict_repr.keys()))\n\n    for key in keys:\n        value = extra_config.get(key, None)\n\n        if value:\n            # This will skip empty values, even if they are set in the `extra_config`\n            dict_repr[key] = value\n\n    return Config.model_validate(dict_repr)\n</code></pre>"},{"location":"api/#nearai.config.NearAiHubConfig","title":"NearAiHubConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>NearAiHub Config.</p> <p>login_with_near (Optional[bool]): Indicates whether to attempt login using Near Auth.</p> <p>api_key (Optional[str]): The API key to use if Near Auth is not being utilized</p> <p>base_url (Optional[str]): NEAR AI Hub url</p> <p>default_provider (Optional[str]): Default provider name</p> <p>default_model (Optional[str]): Default model name</p> <p>custom_llm_provider (Optional[str]): provider to be used by litellm proxy</p> Source code in <code>nearai/config.py</code> <pre><code>class NearAiHubConfig(BaseModel):\n    \"\"\"NearAiHub Config.\n\n    login_with_near (Optional[bool]): Indicates whether to attempt login using Near Auth.\n\n    api_key (Optional[str]): The API key to use if Near Auth is not being utilized\n\n    base_url (Optional[str]): NEAR AI Hub url\n\n    default_provider (Optional[str]): Default provider name\n\n    default_model (Optional[str]): Default model name\n\n    custom_llm_provider (Optional[str]): provider to be used by litellm proxy\n    \"\"\"\n\n    base_url: str = \"https://api.near.ai/v1\"\n    default_provider: str = DEFAULT_PROVIDER\n    default_model: str = DEFAULT_PROVIDER_MODEL\n    custom_llm_provider: str = \"openai\"\n    login_with_near: Optional[bool] = True\n    api_key: Optional[str] = \"\"\n</code></pre>"},{"location":"api/#nearai.dataset","title":"dataset","text":""},{"location":"api/#nearai.dataset.get_dataset","title":"get_dataset","text":"<pre><code>get_dataset(name: str, verbose: bool = True) -&gt; Path\n</code></pre> <p>Download the dataset from the registry and download it locally if it hasn't been downloaded yet.</p> <p>:param name: The name of the entry to download the dataset. The format should be namespace/name/version. :return: The path to the downloaded dataset</p> Source code in <code>nearai/dataset.py</code> <pre><code>def get_dataset(name: str, verbose: bool = True) -&gt; Path:\n    \"\"\"Download the dataset from the registry and download it locally if it hasn't been downloaded yet.\n\n    :param name: The name of the entry to download the dataset. The format should be namespace/name/version.\n    :return: The path to the downloaded dataset\n    \"\"\"\n    return registry.download(name, verbose=verbose)\n</code></pre>"},{"location":"api/#nearai.dataset.load_dataset","title":"load_dataset","text":"<pre><code>load_dataset(\n    alias_or_name: str, verbose: bool = True\n) -&gt; Union[Dataset, DatasetDict]\n</code></pre> <p>Load a dataset from the registry.</p> Source code in <code>nearai/dataset.py</code> <pre><code>def load_dataset(alias_or_name: str, verbose: bool = True) -&gt; Union[Dataset, DatasetDict]:\n    \"\"\"Load a dataset from the registry.\"\"\"\n    path = get_dataset(alias_or_name, verbose=verbose)\n    return load_from_disk(path.as_posix())\n</code></pre>"},{"location":"api/#nearai.delegation","title":"delegation","text":""},{"location":"api/#nearai.delegation.OnBehalfOf","title":"OnBehalfOf","text":"<p>Create a context manager that allows you to delegate actions to another account.</p> <pre><code>with OnBehalfOf(\"scheduler.ai\"):\n    # Upload is done on behalf of scheduler.ai\n    # If delegation permission is not granted, this will raise an exception\n    registry.upload()\n</code></pre> Source code in <code>nearai/delegation.py</code> <pre><code>class OnBehalfOf:\n    \"\"\"Create a context manager that allows you to delegate actions to another account.\n\n    ```python\n    with OnBehalfOf(\"scheduler.ai\"):\n        # Upload is done on behalf of scheduler.ai\n        # If delegation permission is not granted, this will raise an exception\n        registry.upload()\n    ```\n    \"\"\"\n\n    def __init__(self, on_behalf_of: str):\n        \"\"\"Context manager that creates a scope where all actions are done on behalf of another account.\"\"\"\n        self.target_on_behalf_of = on_behalf_of\n        self.original_access_token = None\n\n    def __enter__(self):\n        \"\"\"Set the default client to the account we are acting on behalf of.\"\"\"\n        default_client = ApiClient.get_default()\n        self.original_access_token = default_client.configuration.access_token\n\n        if not isinstance(self.original_access_token, str):\n            return\n\n        assert self.original_access_token.startswith(\"Bearer \")\n        auth = self.original_access_token[len(\"Bearer \") :]\n        auth_data = AuthData.model_validate_json(auth)\n        auth_data.on_behalf_of = self.target_on_behalf_of\n        new_access_token = f\"Bearer {auth_data.generate_bearer_token()}\"\n        default_client.configuration.access_token = new_access_token\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Reset the default client to the original account.\"\"\"\n        default_client = ApiClient.get_default()\n        default_client.configuration.access_token = self.original_access_token\n        self.original_access_token = None\n</code></pre>"},{"location":"api/#nearai.delegation.OnBehalfOf.__enter__","title":"__enter__","text":"<pre><code>__enter__()\n</code></pre> <p>Set the default client to the account we are acting on behalf of.</p> Source code in <code>nearai/delegation.py</code> <pre><code>def __enter__(self):\n    \"\"\"Set the default client to the account we are acting on behalf of.\"\"\"\n    default_client = ApiClient.get_default()\n    self.original_access_token = default_client.configuration.access_token\n\n    if not isinstance(self.original_access_token, str):\n        return\n\n    assert self.original_access_token.startswith(\"Bearer \")\n    auth = self.original_access_token[len(\"Bearer \") :]\n    auth_data = AuthData.model_validate_json(auth)\n    auth_data.on_behalf_of = self.target_on_behalf_of\n    new_access_token = f\"Bearer {auth_data.generate_bearer_token()}\"\n    default_client.configuration.access_token = new_access_token\n</code></pre>"},{"location":"api/#nearai.delegation.OnBehalfOf.__exit__","title":"__exit__","text":"<pre><code>__exit__(exc_type, exc_val, exc_tb)\n</code></pre> <p>Reset the default client to the original account.</p> Source code in <code>nearai/delegation.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Reset the default client to the original account.\"\"\"\n    default_client = ApiClient.get_default()\n    default_client.configuration.access_token = self.original_access_token\n    self.original_access_token = None\n</code></pre>"},{"location":"api/#nearai.delegation.OnBehalfOf.__init__","title":"__init__","text":"<pre><code>__init__(on_behalf_of: str)\n</code></pre> <p>Context manager that creates a scope where all actions are done on behalf of another account.</p> Source code in <code>nearai/delegation.py</code> <pre><code>def __init__(self, on_behalf_of: str):\n    \"\"\"Context manager that creates a scope where all actions are done on behalf of another account.\"\"\"\n    self.target_on_behalf_of = on_behalf_of\n    self.original_access_token = None\n</code></pre>"},{"location":"api/#nearai.delegation.check_on_behalf_of","title":"check_on_behalf_of","text":"<pre><code>check_on_behalf_of()\n</code></pre> <p>Check if the request is being made on behalf of another account.</p> Source code in <code>nearai/delegation.py</code> <pre><code>def check_on_behalf_of():\n    \"\"\"Check if the request is being made on behalf of another account.\"\"\"\n    api = DelegationApi()\n    return api.api_client.configuration.access_token\n</code></pre>"},{"location":"api/#nearai.delegation.revoke_delegation","title":"revoke_delegation","text":"<pre><code>revoke_delegation(delegate_account_id: str)\n</code></pre> <p>Revoke delegation to a specific account.</p> Source code in <code>nearai/delegation.py</code> <pre><code>def revoke_delegation(delegate_account_id: str):\n    \"\"\"Revoke delegation to a specific account.\"\"\"\n    DelegationApi().revoke_delegation_v1_delegation_revoke_delegation_post(delegate_account_id)\n</code></pre>"},{"location":"api/#nearai.evaluation","title":"evaluation","text":""},{"location":"api/#nearai.evaluation._print_metrics_tables","title":"_print_metrics_tables","text":"<pre><code>_print_metrics_tables(\n    rows: List[Dict[str, str]],\n    metric_names: List[str],\n    num_columns: int,\n    all_key_columns: bool,\n    metric_name_max_length: int,\n)\n</code></pre> <p>Builds table(s) and prints them.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def _print_metrics_tables(\n    rows: List[Dict[str, str]],\n    metric_names: List[str],\n    num_columns: int,\n    all_key_columns: bool,\n    metric_name_max_length: int,\n):\n    \"\"\"Builds table(s) and prints them.\"\"\"\n    # Shorten metric names\n    short_metric_names = [_shorten_metric_name(name, metric_name_max_length) for name in metric_names]\n\n    # Prepare the base header and rows\n    base_header = [\"model\", \"agent\"]\n    if all_key_columns:\n        base_header.extend([\"namespace\", \"version\", \"provider\"])\n\n    base_rows = []\n    for row in rows:\n        base_row = [fill(row.pop(\"model\", \"\")), fill(row.pop(\"agent\", \"\"))]\n        namespace = row.pop(\"namespace\", \"\")\n        version = row.pop(\"version\", \"\")\n        provider = row.pop(\"provider\", \"\")\n        if all_key_columns:\n            base_row.extend([fill(namespace), fill(version), fill(provider)])\n        base_rows.append((base_row, row))\n\n    n_metrics_per_table = max(1, num_columns - len(base_header))\n    # Split metrics into groups\n    metric_groups = list(\n        zip(\n            [\n                short_metric_names[i : i + n_metrics_per_table]\n                for i in range(0, len(short_metric_names), n_metrics_per_table)\n            ],\n            [metric_names[i : i + n_metrics_per_table] for i in range(0, len(metric_names), n_metrics_per_table)],\n        )\n    )\n\n    # Print tables\n    for short_group, full_group in metric_groups:\n        header = base_header + short_group\n        table = []\n        for base_row, row_metrics in base_rows:\n            table_row = base_row + [fill(str(row_metrics.get(metric, \"\"))) for metric in full_group]\n            table.append(table_row)\n        print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n</code></pre>"},{"location":"api/#nearai.evaluation._shorten_metric_name","title":"_shorten_metric_name","text":"<pre><code>_shorten_metric_name(name: str, max_length: int) -&gt; str\n</code></pre> <p>Shortens metric name if needed.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def _shorten_metric_name(name: str, max_length: int) -&gt; str:\n    \"\"\"Shortens metric name if needed.\"\"\"\n    if len(name) &lt;= max_length:\n        return name\n    keep = max_length - 2  # 2 dots\n    beginning = keep // 3\n    ending = keep - beginning\n    return name[:beginning] + \"..\" + name[-ending:]\n</code></pre>"},{"location":"api/#nearai.evaluation.load_benchmark_entry_info","title":"load_benchmark_entry_info","text":"<pre><code>load_benchmark_entry_info(info: str) -&gt; Any\n</code></pre> <p>Deserializes benchmark info entry from db data.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def load_benchmark_entry_info(info: str) -&gt; Any:\n    \"\"\"Deserializes benchmark info entry from db data.\"\"\"\n    first_decode = json.loads(info)\n    try:\n        second_decode = json.loads(first_decode)\n        return second_decode\n    except json.JSONDecodeError as e:\n        if \"Unterminated string\" in str(e):\n            last_brace = first_decode.rfind(\"}\")\n            if last_brace != -1:\n                try:\n                    return json.loads(first_decode[: last_brace + 1])\n                except json.JSONDecodeError as e:\n                    pass\n    return first_decode\n</code></pre>"},{"location":"api/#nearai.evaluation.print_evaluation_table","title":"print_evaluation_table","text":"<pre><code>print_evaluation_table(\n    rows: List[Dict[str, str]],\n    columns: List[str],\n    important_columns: List[str],\n    all_key_columns: bool,\n    all_metrics: bool,\n    num_columns: int,\n    metric_name_max_length: int,\n) -&gt; None\n</code></pre> <p>Prints table of evaluations.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def print_evaluation_table(\n    rows: List[Dict[str, str]],\n    columns: List[str],\n    important_columns: List[str],\n    all_key_columns: bool,\n    all_metrics: bool,\n    num_columns: int,\n    metric_name_max_length: int,\n) -&gt; None:\n    \"\"\"Prints table of evaluations.\"\"\"\n    metric_names = columns[5:] if all_metrics else important_columns[2:]\n    _print_metrics_tables(rows, metric_names, num_columns, all_key_columns, metric_name_max_length)\n</code></pre>"},{"location":"api/#nearai.evaluation.record_evaluation_metrics","title":"record_evaluation_metrics","text":"<pre><code>record_evaluation_metrics(\n    solver_strategy: SolverStrategy,\n    benchmark_id: int,\n    data_tasks: Union[Dataset, List[dict]],\n    metrics: Dict[str, Any],\n    prepend_evaluation_name: bool = True,\n) -&gt; None\n</code></pre> <p>Uploads evaluation metrics into registry.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def record_evaluation_metrics(\n    solver_strategy: SolverStrategy,\n    benchmark_id: int,\n    data_tasks: Union[Dataset, List[dict]],\n    metrics: Dict[str, Any],\n    prepend_evaluation_name: bool = True,\n) -&gt; None:\n    \"\"\"Uploads evaluation metrics into registry.\"\"\"\n    evaluation_name = solver_strategy.evaluation_name()\n    model = \"\"\n    agent = \"\"\n    version = \"\"\n    model = solver_strategy.model_name\n    agent = solver_strategy.agent_name()\n    version = solver_strategy.agent_version()\n\n    upload_evaluation(\n        evaluation_name,\n        benchmark_id,\n        data_tasks,\n        metrics if not prepend_evaluation_name else _prepend_name_to_metrics(evaluation_name, metrics),\n        model,\n        agent,\n        solver_strategy.evaluated_entry_namespace(),\n        version,\n        solver_strategy.model_provider(),\n    )\n</code></pre>"},{"location":"api/#nearai.evaluation.record_single_score_evaluation","title":"record_single_score_evaluation","text":"<pre><code>record_single_score_evaluation(\n    solver_strategy: SolverStrategy,\n    benchmark_id: int,\n    data_tasks: Union[Dataset, List[dict]],\n    score: float,\n) -&gt; None\n</code></pre> <p>Uploads single score evaluation into registry.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def record_single_score_evaluation(\n    solver_strategy: SolverStrategy, benchmark_id: int, data_tasks: Union[Dataset, List[dict]], score: float\n) -&gt; None:\n    \"\"\"Uploads single score evaluation into registry.\"\"\"\n    evaluation_name = solver_strategy.evaluation_name()\n    record_evaluation_metrics(solver_strategy, benchmark_id, data_tasks, {evaluation_name: score}, False)\n</code></pre>"},{"location":"api/#nearai.evaluation.upload_evaluation","title":"upload_evaluation","text":"<pre><code>upload_evaluation(\n    evaluation_name: str,\n    benchmark_id: int,\n    data_tasks: Union[Dataset, List[dict]],\n    metrics: Dict[str, Any],\n    model: str = \"\",\n    agent: str = \"\",\n    namespace: str = \"\",\n    version: str = \"\",\n    provider: str = \"\",\n) -&gt; None\n</code></pre> <p>Uploads evaluation into registry.</p> <p><code>evaluation_name</code>: a unique name for (benchmark, solver) tuple, e.g. \"mbpp\" or \"live_bench\" or \"mmlu-5-shot\". <code>metrics</code>: metrics from evaluation. <code>model</code>: model that was used. <code>agent</code>: agent that was evaluated, in any. <code>namespace</code>: namespace of evaluated agent or evaluated model. <code>version</code>: version of evaluated agent or evaluated model. <code>provider</code>: provider of model used; pass <code>local</code> if running locally.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def upload_evaluation(\n    evaluation_name: str,\n    benchmark_id: int,\n    data_tasks: Union[Dataset, List[dict]],\n    metrics: Dict[str, Any],\n    model: str = \"\",\n    agent: str = \"\",\n    namespace: str = \"\",\n    version: str = \"\",\n    provider: str = \"\",\n) -&gt; None:\n    \"\"\"Uploads evaluation into registry.\n\n    `evaluation_name`: a unique name for (benchmark, solver) tuple, e.g. \"mbpp\" or \"live_bench\" or \"mmlu-5-shot\".\n    `metrics`: metrics from evaluation.\n    `model`: model that was used.\n    `agent`: agent that was evaluated, in any.\n    `namespace`: namespace of evaluated agent or evaluated model.\n    `version`: version of evaluated agent or evaluated model.\n    `provider`: provider of model used; pass `local` if running locally.\n    \"\"\"\n    key = f\"evaluation_{evaluation_name}\"\n    metrics[EVALUATED_ENTRY_METADATA] = {}\n    if agent != \"\":\n        metrics[EVALUATED_ENTRY_METADATA][\"agent\"] = agent\n        key += f\"_agent_{agent}\"\n    if model != \"\":\n        metrics[EVALUATED_ENTRY_METADATA][\"model\"] = model\n        key += f\"_model_{model}\"\n    if namespace != \"\":\n        metrics[EVALUATED_ENTRY_METADATA][\"namespace\"] = namespace\n        key += f\"_namespace_{namespace}\"\n    if version != \"\":\n        metrics[EVALUATED_ENTRY_METADATA][\"version\"] = version\n        key += f\"_version_{version}\"\n    if provider != \"\":\n        metrics[EVALUATED_ENTRY_METADATA][\"provider\"] = provider\n        # Url providers like 'https://api.openai.com/v1' can't be included into registry entry name\n        # because of special characters.\n        clean_provider = re.sub(r\"[^a-zA-Z0-9_\\-.]\", \"_\", provider)\n        key += f\"_provider_{clean_provider}\"\n\n    entry_path = get_registry_folder() / key\n    # Create folder entry_path if not present\n    entry_path.mkdir(parents=True, exist_ok=True)\n    # Write file metrics.json inside\n    metrics_file = entry_path / \"metrics.json\"\n    with metrics_file.open(\"w\") as f:\n        json.dump(metrics, f, indent=2)\n\n    # Get solutions from cache in benchmark.py\n    cache = BenchmarkApi().get_benchmark_result_v1_benchmark_get_result_get(benchmark_id)\n    solutions = []\n    for result in cache:\n        try:\n            solution = {\n                \"datum\": data_tasks[result.index],\n                \"status\": result.solved,\n                \"info\": load_benchmark_entry_info(result.info) if result.info else {},\n            }\n            solutions.append(solution)\n        except (AttributeError, json.JSONDecodeError, TypeError) as e:\n            print(f\"Exception while creating solutions data: {str(e)}.\")\n            # Skip entries that can't be properly formatted\n            continue\n\n    # Write solutions file\n    solutions_file = entry_path / \"solutions.json\"\n    with solutions_file.open(\"w\") as f:\n        json.dump(solutions, f, indent=2)\n\n    metadata_path = entry_path / \"metadata.json\"\n    # TODO(#273): Currently that will not update existing evaluation.\n    with open(metadata_path, \"w\") as f:\n        json.dump(\n            {\n                \"name\": key,\n                \"version\": \"0.1.0\",\n                \"description\": \"\",\n                \"category\": \"evaluation\",\n                \"tags\": [],\n                \"details\": {},\n                \"show_entry\": True,\n            },\n            f,\n            indent=2,\n        )\n\n    registry.upload(Path(entry_path), show_progress=True)\n</code></pre>"},{"location":"api/#nearai.finetune","title":"finetune","text":""},{"location":"api/#nearai.finetune.FinetuneCli","title":"FinetuneCli","text":"Source code in <code>nearai/finetune/__init__.py</code> <pre><code>class FinetuneCli:\n    def start(\n        self,\n        model: str,\n        tokenizer: str,\n        dataset: str,\n        num_procs: int,\n        format: str,\n        upload_checkpoint: bool = True,\n        num_nodes: int = 1,\n        job_id: Optional[str] = None,\n        checkpoint: Optional[str] = None,\n        **dataset_kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Start a finetuning job on the current node.\n\n        Args:\n        ----\n            model: Name of a model in the registry. Base model to finetune.\n            tokenizer: Name of a tokenizer in the registry. Using tokenizer.model format.\n            dataset: Name of a dataset in the registry.\n            num_procs: Number of GPUs to use for training\n            format: Name of the configuration file to use. For example llama3-70b, llama3-8b. Valid options are in etc/finetune.\n            upload_checkpoint: Whether to upload the checkpoint to the registry. Default is True.\n            num_nodes: Number of nodes to use for training. Default is 1.\n            job_id: Unique identifier for the job. Default is None.\n            checkpoint: Name of the model checkpoint to start from. Default is None.\n            dataset_kwargs: Additional keyword arguments to pass to the dataset constructor.\n\n        \"\"\"  # noqa: E501\n        from nearai.dataset import get_dataset\n\n        assert num_nodes &gt;= 1\n\n        # Prepare job id folder\n        if job_id is None:\n            job_id = \"job\"\n        job_id = f\"{job_id}-{timestamp()}-{randint(10**8, 10**9 - 1)}\"\n        job_folder = DATA_FOLDER / \"finetune\" / job_id\n        job_folder.mkdir(parents=True, exist_ok=True)\n\n        # Either use the provided config file template or load one predefined one\n        if Path(format).exists():\n            config_template_path = Path(format)\n        else:\n            configs = ETC_FOLDER / \"finetune\"\n            config_template_path = configs / f\"{format}.yml\"\n\n        if not config_template_path.exists():\n            raise FileNotFoundError(f\"Config file not found: {config_template_path}\")\n\n        CONFIG_TEMPLATE = config_template_path.read_text()  # noqa: N806\n\n        # Download model\n        model_path = get_model(model)\n\n        # Download tokenizer\n        tokenizer_path = registry.download(tokenizer) / \"tokenizer.model\"\n        assert tokenizer_path.exists(), f\"tokenizer.model not found in {tokenizer_path}\"\n\n        # Download checkpoint if any\n        checkpoint_path = get_model(checkpoint) if checkpoint else \"null\"\n        resume_checkpoint = checkpoint_path != \"null\"\n\n        # Download dataset\n        dataset_path = get_dataset(dataset)\n\n        # Set up output directories\n        checkpoint_output_dir = job_folder / \"checkpoint_output\"\n        logging_output_dir = job_folder / \"logs\"\n        logging_output_dir.mkdir(parents=True, exist_ok=True)\n\n        # Prepare config file\n        dataset_args_dict = deepcopy(dataset_kwargs)\n\n        dataset_args_dict[\"_component_\"] = dataset_args_dict.pop(\"method\")\n        dataset_args_dict[\"source\"] = str(dataset_path.absolute())\n        dataset_args = \"\\n\".join(f\"  {key}: {value}\" for key, value in dataset_args_dict.items())\n\n        config = job_folder / \"config.yaml\"\n        with open(config, \"w\") as f:\n            f.write(\n                CONFIG_TEMPLATE.format(\n                    TOKENIZER=str(tokenizer_path),\n                    MODEL=str(model_path),\n                    RECIPE_CHECKPOINT=checkpoint_path,\n                    RESUME_FROM_CHECKPOINT=resume_checkpoint,\n                    CHECKPOINT_OUTPUT_DIR=str(checkpoint_output_dir),\n                    DATASET_ARGS=dataset_args,\n                    LOGGING_OUTPUT_DIR=str(logging_output_dir),\n                )\n            )\n\n        # Spawn background thread to read logs and push to database\n        threading.Thread(target=find_new_logs_background, args=(logging_output_dir, job_id)).start()\n\n        print(\"Starting job at\", job_folder)\n        if num_nodes == 1:\n            run(\n                [\n                    \"tune\",\n                    \"run\",\n                    \"--nproc_per_node\",\n                    str(num_procs),\n                    \"lora_finetune_distributed\",\n                    \"--config\",\n                    str(config),\n                ]\n            )\n        else:\n            # Fetch rank and master addr from environment variables\n            raise NotImplementedError()\n\n        global BACKGROUND_PROCESS\n        BACKGROUND_PROCESS = False\n\n        if upload_checkpoint:\n            registry.upload(\n                job_folder,\n                EntryMetadata.from_dict(\n                    {\n                        \"name\": f\"finetune-{job_id}\",\n                        \"version\": \"0.0.1\",\n                        \"description\": f\"Finetuned checkpoint from base mode {model} using dataset {dataset}\",\n                        \"category\": \"finetune\",\n                        \"tags\": [\"finetune\", f\"base-model-{model}\", f\"base-dataset-{dataset}\"],\n                        \"details\": dict(\n                            model=model,\n                            tokenizer=tokenizer,\n                            dataset=dataset,\n                            num_procs=num_procs,\n                            format=format,\n                            num_nodes=num_nodes,\n                            checkpoint=checkpoint,\n                            **dataset_kwargs,\n                        ),\n                        \"show_entry\": True,\n                    }\n                ),\n                show_progress=True,\n            )\n\n    def inspect(self, job_id: str) -&gt; None:  # noqa: D102\n        raise NotImplementedError()\n</code></pre>"},{"location":"api/#nearai.finetune.FinetuneCli.start","title":"start","text":"<pre><code>start(\n    model: str,\n    tokenizer: str,\n    dataset: str,\n    num_procs: int,\n    format: str,\n    upload_checkpoint: bool = True,\n    num_nodes: int = 1,\n    job_id: Optional[str] = None,\n    checkpoint: Optional[str] = None,\n    **dataset_kwargs: Any,\n) -&gt; None\n</code></pre> <p>Start a finetuning job on the current node.</p> <pre><code>model: Name of a model in the registry. Base model to finetune.\ntokenizer: Name of a tokenizer in the registry. Using tokenizer.model format.\ndataset: Name of a dataset in the registry.\nnum_procs: Number of GPUs to use for training\nformat: Name of the configuration file to use. For example llama3-70b, llama3-8b. Valid options are in etc/finetune.\nupload_checkpoint: Whether to upload the checkpoint to the registry. Default is True.\nnum_nodes: Number of nodes to use for training. Default is 1.\njob_id: Unique identifier for the job. Default is None.\ncheckpoint: Name of the model checkpoint to start from. Default is None.\ndataset_kwargs: Additional keyword arguments to pass to the dataset constructor.\n</code></pre> Source code in <code>nearai/finetune/__init__.py</code> <pre><code>def start(\n    self,\n    model: str,\n    tokenizer: str,\n    dataset: str,\n    num_procs: int,\n    format: str,\n    upload_checkpoint: bool = True,\n    num_nodes: int = 1,\n    job_id: Optional[str] = None,\n    checkpoint: Optional[str] = None,\n    **dataset_kwargs: Any,\n) -&gt; None:\n    \"\"\"Start a finetuning job on the current node.\n\n    Args:\n    ----\n        model: Name of a model in the registry. Base model to finetune.\n        tokenizer: Name of a tokenizer in the registry. Using tokenizer.model format.\n        dataset: Name of a dataset in the registry.\n        num_procs: Number of GPUs to use for training\n        format: Name of the configuration file to use. For example llama3-70b, llama3-8b. Valid options are in etc/finetune.\n        upload_checkpoint: Whether to upload the checkpoint to the registry. Default is True.\n        num_nodes: Number of nodes to use for training. Default is 1.\n        job_id: Unique identifier for the job. Default is None.\n        checkpoint: Name of the model checkpoint to start from. Default is None.\n        dataset_kwargs: Additional keyword arguments to pass to the dataset constructor.\n\n    \"\"\"  # noqa: E501\n    from nearai.dataset import get_dataset\n\n    assert num_nodes &gt;= 1\n\n    # Prepare job id folder\n    if job_id is None:\n        job_id = \"job\"\n    job_id = f\"{job_id}-{timestamp()}-{randint(10**8, 10**9 - 1)}\"\n    job_folder = DATA_FOLDER / \"finetune\" / job_id\n    job_folder.mkdir(parents=True, exist_ok=True)\n\n    # Either use the provided config file template or load one predefined one\n    if Path(format).exists():\n        config_template_path = Path(format)\n    else:\n        configs = ETC_FOLDER / \"finetune\"\n        config_template_path = configs / f\"{format}.yml\"\n\n    if not config_template_path.exists():\n        raise FileNotFoundError(f\"Config file not found: {config_template_path}\")\n\n    CONFIG_TEMPLATE = config_template_path.read_text()  # noqa: N806\n\n    # Download model\n    model_path = get_model(model)\n\n    # Download tokenizer\n    tokenizer_path = registry.download(tokenizer) / \"tokenizer.model\"\n    assert tokenizer_path.exists(), f\"tokenizer.model not found in {tokenizer_path}\"\n\n    # Download checkpoint if any\n    checkpoint_path = get_model(checkpoint) if checkpoint else \"null\"\n    resume_checkpoint = checkpoint_path != \"null\"\n\n    # Download dataset\n    dataset_path = get_dataset(dataset)\n\n    # Set up output directories\n    checkpoint_output_dir = job_folder / \"checkpoint_output\"\n    logging_output_dir = job_folder / \"logs\"\n    logging_output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Prepare config file\n    dataset_args_dict = deepcopy(dataset_kwargs)\n\n    dataset_args_dict[\"_component_\"] = dataset_args_dict.pop(\"method\")\n    dataset_args_dict[\"source\"] = str(dataset_path.absolute())\n    dataset_args = \"\\n\".join(f\"  {key}: {value}\" for key, value in dataset_args_dict.items())\n\n    config = job_folder / \"config.yaml\"\n    with open(config, \"w\") as f:\n        f.write(\n            CONFIG_TEMPLATE.format(\n                TOKENIZER=str(tokenizer_path),\n                MODEL=str(model_path),\n                RECIPE_CHECKPOINT=checkpoint_path,\n                RESUME_FROM_CHECKPOINT=resume_checkpoint,\n                CHECKPOINT_OUTPUT_DIR=str(checkpoint_output_dir),\n                DATASET_ARGS=dataset_args,\n                LOGGING_OUTPUT_DIR=str(logging_output_dir),\n            )\n        )\n\n    # Spawn background thread to read logs and push to database\n    threading.Thread(target=find_new_logs_background, args=(logging_output_dir, job_id)).start()\n\n    print(\"Starting job at\", job_folder)\n    if num_nodes == 1:\n        run(\n            [\n                \"tune\",\n                \"run\",\n                \"--nproc_per_node\",\n                str(num_procs),\n                \"lora_finetune_distributed\",\n                \"--config\",\n                str(config),\n            ]\n        )\n    else:\n        # Fetch rank and master addr from environment variables\n        raise NotImplementedError()\n\n    global BACKGROUND_PROCESS\n    BACKGROUND_PROCESS = False\n\n    if upload_checkpoint:\n        registry.upload(\n            job_folder,\n            EntryMetadata.from_dict(\n                {\n                    \"name\": f\"finetune-{job_id}\",\n                    \"version\": \"0.0.1\",\n                    \"description\": f\"Finetuned checkpoint from base mode {model} using dataset {dataset}\",\n                    \"category\": \"finetune\",\n                    \"tags\": [\"finetune\", f\"base-model-{model}\", f\"base-dataset-{dataset}\"],\n                    \"details\": dict(\n                        model=model,\n                        tokenizer=tokenizer,\n                        dataset=dataset,\n                        num_procs=num_procs,\n                        format=format,\n                        num_nodes=num_nodes,\n                        checkpoint=checkpoint,\n                        **dataset_kwargs,\n                    ),\n                    \"show_entry\": True,\n                }\n            ),\n            show_progress=True,\n        )\n</code></pre>"},{"location":"api/#nearai.finetune.parse_line","title":"parse_line","text":"<pre><code>parse_line(line: str) -&gt; Tuple[int, dict[str, float]]\n</code></pre> <p>Example of line to be parsed.</p> <p>Step 33 | loss:1.5400923490524292 lr:9.9e-05 tokens_per_second_per_gpu:101.22285588141214</p> Source code in <code>nearai/finetune/__init__.py</code> <pre><code>def parse_line(line: str) -&gt; Tuple[int, dict[str, float]]:\n    \"\"\"Example of line to be parsed.\n\n    Step 33 | loss:1.5400923490524292 lr:9.9e-05 tokens_per_second_per_gpu:101.22285588141214\n    \"\"\"\n    step_raw, metrics_raw = map(str.strip, line.strip(\" \\n\").split(\"|\"))\n    step = int(step_raw.split(\" \")[-1])\n    metrics = {metric[0]: float(metric[1]) for metric in map(lambda metric: metric.split(\":\"), metrics_raw.split(\" \"))}\n    return step, metrics\n</code></pre>"},{"location":"api/#nearai.finetune.text_completion","title":"text_completion","text":""},{"location":"api/#nearai.finetune.text_completion.TextCompletionDataset","title":"TextCompletionDataset","text":"<p>               Bases: <code>Dataset</code></p> <p>Freeform dataset for any unstructured text corpus. Quickly load any dataset from Hugging Face or local disk and tokenize it for your model.</p> <pre><code>tokenizer (BaseTokenizer): Tokenizer used to encode data. Tokenize must implement an ``encode`` and ``decode`` method.\nsource (str): path string of dataset, anything supported by Hugging Face's ``load_dataset``\n    (https://huggingface.co/docs/datasets/en/package_reference/loading_methods#datasets.load_dataset.path)\ncolumn (str): name of column in the sample that contains the text data. This is typically required\n    for Hugging Face datasets or tabular data. For local datasets with a single column, use the default \"text\",\n    which is what is assigned by Hugging Face datasets when loaded into memory. Default is \"text\".\nmax_seq_len (Optional[int]): Maximum number of tokens in the returned input and label token id lists.\n    Default is None, disabling truncation. We recommend setting this to the highest you can fit in memory\n    and is supported by the model. For example, llama2-7B supports up to 4096 for sequence length.\n**load_dataset_kwargs (Dict[str, Any]): additional keyword arguments to pass to ``load_dataset``.\n</code></pre> Source code in <code>nearai/finetune/text_completion.py</code> <pre><code>class TextCompletionDataset(Dataset):\n    \"\"\"Freeform dataset for any unstructured text corpus. Quickly load any dataset from Hugging Face or local disk and tokenize it for your model.\n\n    Args:\n    ----\n        tokenizer (BaseTokenizer): Tokenizer used to encode data. Tokenize must implement an ``encode`` and ``decode`` method.\n        source (str): path string of dataset, anything supported by Hugging Face's ``load_dataset``\n            (https://huggingface.co/docs/datasets/en/package_reference/loading_methods#datasets.load_dataset.path)\n        column (str): name of column in the sample that contains the text data. This is typically required\n            for Hugging Face datasets or tabular data. For local datasets with a single column, use the default \"text\",\n            which is what is assigned by Hugging Face datasets when loaded into memory. Default is \"text\".\n        max_seq_len (Optional[int]): Maximum number of tokens in the returned input and label token id lists.\n            Default is None, disabling truncation. We recommend setting this to the highest you can fit in memory\n            and is supported by the model. For example, llama2-7B supports up to 4096 for sequence length.\n        **load_dataset_kwargs (Dict[str, Any]): additional keyword arguments to pass to ``load_dataset``.\n\n    \"\"\"  # noqa: E501\n\n    def __init__(  # noqa: D107\n        self,\n        tokenizer: BaseTokenizer,\n        source: str,\n        column: str = \"text\",\n        split: Optional[str] = None,\n        max_seq_len: Optional[int] = None,\n        **load_dataset_kwargs: Dict[str, Any],\n    ) -&gt; None:\n        self._tokenizer = tokenizer\n        self._data = load_from_disk(source, **load_dataset_kwargs)\n        if split is not None:\n            self._data = self._data[split]\n        self.max_seq_len = max_seq_len\n        self._column = column\n\n    def __len__(self) -&gt; int:  # noqa: D105\n        return len(self._data)\n\n    def __getitem__(self, index: int) -&gt; Dict[str, List[int]]:  # noqa: D105\n        sample = self._data[index]\n        return self._prepare_sample(sample)\n\n    def _prepare_sample(self, sample: Mapping[str, Any]) -&gt; Dict[str, List[int]]:\n        prompt = sample[self._column]\n        tokens = self._tokenizer.encode(text=prompt, add_bos=True, add_eos=True)\n\n        # Truncate if needed, but don't coerce EOS id\n        if self.max_seq_len is not None:\n            tokens = truncate(tokens, self.max_seq_len - 1)\n\n        # No need to offset labels by 1 - happens in the recipe\n        labels = tokens.copy()\n\n        return {\"tokens\": tokens, \"labels\": labels}\n</code></pre>"},{"location":"api/#nearai.finetune.text_completion.truncate","title":"truncate","text":"<pre><code>truncate(\n    tokens: List[Any],\n    max_seq_len: int,\n    eos_id: Optional[Any] = None,\n) -&gt; List[Any]\n</code></pre> <p>Truncate a list of tokens to a maximum length. If eos_id is provided, the last token will be replaced with eos_id.</p> <pre><code>tokens (List[Any]): list of tokens to truncate\nmax_seq_len (int): maximum length of the list\neos_id (Optional[Any]): token to replace the last token with. If None, the\n    last token will not be replaced. Default is None.\n</code></pre> <pre><code>List[Any]: truncated list of tokens\n</code></pre> Source code in <code>nearai/finetune/text_completion.py</code> <pre><code>def truncate(\n    tokens: List[Any],\n    max_seq_len: int,\n    eos_id: Optional[Any] = None,\n) -&gt; List[Any]:\n    \"\"\"Truncate a list of tokens to a maximum length. If eos_id is provided, the last token will be replaced with eos_id.\n\n    Args:\n    ----\n        tokens (List[Any]): list of tokens to truncate\n        max_seq_len (int): maximum length of the list\n        eos_id (Optional[Any]): token to replace the last token with. If None, the\n            last token will not be replaced. Default is None.\n\n    Returns:\n    -------\n        List[Any]: truncated list of tokens\n\n    \"\"\"  # noqa: E501\n    tokens_truncated = tokens[:max_seq_len]\n    if eos_id is not None and tokens_truncated[-1] != eos_id:\n        tokens_truncated[-1] = eos_id\n    return tokens_truncated\n</code></pre>"},{"location":"api/#nearai.hub","title":"hub","text":""},{"location":"api/#nearai.hub.Hub","title":"Hub","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/hub.py</code> <pre><code>class Hub(object):\n    def __init__(self, config: Config) -&gt; None:\n        \"\"\"Initializes the Hub class with the given configuration.\"\"\"\n        self.info = None\n        self.provider = None\n        self.model = None\n        self.endpoint = None\n        self.query = None\n        self._config = config\n\n    def parse_hub_chat_params(self, kwargs):\n        \"\"\"Parses and sets instance attributes from the given keyword arguments, using default values if needed.\"\"\"\n        if self._config.nearai_hub is None:\n            self._config.nearai_hub = NearAiHubConfig()\n\n        self.query = kwargs.get(\"query\")\n        self.endpoint = kwargs.get(\"endpoint\", f\"{self._config.nearai_hub.base_url}/chat/completions\")\n        self.model = kwargs.get(\"model\", self._config.nearai_hub.default_model)\n        self.provider = kwargs.get(\"provider\", self._config.nearai_hub.default_provider)\n        self.info = kwargs.get(\"info\", False)\n\n    def chat(self, kwargs):\n        \"\"\"Processes a chat request by sending parameters to the NEAR AI Hub and printing the response.\"\"\"\n        try:\n            self.parse_hub_chat_params(kwargs)\n\n            if not self.query:\n                return print(\"Error: 'query' is required for the `hub chat` command.\")\n\n            if self._config.nearai_hub is None:\n                self._config.nearai_hub = NearAiHubConfig()\n\n            data = {\n                \"max_tokens\": 256,\n                \"temperature\": 1,\n                \"frequency_penalty\": 0,\n                \"n\": 1,\n                \"messages\": [{\"role\": \"user\", \"content\": str(self.query)}],\n                \"model\": self.model,\n            }\n\n            auth = self._config.auth\n\n            if self._config.nearai_hub.login_with_near:\n                bearer_token = auth.generate_bearer_token()\n                headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {bearer_token}\"}\n\n                data[\"provider\"] = self.provider\n            elif self._config.nearai_hub.api_key:\n                headers = {\n                    \"Content-Type\": \"application/json\",\n                    \"Authorization\": \"Bearer {}\".format(self._config.nearai_hub.api_key),\n                }\n            else:\n                return print(\"Illegal NEAR AI Hub Config\")\n\n            if self.info:\n                print(f\"Requesting hub using NEAR Account {auth.account_id}\")\n\n            response = requests.post(self.endpoint, headers=headers, data=json.dumps(data))\n\n            completion = response.json()\n\n            print(completion[\"choices\"][0][\"message\"][\"content\"])\n\n        except Exception as e:\n            print(f\"Request failed: {e}\")\n</code></pre>"},{"location":"api/#nearai.hub.Hub.__init__","title":"__init__","text":"<pre><code>__init__(config: Config) -&gt; None\n</code></pre> <p>Initializes the Hub class with the given configuration.</p> Source code in <code>nearai/hub.py</code> <pre><code>def __init__(self, config: Config) -&gt; None:\n    \"\"\"Initializes the Hub class with the given configuration.\"\"\"\n    self.info = None\n    self.provider = None\n    self.model = None\n    self.endpoint = None\n    self.query = None\n    self._config = config\n</code></pre>"},{"location":"api/#nearai.hub.Hub.chat","title":"chat","text":"<pre><code>chat(kwargs)\n</code></pre> <p>Processes a chat request by sending parameters to the NEAR AI Hub and printing the response.</p> Source code in <code>nearai/hub.py</code> <pre><code>def chat(self, kwargs):\n    \"\"\"Processes a chat request by sending parameters to the NEAR AI Hub and printing the response.\"\"\"\n    try:\n        self.parse_hub_chat_params(kwargs)\n\n        if not self.query:\n            return print(\"Error: 'query' is required for the `hub chat` command.\")\n\n        if self._config.nearai_hub is None:\n            self._config.nearai_hub = NearAiHubConfig()\n\n        data = {\n            \"max_tokens\": 256,\n            \"temperature\": 1,\n            \"frequency_penalty\": 0,\n            \"n\": 1,\n            \"messages\": [{\"role\": \"user\", \"content\": str(self.query)}],\n            \"model\": self.model,\n        }\n\n        auth = self._config.auth\n\n        if self._config.nearai_hub.login_with_near:\n            bearer_token = auth.generate_bearer_token()\n            headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {bearer_token}\"}\n\n            data[\"provider\"] = self.provider\n        elif self._config.nearai_hub.api_key:\n            headers = {\n                \"Content-Type\": \"application/json\",\n                \"Authorization\": \"Bearer {}\".format(self._config.nearai_hub.api_key),\n            }\n        else:\n            return print(\"Illegal NEAR AI Hub Config\")\n\n        if self.info:\n            print(f\"Requesting hub using NEAR Account {auth.account_id}\")\n\n        response = requests.post(self.endpoint, headers=headers, data=json.dumps(data))\n\n        completion = response.json()\n\n        print(completion[\"choices\"][0][\"message\"][\"content\"])\n\n    except Exception as e:\n        print(f\"Request failed: {e}\")\n</code></pre>"},{"location":"api/#nearai.hub.Hub.parse_hub_chat_params","title":"parse_hub_chat_params","text":"<pre><code>parse_hub_chat_params(kwargs)\n</code></pre> <p>Parses and sets instance attributes from the given keyword arguments, using default values if needed.</p> Source code in <code>nearai/hub.py</code> <pre><code>def parse_hub_chat_params(self, kwargs):\n    \"\"\"Parses and sets instance attributes from the given keyword arguments, using default values if needed.\"\"\"\n    if self._config.nearai_hub is None:\n        self._config.nearai_hub = NearAiHubConfig()\n\n    self.query = kwargs.get(\"query\")\n    self.endpoint = kwargs.get(\"endpoint\", f\"{self._config.nearai_hub.base_url}/chat/completions\")\n    self.model = kwargs.get(\"model\", self._config.nearai_hub.default_model)\n    self.provider = kwargs.get(\"provider\", self._config.nearai_hub.default_provider)\n    self.info = kwargs.get(\"info\", False)\n</code></pre>"},{"location":"api/#nearai.lib","title":"lib","text":""},{"location":"api/#nearai.lib.parse_location","title":"parse_location","text":"<pre><code>parse_location(entry_location: str) -&gt; EntryLocation\n</code></pre> <p>Create a EntryLocation from a string in the format namespace/name/version.</p> Source code in <code>nearai/lib.py</code> <pre><code>def parse_location(entry_location: str) -&gt; EntryLocation:\n    \"\"\"Create a EntryLocation from a string in the format namespace/name/version.\"\"\"\n    match = entry_location_pattern.match(entry_location)\n\n    if match is None:\n        raise ValueError(f\"Invalid entry format: {entry_location}. Should have the format &lt;namespace&gt;/&lt;name&gt;/&lt;version&gt;\")\n\n    return EntryLocation(\n        namespace=match.group(\"namespace\"),\n        name=match.group(\"name\"),\n        version=match.group(\"version\"),\n    )\n</code></pre>"},{"location":"api/#nearai.login","title":"login","text":""},{"location":"api/#nearai.login.AuthHandler","title":"AuthHandler","text":"<p>               Bases: <code>SimpleHTTPRequestHandler</code></p> Source code in <code>nearai/login.py</code> <pre><code>class AuthHandler(http.server.SimpleHTTPRequestHandler):\n    def log_message(self, format, *args):\n        \"\"\"Webserver logging method.\"\"\"\n        pass  # Override to suppress logging\n\n    def do_GET(self):  # noqa: N802\n        \"\"\"Webserver GET method.\"\"\"\n        global NONCE, PORT\n\n        script_path = Path(__file__).resolve()\n        assets_folder = script_path.parent / \"assets\"\n\n        if self.path.startswith(\"/capture\"):\n            with open(os.path.join(assets_folder, \"auth_capture.html\"), \"r\", encoding=\"utf-8\") as file:\n                content = file.read()\n            self.send_response(200)\n            self.send_header(\"Content-type\", \"text/html\")\n            self.end_headers()\n            self.wfile.write(content.encode(\"utf-8\"))\n\n        if self.path.startswith(\"/auth\"):\n            parsed_url = urlparse.urlparse(self.path)\n            fragment = parsed_url.query\n            params = urlparse.parse_qs(fragment)\n\n            required_params = [\"accountId\", \"signature\", \"publicKey\"]\n\n            if all(param in params for param in required_params):\n                update_auth_config(\n                    params[\"accountId\"][0],\n                    params[\"signature\"][0],\n                    params[\"publicKey\"][0],\n                    callback_url=generate_callback_url(PORT),\n                    nonce=NONCE,\n                )\n            else:\n                print(\"Required parameters not found\")\n\n            with open(os.path.join(assets_folder, \"auth_complete.html\"), \"r\", encoding=\"utf-8\") as file:\n                content = file.read()\n            self.send_response(200)\n            self.send_header(\"Content-type\", \"text/html\")\n            self.end_headers()\n            self.wfile.write(content.encode(\"utf-8\"))\n\n            # Give the server some time to read the response before shutting it down\n            def shutdown_server():\n                global httpd\n                time.sleep(2)  # Wait 2 seconds before shutting down\n                if httpd:\n                    httpd.shutdown()\n\n            threading.Thread(target=shutdown_server).start()\n</code></pre>"},{"location":"api/#nearai.login.AuthHandler.do_GET","title":"do_GET","text":"<pre><code>do_GET()\n</code></pre> <p>Webserver GET method.</p> Source code in <code>nearai/login.py</code> <pre><code>def do_GET(self):  # noqa: N802\n    \"\"\"Webserver GET method.\"\"\"\n    global NONCE, PORT\n\n    script_path = Path(__file__).resolve()\n    assets_folder = script_path.parent / \"assets\"\n\n    if self.path.startswith(\"/capture\"):\n        with open(os.path.join(assets_folder, \"auth_capture.html\"), \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/html\")\n        self.end_headers()\n        self.wfile.write(content.encode(\"utf-8\"))\n\n    if self.path.startswith(\"/auth\"):\n        parsed_url = urlparse.urlparse(self.path)\n        fragment = parsed_url.query\n        params = urlparse.parse_qs(fragment)\n\n        required_params = [\"accountId\", \"signature\", \"publicKey\"]\n\n        if all(param in params for param in required_params):\n            update_auth_config(\n                params[\"accountId\"][0],\n                params[\"signature\"][0],\n                params[\"publicKey\"][0],\n                callback_url=generate_callback_url(PORT),\n                nonce=NONCE,\n            )\n        else:\n            print(\"Required parameters not found\")\n\n        with open(os.path.join(assets_folder, \"auth_complete.html\"), \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/html\")\n        self.end_headers()\n        self.wfile.write(content.encode(\"utf-8\"))\n\n        # Give the server some time to read the response before shutting it down\n        def shutdown_server():\n            global httpd\n            time.sleep(2)  # Wait 2 seconds before shutting down\n            if httpd:\n                httpd.shutdown()\n\n        threading.Thread(target=shutdown_server).start()\n</code></pre>"},{"location":"api/#nearai.login.AuthHandler.log_message","title":"log_message","text":"<pre><code>log_message(format, *args)\n</code></pre> <p>Webserver logging method.</p> Source code in <code>nearai/login.py</code> <pre><code>def log_message(self, format, *args):\n    \"\"\"Webserver logging method.\"\"\"\n    pass  # Override to suppress logging\n</code></pre>"},{"location":"api/#nearai.login.find_open_port","title":"find_open_port","text":"<pre><code>find_open_port() -&gt; int\n</code></pre> <p>Finds and returns an open port number by binding to a free port on the local machine.</p> Source code in <code>nearai/login.py</code> <pre><code>def find_open_port() -&gt; int:\n    \"\"\"Finds and returns an open port number by binding to a free port on the local machine.\"\"\"\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.bind((\"\", 0))\n        return s.getsockname()[1]\n</code></pre>"},{"location":"api/#nearai.login.generate_and_save_signature","title":"generate_and_save_signature","text":"<pre><code>generate_and_save_signature(account_id, private_key)\n</code></pre> <p>Generates a signature for the given account ID and private key, then updates the auth configuration.</p> Source code in <code>nearai/login.py</code> <pre><code>def generate_and_save_signature(account_id, private_key):\n    \"\"\"Generates a signature for the given account ID and private key, then updates the auth configuration.\"\"\"\n    nonce = generate_nonce()\n    payload = near.Payload(MESSAGE, nonce, RECIPIENT, \"\")\n\n    signature, public_key = near.create_signature(private_key, payload)\n\n    if update_auth_config(account_id, signature, public_key, \"\", nonce):\n        print_login_status()\n</code></pre>"},{"location":"api/#nearai.login.generate_callback_url","title":"generate_callback_url","text":"<pre><code>generate_callback_url(port)\n</code></pre> <p>Generates a callback URL using the specified port number.</p> Source code in <code>nearai/login.py</code> <pre><code>def generate_callback_url(port):\n    \"\"\"Generates a callback URL using the specified port number.\"\"\"\n    return f\"http://localhost:{port}/capture\"\n</code></pre>"},{"location":"api/#nearai.login.generate_nonce","title":"generate_nonce","text":"<pre><code>generate_nonce()\n</code></pre> <p>Generates a nonce based on the current time in milliseconds.</p> Source code in <code>nearai/login.py</code> <pre><code>def generate_nonce():\n    \"\"\"Generates a nonce based on the current time in milliseconds.\"\"\"\n    return str(int(time.time() * 1000))\n</code></pre>"},{"location":"api/#nearai.login.login_with_file_credentials","title":"login_with_file_credentials","text":"<pre><code>login_with_file_credentials(account_id)\n</code></pre> <p>Logs in using credentials from a file for the specified account ID, generating and saving a signature.</p> Source code in <code>nearai/login.py</code> <pre><code>def login_with_file_credentials(account_id):\n    \"\"\"Logs in using credentials from a file for the specified account ID, generating and saving a signature.\"\"\"\n    file_path = os.path.expanduser(os.path.join(\"~/.near-credentials/\", \"mainnet\", f\"{account_id}.json\"))\n\n    if os.path.exists(file_path):\n        with open(file_path, \"r\") as file:\n            content = file.read()\n            account_data = json.loads(content)\n            private_key = account_data.get(\"private_key\", None)\n            if not private_key:\n                return print(f\"Private key is missing for {account_id} on mainnet\")\n            generate_and_save_signature(account_id, account_data[\"private_key\"])\n\n    else:\n        return print(f\"Account data is missing for {account_id}\")\n</code></pre>"},{"location":"api/#nearai.login.login_with_near_auth","title":"login_with_near_auth","text":"<pre><code>login_with_near_auth(remote, auth_url)\n</code></pre> <p>Initiates the login process using NEAR authentication, either starting a local server to handle the callback or providing a URL for remote authentication.</p> Source code in <code>nearai/login.py</code> <pre><code>def login_with_near_auth(remote, auth_url):\n    \"\"\"Initiates the login process using NEAR authentication, either starting a local server to handle the callback or providing a URL for remote authentication.\"\"\"  # noqa: E501\n    global NONCE, PORT\n    NONCE = generate_nonce()\n\n    params = {\n        \"message\": MESSAGE,\n        \"nonce\": NONCE,\n        \"recipient\": RECIPIENT,\n    }\n\n    if not remote:\n        PORT = find_open_port()\n\n        global httpd\n        with socketserver.TCPServer((\"\", PORT), AuthHandler) as httpd:\n            params[\"callbackUrl\"] = f\"http://localhost:{PORT}/capture\"\n\n            encoded_params = urlparse.urlencode(params)\n\n            print_url_message(f\"{auth_url}?{encoded_params}\")\n\n            httpd.serve_forever()\n\n    else:\n        encoded_params = urlparse.urlencode(params)\n\n        print_url_message(f\"{auth_url}?{encoded_params}\")\n        print(\"After visiting the URL, follow the instructions to save your auth signature\")\n</code></pre>"},{"location":"api/#nearai.login.print_login_status","title":"print_login_status","text":"<pre><code>print_login_status()\n</code></pre> <p>Prints the current authentication status if available in the config file.</p> Source code in <code>nearai/login.py</code> <pre><code>def print_login_status():\n    \"\"\"Prints the current authentication status if available in the config file.\"\"\"\n    config = load_config_file()\n    if config.get(\"auth\") and config[\"auth\"].get(\"account_id\"):\n        print(f\"Auth data for: {config['auth']['account_id']}\")\n        print(f\"signature: {config['auth']['signature']}\")\n        print(f\"public_key: {config['auth']['public_key']}\")\n        print(f\"nonce: {config['auth']['nonce']}\")\n        print(f\"message: {config['auth']['message']}\")\n        print(f\"recipient: {config['auth']['recipient']}\")\n    else:\n        print(\"Near auth details not found\")\n</code></pre>"},{"location":"api/#nearai.login.print_url_message","title":"print_url_message","text":"<pre><code>print_url_message(url)\n</code></pre> <p>Prints a message instructing the user to visit the given URL to complete the login process.</p> Source code in <code>nearai/login.py</code> <pre><code>def print_url_message(url):\n    \"\"\"Prints a message instructing the user to visit the given URL to complete the login process.\"\"\"\n    print(f\"Please visit the following URL to complete the login process: {url}\")\n</code></pre>"},{"location":"api/#nearai.login.update_auth_config","title":"update_auth_config","text":"<pre><code>update_auth_config(\n    account_id, signature, public_key, callback_url, nonce\n)\n</code></pre> <p>Update authentication configuration if the provided signature is valid.</p> Source code in <code>nearai/login.py</code> <pre><code>def update_auth_config(account_id, signature, public_key, callback_url, nonce):\n    \"\"\"Update authentication configuration if the provided signature is valid.\"\"\"\n    if near.verify_signed_message(\n        account_id,\n        public_key,\n        signature,\n        MESSAGE,\n        nonce,\n        RECIPIENT,\n        callback_url,\n    ):\n        config = load_config_file()\n\n        auth = AuthData.model_validate(\n            {\n                \"account_id\": account_id,\n                \"signature\": signature,\n                \"public_key\": public_key,\n                \"callback_url\": callback_url,\n                \"nonce\": nonce,\n                \"recipient\": RECIPIENT,\n                \"message\": MESSAGE,\n            }\n        )\n\n        config[\"auth\"] = auth.model_dump()\n        save_config_file(config)\n\n        print(f\"Auth data has been successfully saved! You are now logged in with account ID: {account_id}\")\n        return True\n    else:\n        print(\"Signature verification failed. Abort\")\n        return False\n</code></pre>"},{"location":"api/#nearai.model","title":"model","text":""},{"location":"api/#nearai.model.get_model","title":"get_model","text":"<pre><code>get_model(name: str) -&gt; Path\n</code></pre> <p>Download the model from the registry and download it locally if it hasn't been downloaded yet.</p> <p>:param name: The name of the entry to download the model. The format should be namespace/name/version. :return: The path to the downloaded model</p> Source code in <code>nearai/model.py</code> <pre><code>def get_model(name: str) -&gt; Path:\n    \"\"\"Download the model from the registry and download it locally if it hasn't been downloaded yet.\n\n    :param name: The name of the entry to download the model. The format should be namespace/name/version.\n    :return: The path to the downloaded model\n    \"\"\"\n    return registry.download(name)\n</code></pre>"},{"location":"api/#nearai.registry","title":"registry","text":""},{"location":"api/#nearai.registry.Registry","title":"Registry","text":"Source code in <code>nearai/registry.py</code> <pre><code>class Registry:\n    def __init__(self):\n        \"\"\"Create Registry object to interact with the registry programmatically.\"\"\"\n        self.download_folder = DATA_FOLDER / \"registry\"\n        self.api = RegistryApi()\n\n        if not self.download_folder.exists():\n            self.download_folder.mkdir(parents=True, exist_ok=True)\n\n    def update(self, entry_location: EntryLocation, metadata: EntryMetadataInput) -&gt; Dict[str, Any]:\n        \"\"\"Update metadata of a entry in the registry.\"\"\"\n        result = self.api.upload_metadata_v1_registry_upload_metadata_post(\n            BodyUploadMetadataV1RegistryUploadMetadataPost(metadata=metadata, entry_location=entry_location)\n        )\n        return result\n\n    def info(self, entry_location: EntryLocation) -&gt; Optional[EntryMetadata]:\n        \"\"\"Get metadata of a entry in the registry.\"\"\"\n        try:\n            return self.api.download_metadata_v1_registry_download_metadata_post(\n                BodyDownloadMetadataV1RegistryDownloadMetadataPost.from_dict(dict(entry_location=entry_location))\n            )\n        except NotFoundException:\n            return None\n\n    def upload_file(self, entry_location: EntryLocation, local_path: Path, path: Path) -&gt; bool:\n        \"\"\"Upload a file to the registry.\"\"\"\n        with open(local_path, \"rb\") as file:\n            data = file.read()\n\n            try:\n                self.api.upload_file_v1_registry_upload_file_post(\n                    path=str(path),\n                    file=data,\n                    namespace=entry_location.namespace,\n                    name=entry_location.name,\n                    version=entry_location.version,\n                )\n                return True\n            except BadRequestException as e:\n                if isinstance(e.body, str) and \"already exists\" in e.body:\n                    return False\n\n                raise e\n\n    def download_file(self, entry_location: EntryLocation, path: Path, local_path: Path):\n        \"\"\"Download a file from the registry.\"\"\"\n        result = self.api.download_file_v1_registry_download_file_post_without_preload_content(\n            BodyDownloadFileV1RegistryDownloadFilePost.from_dict(\n                dict(\n                    entry_location=entry_location,\n                    path=str(path),\n                )\n            )\n        )\n\n        local_path.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(local_path, \"wb\") as f:\n            copyfileobj(result, f)\n\n    def download(\n        self,\n        entry_location: Union[str, EntryLocation],\n        force: bool = False,\n        show_progress: bool = False,\n        verbose: bool = True,\n    ) -&gt; Path:\n        \"\"\"Download entry from the registry locally.\"\"\"\n        if isinstance(entry_location, str):\n            entry_location = parse_location(entry_location)\n\n        download_path = get_registry_folder() / entry_location.namespace / entry_location.name / entry_location.version\n\n        if download_path.exists():\n            if not force:\n                if verbose:\n                    print(\n                        f\"Entry {entry_location} already exists at {download_path}. Use --force to overwrite the entry.\"\n                    )\n                return download_path\n\n        files = registry.list_files(entry_location)\n\n        download_path.mkdir(parents=True, exist_ok=True)\n\n        metadata = registry.info(entry_location)\n\n        if metadata is None:\n            raise ValueError(f\"Entry {entry_location} not found.\")\n\n        metadata_path = download_path / \"metadata.json\"\n        with open(metadata_path, \"w\") as f:\n            f.write(metadata.model_dump_json(indent=2))\n\n        for file in (pbar := tqdm(files, disable=not show_progress)):\n            pbar.set_description(file)\n            registry.download_file(entry_location, file, download_path / file)\n\n        return download_path\n\n    def upload(\n        self,\n        local_path: Path,\n        metadata: Optional[EntryMetadata] = None,\n        show_progress: bool = False,\n    ) -&gt; EntryLocation:\n        \"\"\"Upload entry to the registry.\n\n        If metadata is provided it will overwrite the metadata in the directory,\n        otherwise it will use the metadata.json found on the root of the directory.\n        Files matching patterns in .gitignore (if present) will be excluded from upload.\n        \"\"\"\n        path = Path(local_path).absolute()\n\n        if CONFIG.auth is None:\n            print(\"Please login with `nearai login`\")\n            exit(1)\n\n        metadata_path = path / \"metadata.json\"\n\n        if metadata is not None:\n            with open(metadata_path, \"w\") as f:\n                f.write(metadata.model_dump_json(indent=2))\n\n        check_metadata_present(metadata_path)\n\n        with open(metadata_path) as f:\n            plain_metadata: Dict[str, Any] = json.load(f)\n\n        namespace = get_namespace(local_path)\n        name = plain_metadata.pop(\"name\")\n        assert \" \" not in name\n\n        entry_location = EntryLocation.model_validate(\n            dict(\n                namespace=namespace,\n                name=name,\n                version=plain_metadata.pop(\"version\"),\n            )\n        )\n\n        entry_metadata = EntryMetadataInput.model_validate(plain_metadata)\n        source = entry_metadata.details.get(\"_source\", None)\n\n        if source is not None:\n            print(f\"Only default source is allowed, found: {source}. Remove details._source from metadata.\")\n            exit(1)\n\n        if self.info(entry_location) is None:\n            # New entry location. Check for similar names in registry.\n            entries = self.list_all_visible()\n            canonical_namespace = get_canonical_name(namespace)\n            canonical_name = get_canonical_name(name)\n\n            for entry in entries:\n                if entry.name == name and entry.namespace == namespace:\n                    break\n                if (\n                    get_canonical_name(entry.name) == canonical_name\n                    and get_canonical_name(entry.namespace) == canonical_namespace\n                ):\n                    print(f\"A registry item with a similar name already exists: {entry.namespace}/{entry.name}\")\n                    exit(1)\n\n        registry.update(entry_location, entry_metadata)\n\n        # Initialize gitignore matcher\n        gitignore_spec = None\n        try:\n            import pathspec\n\n            gitignore_path = path / \".gitignore\"\n            if gitignore_path.exists() and gitignore_path.is_file():\n                with open(gitignore_path, \"r\") as f:\n                    print(\".gitignore file detected. Will filter out git ignore files.\\n\")\n                    # Start with Git's default ignore patterns\n                    default_ignore_patterns = [\n                        # Git internal directories\n                        \".git/\",\n                        \".gitignore\",\n                        \".gitmodules\",\n                        \".gitattributes\",\n                        # Python specific\n                        \"__pycache__/\",\n                        \"*.py[cod]\",\n                        \"*$py.class\",\n                        \"*.so\",\n                        \".Python\",\n                        \"build/\",\n                        \"develop-eggs/\",\n                        \"dist/\",\n                        \"downloads/\",\n                        \"eggs/\",\n                        \".eggs/\",\n                        \"lib/\",\n                        \"lib64/\",\n                        \"parts/\",\n                        \"sdist/\",\n                        \"var/\",\n                        \"wheels/\",\n                        \"*.egg-info/\",\n                        \".installed.cfg\",\n                        \"*.egg\",\n                        # Common cache directories\n                        \".ruff_cache/\",\n                        \".pytest_cache/\",\n                        \".mypy_cache/\",\n                        \".hypothesis/\",\n                        \".coverage\",\n                        \"htmlcov/\",\n                        \".tox/\",\n                        \".nox/\",\n                        # Virtual environments\n                        \"venv/\",\n                        \"env/\",\n                        \".env/\",\n                        \".venv/\",\n                        \"ENV/\",\n                        # Jupyter Notebook\n                        \".ipynb_checkpoints\",\n                        # IDE specific\n                        \".idea/\",\n                        \".vscode/\",\n                        \"*.swp\",\n                        \"*.swo\",\n                        # macOS specific\n                        \".DS_Store\",\n                        \".AppleDouble\",\n                        \".LSOverride\",\n                        # Windows specific\n                        \"Thumbs.db\",\n                        \"ehthumbs.db\",\n                        \"Desktop.ini\",\n                    ]\n                    custom_patterns = f.readlines()\n                    gitignore_spec = pathspec.PathSpec.from_lines(\n                        \"gitwildmatch\", default_ignore_patterns + custom_patterns\n                    )\n        except ImportError:\n            print(\"Error: pathspec library not found. .gitignore patterns will not be applied.\")\n            exit(1)\n        except Exception as e:\n            print(f\"Error: Failed to parse .gitignore file: {str(e)}\")\n            exit(1)\n\n        all_files = []\n        total_size = 0\n        num_files_ignored = 0\n\n        # Traverse all files in the directory `path`\n        for file in path.rglob(\"*\"):\n            if not file.is_file():\n                continue\n\n            relative = file.relative_to(path)\n            ignore_file = False\n\n            # Don't upload metadata file.\n            if file == metadata_path:\n                ignore_file = True\n\n            # Don't upload backup files.\n            if not ignore_file and file.name.endswith(\"~\"):\n                ignore_file = True\n\n            # Don't upload configuration files.\n            if not ignore_file and relative.parts[0] == \".nearai\":\n                ignore_file = True\n\n            # Don't upload files in __pycache__\n            if not ignore_file and \"__pycache__\" in relative.parts:\n                ignore_file = True\n\n            # Check if file matches gitignore patterns\n            if not ignore_file and gitignore_spec is not None:\n                rel_str = str(relative).replace(\"\\\\\", \"/\")\n                if gitignore_spec.match_file(rel_str):\n                    ignore_file = True\n\n            if ignore_file:\n                num_files_ignored += 1\n                continue\n\n            size = file.stat().st_size\n            total_size += size\n\n            all_files.append((file, relative, size))\n\n        if num_files_ignored &gt; 0:\n            print(f\"{num_files_ignored} files are filtered out and will not be uploaded.\\n\")\n\n        print(\"Files to be uploaded:\")\n        for _file, relative, _size in all_files:\n            print(f\"U   {relative}\")\n        print(\"\")\n\n        pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True, disable=not show_progress)\n        for file, relative, size in all_files:\n            registry.upload_file(entry_location, file, relative)\n            pbar.update(size)\n\n        return entry_location\n\n    def list_files(self, entry_location: EntryLocation) -&gt; List[str]:\n        \"\"\"List files in from an entry in the registry.\n\n        Return the relative paths to all files with respect to the root of the entry.\n        \"\"\"\n        result = self.api.list_files_v1_registry_list_files_post(\n            BodyListFilesV1RegistryListFilesPost.from_dict(dict(entry_location=entry_location))\n        )\n        return [file.filename for file in result]\n\n    def list(\n        self,\n        namespace: str,\n        category: str,\n        tags: str,\n        total: int,\n        offset: int,\n        show_all: bool,\n        show_latest_version: bool,\n        starred_by: str = \"\",\n    ) -&gt; List[EntryInformation]:\n        \"\"\"List and filter entries in the registry.\"\"\"\n        return self.api.list_entries_v1_registry_list_entries_post(\n            namespace=namespace,\n            category=category,\n            tags=tags,\n            total=total,\n            offset=offset,\n            show_hidden=show_all,\n            show_latest_version=show_latest_version,\n            starred_by=starred_by,\n        )\n\n    def list_all_visible(self, category: str = \"\") -&gt; List[EntryInformation]:\n        \"\"\"List all visible entries.\"\"\"\n        total = 10000\n        entries = self.list(\n            namespace=\"\",\n            category=category,\n            tags=\"\",\n            total=total,\n            offset=0,\n            show_all=False,\n            show_latest_version=True,\n        )\n        assert len(entries) &lt; total\n        return entries\n\n    def dict_models(self) -&gt; Dict[NamespacedName, NamespacedName]:\n        \"\"\"Returns a mapping canonical-&gt;name.\"\"\"\n        entries = self.list_all_visible(category=\"model\")\n        result: Dict[NamespacedName, NamespacedName] = {}\n        for entry in entries:\n            namespaced_name = NamespacedName(name=entry.name, namespace=entry.namespace)\n            canonical_namespaced_name = namespaced_name.canonical()\n            if canonical_namespaced_name in result:\n                raise ValueError(\n                    f\"Duplicate registry entry for model {namespaced_name}, canonical {canonical_namespaced_name}\"\n                )\n            result[canonical_namespaced_name] = namespaced_name\n        return result\n</code></pre>"},{"location":"api/#nearai.registry.Registry.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Create Registry object to interact with the registry programmatically.</p> Source code in <code>nearai/registry.py</code> <pre><code>def __init__(self):\n    \"\"\"Create Registry object to interact with the registry programmatically.\"\"\"\n    self.download_folder = DATA_FOLDER / \"registry\"\n    self.api = RegistryApi()\n\n    if not self.download_folder.exists():\n        self.download_folder.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"api/#nearai.registry.Registry.dict_models","title":"dict_models","text":"<pre><code>dict_models() -&gt; Dict[NamespacedName, NamespacedName]\n</code></pre> <p>Returns a mapping canonical-&gt;name.</p> Source code in <code>nearai/registry.py</code> <pre><code>def dict_models(self) -&gt; Dict[NamespacedName, NamespacedName]:\n    \"\"\"Returns a mapping canonical-&gt;name.\"\"\"\n    entries = self.list_all_visible(category=\"model\")\n    result: Dict[NamespacedName, NamespacedName] = {}\n    for entry in entries:\n        namespaced_name = NamespacedName(name=entry.name, namespace=entry.namespace)\n        canonical_namespaced_name = namespaced_name.canonical()\n        if canonical_namespaced_name in result:\n            raise ValueError(\n                f\"Duplicate registry entry for model {namespaced_name}, canonical {canonical_namespaced_name}\"\n            )\n        result[canonical_namespaced_name] = namespaced_name\n    return result\n</code></pre>"},{"location":"api/#nearai.registry.Registry.download","title":"download","text":"<pre><code>download(\n    entry_location: Union[str, EntryLocation],\n    force: bool = False,\n    show_progress: bool = False,\n    verbose: bool = True,\n) -&gt; Path\n</code></pre> <p>Download entry from the registry locally.</p> Source code in <code>nearai/registry.py</code> <pre><code>def download(\n    self,\n    entry_location: Union[str, EntryLocation],\n    force: bool = False,\n    show_progress: bool = False,\n    verbose: bool = True,\n) -&gt; Path:\n    \"\"\"Download entry from the registry locally.\"\"\"\n    if isinstance(entry_location, str):\n        entry_location = parse_location(entry_location)\n\n    download_path = get_registry_folder() / entry_location.namespace / entry_location.name / entry_location.version\n\n    if download_path.exists():\n        if not force:\n            if verbose:\n                print(\n                    f\"Entry {entry_location} already exists at {download_path}. Use --force to overwrite the entry.\"\n                )\n            return download_path\n\n    files = registry.list_files(entry_location)\n\n    download_path.mkdir(parents=True, exist_ok=True)\n\n    metadata = registry.info(entry_location)\n\n    if metadata is None:\n        raise ValueError(f\"Entry {entry_location} not found.\")\n\n    metadata_path = download_path / \"metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        f.write(metadata.model_dump_json(indent=2))\n\n    for file in (pbar := tqdm(files, disable=not show_progress)):\n        pbar.set_description(file)\n        registry.download_file(entry_location, file, download_path / file)\n\n    return download_path\n</code></pre>"},{"location":"api/#nearai.registry.Registry.download_file","title":"download_file","text":"<pre><code>download_file(\n    entry_location: EntryLocation,\n    path: Path,\n    local_path: Path,\n)\n</code></pre> <p>Download a file from the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def download_file(self, entry_location: EntryLocation, path: Path, local_path: Path):\n    \"\"\"Download a file from the registry.\"\"\"\n    result = self.api.download_file_v1_registry_download_file_post_without_preload_content(\n        BodyDownloadFileV1RegistryDownloadFilePost.from_dict(\n            dict(\n                entry_location=entry_location,\n                path=str(path),\n            )\n        )\n    )\n\n    local_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(local_path, \"wb\") as f:\n        copyfileobj(result, f)\n</code></pre>"},{"location":"api/#nearai.registry.Registry.info","title":"info","text":"<pre><code>info(\n    entry_location: EntryLocation,\n) -&gt; Optional[EntryMetadata]\n</code></pre> <p>Get metadata of a entry in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def info(self, entry_location: EntryLocation) -&gt; Optional[EntryMetadata]:\n    \"\"\"Get metadata of a entry in the registry.\"\"\"\n    try:\n        return self.api.download_metadata_v1_registry_download_metadata_post(\n            BodyDownloadMetadataV1RegistryDownloadMetadataPost.from_dict(dict(entry_location=entry_location))\n        )\n    except NotFoundException:\n        return None\n</code></pre>"},{"location":"api/#nearai.registry.Registry.list","title":"list","text":"<pre><code>list(\n    namespace: str,\n    category: str,\n    tags: str,\n    total: int,\n    offset: int,\n    show_all: bool,\n    show_latest_version: bool,\n    starred_by: str = \"\",\n) -&gt; List[EntryInformation]\n</code></pre> <p>List and filter entries in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def list(\n    self,\n    namespace: str,\n    category: str,\n    tags: str,\n    total: int,\n    offset: int,\n    show_all: bool,\n    show_latest_version: bool,\n    starred_by: str = \"\",\n) -&gt; List[EntryInformation]:\n    \"\"\"List and filter entries in the registry.\"\"\"\n    return self.api.list_entries_v1_registry_list_entries_post(\n        namespace=namespace,\n        category=category,\n        tags=tags,\n        total=total,\n        offset=offset,\n        show_hidden=show_all,\n        show_latest_version=show_latest_version,\n        starred_by=starred_by,\n    )\n</code></pre>"},{"location":"api/#nearai.registry.Registry.list_all_visible","title":"list_all_visible","text":"<pre><code>list_all_visible(\n    category: str = \"\",\n) -&gt; List[EntryInformation]\n</code></pre> <p>List all visible entries.</p> Source code in <code>nearai/registry.py</code> <pre><code>def list_all_visible(self, category: str = \"\") -&gt; List[EntryInformation]:\n    \"\"\"List all visible entries.\"\"\"\n    total = 10000\n    entries = self.list(\n        namespace=\"\",\n        category=category,\n        tags=\"\",\n        total=total,\n        offset=0,\n        show_all=False,\n        show_latest_version=True,\n    )\n    assert len(entries) &lt; total\n    return entries\n</code></pre>"},{"location":"api/#nearai.registry.Registry.list_files","title":"list_files","text":"<pre><code>list_files(entry_location: EntryLocation) -&gt; List[str]\n</code></pre> <p>List files in from an entry in the registry.</p> <p>Return the relative paths to all files with respect to the root of the entry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def list_files(self, entry_location: EntryLocation) -&gt; List[str]:\n    \"\"\"List files in from an entry in the registry.\n\n    Return the relative paths to all files with respect to the root of the entry.\n    \"\"\"\n    result = self.api.list_files_v1_registry_list_files_post(\n        BodyListFilesV1RegistryListFilesPost.from_dict(dict(entry_location=entry_location))\n    )\n    return [file.filename for file in result]\n</code></pre>"},{"location":"api/#nearai.registry.Registry.update","title":"update","text":"<pre><code>update(\n    entry_location: EntryLocation,\n    metadata: EntryMetadataInput,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Update metadata of a entry in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def update(self, entry_location: EntryLocation, metadata: EntryMetadataInput) -&gt; Dict[str, Any]:\n    \"\"\"Update metadata of a entry in the registry.\"\"\"\n    result = self.api.upload_metadata_v1_registry_upload_metadata_post(\n        BodyUploadMetadataV1RegistryUploadMetadataPost(metadata=metadata, entry_location=entry_location)\n    )\n    return result\n</code></pre>"},{"location":"api/#nearai.registry.Registry.upload","title":"upload","text":"<pre><code>upload(\n    local_path: Path,\n    metadata: Optional[EntryMetadata] = None,\n    show_progress: bool = False,\n) -&gt; EntryLocation\n</code></pre> <p>Upload entry to the registry.</p> <p>If metadata is provided it will overwrite the metadata in the directory, otherwise it will use the metadata.json found on the root of the directory. Files matching patterns in .gitignore (if present) will be excluded from upload.</p> Source code in <code>nearai/registry.py</code> <pre><code>def upload(\n    self,\n    local_path: Path,\n    metadata: Optional[EntryMetadata] = None,\n    show_progress: bool = False,\n) -&gt; EntryLocation:\n    \"\"\"Upload entry to the registry.\n\n    If metadata is provided it will overwrite the metadata in the directory,\n    otherwise it will use the metadata.json found on the root of the directory.\n    Files matching patterns in .gitignore (if present) will be excluded from upload.\n    \"\"\"\n    path = Path(local_path).absolute()\n\n    if CONFIG.auth is None:\n        print(\"Please login with `nearai login`\")\n        exit(1)\n\n    metadata_path = path / \"metadata.json\"\n\n    if metadata is not None:\n        with open(metadata_path, \"w\") as f:\n            f.write(metadata.model_dump_json(indent=2))\n\n    check_metadata_present(metadata_path)\n\n    with open(metadata_path) as f:\n        plain_metadata: Dict[str, Any] = json.load(f)\n\n    namespace = get_namespace(local_path)\n    name = plain_metadata.pop(\"name\")\n    assert \" \" not in name\n\n    entry_location = EntryLocation.model_validate(\n        dict(\n            namespace=namespace,\n            name=name,\n            version=plain_metadata.pop(\"version\"),\n        )\n    )\n\n    entry_metadata = EntryMetadataInput.model_validate(plain_metadata)\n    source = entry_metadata.details.get(\"_source\", None)\n\n    if source is not None:\n        print(f\"Only default source is allowed, found: {source}. Remove details._source from metadata.\")\n        exit(1)\n\n    if self.info(entry_location) is None:\n        # New entry location. Check for similar names in registry.\n        entries = self.list_all_visible()\n        canonical_namespace = get_canonical_name(namespace)\n        canonical_name = get_canonical_name(name)\n\n        for entry in entries:\n            if entry.name == name and entry.namespace == namespace:\n                break\n            if (\n                get_canonical_name(entry.name) == canonical_name\n                and get_canonical_name(entry.namespace) == canonical_namespace\n            ):\n                print(f\"A registry item with a similar name already exists: {entry.namespace}/{entry.name}\")\n                exit(1)\n\n    registry.update(entry_location, entry_metadata)\n\n    # Initialize gitignore matcher\n    gitignore_spec = None\n    try:\n        import pathspec\n\n        gitignore_path = path / \".gitignore\"\n        if gitignore_path.exists() and gitignore_path.is_file():\n            with open(gitignore_path, \"r\") as f:\n                print(\".gitignore file detected. Will filter out git ignore files.\\n\")\n                # Start with Git's default ignore patterns\n                default_ignore_patterns = [\n                    # Git internal directories\n                    \".git/\",\n                    \".gitignore\",\n                    \".gitmodules\",\n                    \".gitattributes\",\n                    # Python specific\n                    \"__pycache__/\",\n                    \"*.py[cod]\",\n                    \"*$py.class\",\n                    \"*.so\",\n                    \".Python\",\n                    \"build/\",\n                    \"develop-eggs/\",\n                    \"dist/\",\n                    \"downloads/\",\n                    \"eggs/\",\n                    \".eggs/\",\n                    \"lib/\",\n                    \"lib64/\",\n                    \"parts/\",\n                    \"sdist/\",\n                    \"var/\",\n                    \"wheels/\",\n                    \"*.egg-info/\",\n                    \".installed.cfg\",\n                    \"*.egg\",\n                    # Common cache directories\n                    \".ruff_cache/\",\n                    \".pytest_cache/\",\n                    \".mypy_cache/\",\n                    \".hypothesis/\",\n                    \".coverage\",\n                    \"htmlcov/\",\n                    \".tox/\",\n                    \".nox/\",\n                    # Virtual environments\n                    \"venv/\",\n                    \"env/\",\n                    \".env/\",\n                    \".venv/\",\n                    \"ENV/\",\n                    # Jupyter Notebook\n                    \".ipynb_checkpoints\",\n                    # IDE specific\n                    \".idea/\",\n                    \".vscode/\",\n                    \"*.swp\",\n                    \"*.swo\",\n                    # macOS specific\n                    \".DS_Store\",\n                    \".AppleDouble\",\n                    \".LSOverride\",\n                    # Windows specific\n                    \"Thumbs.db\",\n                    \"ehthumbs.db\",\n                    \"Desktop.ini\",\n                ]\n                custom_patterns = f.readlines()\n                gitignore_spec = pathspec.PathSpec.from_lines(\n                    \"gitwildmatch\", default_ignore_patterns + custom_patterns\n                )\n    except ImportError:\n        print(\"Error: pathspec library not found. .gitignore patterns will not be applied.\")\n        exit(1)\n    except Exception as e:\n        print(f\"Error: Failed to parse .gitignore file: {str(e)}\")\n        exit(1)\n\n    all_files = []\n    total_size = 0\n    num_files_ignored = 0\n\n    # Traverse all files in the directory `path`\n    for file in path.rglob(\"*\"):\n        if not file.is_file():\n            continue\n\n        relative = file.relative_to(path)\n        ignore_file = False\n\n        # Don't upload metadata file.\n        if file == metadata_path:\n            ignore_file = True\n\n        # Don't upload backup files.\n        if not ignore_file and file.name.endswith(\"~\"):\n            ignore_file = True\n\n        # Don't upload configuration files.\n        if not ignore_file and relative.parts[0] == \".nearai\":\n            ignore_file = True\n\n        # Don't upload files in __pycache__\n        if not ignore_file and \"__pycache__\" in relative.parts:\n            ignore_file = True\n\n        # Check if file matches gitignore patterns\n        if not ignore_file and gitignore_spec is not None:\n            rel_str = str(relative).replace(\"\\\\\", \"/\")\n            if gitignore_spec.match_file(rel_str):\n                ignore_file = True\n\n        if ignore_file:\n            num_files_ignored += 1\n            continue\n\n        size = file.stat().st_size\n        total_size += size\n\n        all_files.append((file, relative, size))\n\n    if num_files_ignored &gt; 0:\n        print(f\"{num_files_ignored} files are filtered out and will not be uploaded.\\n\")\n\n    print(\"Files to be uploaded:\")\n    for _file, relative, _size in all_files:\n        print(f\"U   {relative}\")\n    print(\"\")\n\n    pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True, disable=not show_progress)\n    for file, relative, size in all_files:\n        registry.upload_file(entry_location, file, relative)\n        pbar.update(size)\n\n    return entry_location\n</code></pre>"},{"location":"api/#nearai.registry.Registry.upload_file","title":"upload_file","text":"<pre><code>upload_file(\n    entry_location: EntryLocation,\n    local_path: Path,\n    path: Path,\n) -&gt; bool\n</code></pre> <p>Upload a file to the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def upload_file(self, entry_location: EntryLocation, local_path: Path, path: Path) -&gt; bool:\n    \"\"\"Upload a file to the registry.\"\"\"\n    with open(local_path, \"rb\") as file:\n        data = file.read()\n\n        try:\n            self.api.upload_file_v1_registry_upload_file_post(\n                path=str(path),\n                file=data,\n                namespace=entry_location.namespace,\n                name=entry_location.name,\n                version=entry_location.version,\n            )\n            return True\n        except BadRequestException as e:\n            if isinstance(e.body, str) and \"already exists\" in e.body:\n                return False\n\n            raise e\n</code></pre>"},{"location":"api/#nearai.registry.check_version_exists","title":"check_version_exists","text":"<pre><code>check_version_exists(\n    namespace: str, name: str, version: str\n) -&gt; Tuple[bool, Optional[str]]\n</code></pre> <p>Check if a version already exists in the registry.</p> <pre><code>namespace: The namespace\nname: The agent name\nversion: The version to check\n</code></pre> <pre><code>Tuple of (exists, error)\nIf exists is True, the version exists\nIf error is not None, an error occurred during checking\n</code></pre> Source code in <code>nearai/registry.py</code> <pre><code>def check_version_exists(namespace: str, name: str, version: str) -&gt; Tuple[bool, Optional[str]]:\n    \"\"\"Check if a version already exists in the registry.\n\n    Args:\n    ----\n        namespace: The namespace\n        name: The agent name\n        version: The version to check\n\n    Returns:\n    -------\n        Tuple of (exists, error)\n        If exists is True, the version exists\n        If error is not None, an error occurred during checking\n\n    \"\"\"\n    entry_location = f\"{namespace}/{name}/{version}\"\n    try:\n        existing_entry = registry.info(parse_location(entry_location))\n\n        if existing_entry:\n            return True, None\n        return False, None\n    except Exception as e:\n        # Only proceed if the error indicates the entry doesn't exist\n        if \"not found\" in str(e).lower() or \"does not exist\" in str(e).lower():\n            return False, None\n        return False, f\"Error checking registry: {str(e)}\"\n</code></pre>"},{"location":"api/#nearai.registry.get_namespace","title":"get_namespace","text":"<pre><code>get_namespace(local_path: Path) -&gt; str\n</code></pre> <p>Returns namespace of an item or user namespace.</p> Source code in <code>nearai/registry.py</code> <pre><code>def get_namespace(local_path: Path) -&gt; str:\n    \"\"\"Returns namespace of an item or user namespace.\"\"\"\n    registry_folder = get_registry_folder()\n\n    try:\n        # Check if the path matches the expected structure\n        relative_path = local_path.relative_to(registry_folder)\n\n    except ValueError:\n        # If local_path is not relative to registry_folder, try resolving it to an absolute path\n        local_path = local_path.resolve()\n        try:\n            # Retry checking if the now absolute path is within registry_folder\n            relative_path = local_path.relative_to(registry_folder)\n        except ValueError:\n            relative_path = None\n            pass\n\n    if relative_path:\n        parts = relative_path.parts\n\n        # If the path has 3 parts (namespace, item_name, version),\n        # return the first part as the namespace\n        if len(parts) == 3:\n            return str(parts[0])\n\n    # If we couldn't extract a namespace from the path, return the default\n    if CONFIG.auth is None:\n        raise ValueError(\"AuthData is None\")\n    return CONFIG.auth.namespace\n</code></pre>"},{"location":"api/#nearai.registry.get_registry_folder","title":"get_registry_folder","text":"<pre><code>get_registry_folder() -&gt; Path\n</code></pre> <p>Path to local registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def get_registry_folder() -&gt; Path:\n    \"\"\"Path to local registry.\"\"\"\n    return DATA_FOLDER / REGISTRY_FOLDER\n</code></pre>"},{"location":"api/#nearai.registry.increment_version_by_type","title":"increment_version_by_type","text":"<pre><code>increment_version_by_type(\n    version: str, increment_type: str\n) -&gt; str\n</code></pre> <p>Increment version according to PEP 440.</p> <pre><code>version: Current version string\nincrement_type: Type of increment ('major', 'minor', or 'patch')\n</code></pre> <pre><code>New version string\n</code></pre> <pre><code>ValueError: If increment_type is invalid or version is invalid\n</code></pre> Source code in <code>nearai/registry.py</code> <pre><code>def increment_version_by_type(version: str, increment_type: str) -&gt; str:\n    \"\"\"Increment version according to PEP 440.\n\n    Args:\n    ----\n        version: Current version string\n        increment_type: Type of increment ('major', 'minor', or 'patch')\n\n    Returns:\n    -------\n        New version string\n\n    Raises:\n    ------\n        ValueError: If increment_type is invalid or version is invalid\n\n    \"\"\"\n    try:\n        v = Version(version)\n        major, minor, micro = v.release[:3]\n\n        if increment_type == \"major\":\n            return f\"{major + 1}.0.0\"\n        elif increment_type == \"minor\":\n            return f\"{major}.{minor + 1}.0\"\n        elif increment_type == \"patch\":\n            return f\"{major}.{minor}.{micro + 1}\"\n        else:\n            raise ValueError(f\"Invalid increment type: {increment_type}\")\n    except InvalidVersion as e:\n        raise ValueError(f\"Invalid version format: {str(e)}\") from e\n</code></pre>"},{"location":"api/#nearai.registry.resolve_local_path","title":"resolve_local_path","text":"<pre><code>resolve_local_path(local_path: Path) -&gt; Path\n</code></pre> <p>Determines if the <code>local_path</code> is <code>local_path</code> or <code>registry_folder/local_path</code>.</p> <p>Raises FileNotFoundError if folder or parent folder is not present.</p> Source code in <code>nearai/registry.py</code> <pre><code>def resolve_local_path(local_path: Path) -&gt; Path:\n    \"\"\"Determines if the `local_path` is `local_path` or `registry_folder/local_path`.\n\n    Raises FileNotFoundError if folder or parent folder is not present.\n    \"\"\"\n    if local_path.exists() or local_path.parent.exists():\n        return local_path\n\n    registry_path = get_registry_folder() / local_path\n    if registry_path.exists() or registry_path.parent.exists():\n        return registry_path\n\n    # If neither exists, raise an error\n    raise FileNotFoundError(f\"Path not found: {local_path} or {registry_path}\")\n</code></pre>"},{"location":"api/#nearai.registry.validate_version","title":"validate_version","text":"<pre><code>validate_version(\n    version: str,\n) -&gt; Tuple[bool, Optional[str]]\n</code></pre> <p>Validate version string according to PEP 440.</p> <pre><code>version: Version string to validate\n</code></pre> <pre><code>Tuple of (is_valid, error_message)\n</code></pre> Source code in <code>nearai/registry.py</code> <pre><code>def validate_version(version: str) -&gt; Tuple[bool, Optional[str]]:\n    \"\"\"Validate version string according to PEP 440.\n\n    Args:\n    ----\n        version: Version string to validate\n\n    Returns:\n    -------\n        Tuple of (is_valid, error_message)\n\n    \"\"\"\n    try:\n        Version(version)\n        return True, None\n    except InvalidVersion as e:\n        return False, f\"Invalid version format: {str(e)}. Version must follow PEP 440:https://peps.python.org/pep-0440.\"\n</code></pre>"},{"location":"api/#nearai.shared","title":"shared","text":""},{"location":"api/#nearai.shared.auth_data","title":"auth_data","text":""},{"location":"api/#nearai.shared.auth_data.AuthData","title":"AuthData","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/shared/auth_data.py</code> <pre><code>class AuthData(BaseModel):\n    account_id: str\n    signature: str\n    public_key: str\n    callback_url: str\n    nonce: str\n    recipient: str\n    message: str\n    on_behalf_of: Optional[str] = None\n\n    def generate_bearer_token(self):\n        \"\"\"Generates a JSON-encoded bearer token containing authentication data.\"\"\"\n        required_keys = {\"account_id\", \"public_key\", \"signature\", \"callback_url\", \"message\", \"nonce\", \"recipient\"}\n\n        for key in required_keys:\n            if getattr(self, key) is None:\n                raise ValueError(f\"Missing required auth data: {key}\")\n\n        if self.on_behalf_of is not None:\n            required_keys.add(\"on_behalf_of\")\n\n        bearer_data = {key: getattr(self, key) for key in required_keys}\n\n        return json.dumps(bearer_data)\n\n    @property\n    def namespace(self):\n        \"\"\"Get the account ID for the auth data.\n\n        In case you are running a request on behalf of another account, this will return the account ID of the account.\n        \"\"\"\n        if self.on_behalf_of is not None:\n            return self.on_behalf_of\n        return self.account_id\n</code></pre>"},{"location":"api/#nearai.shared.auth_data.AuthData.namespace","title":"namespace  <code>property</code>","text":"<pre><code>namespace\n</code></pre> <p>Get the account ID for the auth data.</p> <p>In case you are running a request on behalf of another account, this will return the account ID of the account.</p>"},{"location":"api/#nearai.shared.auth_data.AuthData.generate_bearer_token","title":"generate_bearer_token","text":"<pre><code>generate_bearer_token()\n</code></pre> <p>Generates a JSON-encoded bearer token containing authentication data.</p> Source code in <code>nearai/shared/auth_data.py</code> <pre><code>def generate_bearer_token(self):\n    \"\"\"Generates a JSON-encoded bearer token containing authentication data.\"\"\"\n    required_keys = {\"account_id\", \"public_key\", \"signature\", \"callback_url\", \"message\", \"nonce\", \"recipient\"}\n\n    for key in required_keys:\n        if getattr(self, key) is None:\n            raise ValueError(f\"Missing required auth data: {key}\")\n\n    if self.on_behalf_of is not None:\n        required_keys.add(\"on_behalf_of\")\n\n    bearer_data = {key: getattr(self, key) for key in required_keys}\n\n    return json.dumps(bearer_data)\n</code></pre>"},{"location":"api/#nearai.shared.cache","title":"cache","text":""},{"location":"api/#nearai.shared.cache.mem_cache_with_timeout","title":"mem_cache_with_timeout","text":"<pre><code>mem_cache_with_timeout(timeout: int)\n</code></pre> <p>Decorator to cache function results for a specified timeout period.</p> Source code in <code>nearai/shared/cache.py</code> <pre><code>def mem_cache_with_timeout(timeout: int):\n    \"\"\"Decorator to cache function results for a specified timeout period.\"\"\"\n\n    def decorator(func):\n        cache = {}\n\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            now = time.time()\n            key = (args, frozenset(kwargs.items()))\n            if key in cache:\n                result, timestamp = cache[key]\n                if now - timestamp &lt; timeout:\n                    return result\n            result = func(*args, **kwargs)\n            cache[key] = (result, now)\n            return result\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/#nearai.shared.client_config","title":"client_config","text":""},{"location":"api/#nearai.shared.client_config.ClientConfig","title":"ClientConfig","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/shared/client_config.py</code> <pre><code>class ClientConfig(BaseModel):\n    base_url: str = \"https://api.near.ai/v1\"\n    custom_llm_provider: str = \"openai\"\n    auth: Optional[AuthData] = None\n    default_provider: Optional[str] = None  # future: remove in favor of api decision\n    num_inference_retries: int = 1\n\n    def get_hub_client(self):\n        \"\"\"Get the hub client.\"\"\"\n        signature = f\"Bearer {self.auth.model_dump_json()}\" if self.auth else None\n        base_url = self.base_url\n        return openai.OpenAI(\n            base_url=base_url, api_key=signature, timeout=DEFAULT_TIMEOUT, max_retries=DEFAULT_MAX_RETRIES\n        )\n</code></pre>"},{"location":"api/#nearai.shared.client_config.ClientConfig.get_hub_client","title":"get_hub_client","text":"<pre><code>get_hub_client()\n</code></pre> <p>Get the hub client.</p> Source code in <code>nearai/shared/client_config.py</code> <pre><code>def get_hub_client(self):\n    \"\"\"Get the hub client.\"\"\"\n    signature = f\"Bearer {self.auth.model_dump_json()}\" if self.auth else None\n    base_url = self.base_url\n    return openai.OpenAI(\n        base_url=base_url, api_key=signature, timeout=DEFAULT_TIMEOUT, max_retries=DEFAULT_MAX_RETRIES\n    )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client","title":"inference_client","text":""},{"location":"api/#nearai.shared.inference_client.InferenceClient","title":"InferenceClient","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>class InferenceClient(object):\n    def __init__(self, config: ClientConfig, runner_api_key: str = \"\", agent_identifier: str = \"\") -&gt; None:  # noqa: D107\n        self._config = config\n        self.runner_api_key = runner_api_key\n        self.agent_identifier = agent_identifier\n        self._auth = None\n        self.generate_auth_for_current_agent(config, agent_identifier)\n        self.client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n        self._provider_models: Optional[ProviderModels] = None\n\n    def generate_auth_for_current_agent(self, config, agent_identifier):\n        \"\"\"Regenerate auth for the current agent.\"\"\"\n        self.agent_identifier = agent_identifier\n        if config.auth is not None:\n            auth_bearer_token = config.auth.generate_bearer_token()\n            new_token = json.loads(auth_bearer_token)\n            new_token[\"runner_data\"] = json.dumps({\"agent\": agent_identifier, \"runner_api_key\": self.runner_api_key})\n            auth_bearer_token = json.dumps(new_token)\n            self._auth = auth_bearer_token\n        else:\n            self._auth = None\n\n    # This makes sense in the CLI where we don't mind doing this request and caching it.\n    # In the aws_runner this is an extra request every time we run.\n    # TODO(#233): add a choice of a provider model in aws_runner, and then this step can be skipped.\n    @cached_property\n    def provider_models(self) -&gt; ProviderModels:  # noqa: D102\n        if self._provider_models is None:\n            self._provider_models = ProviderModels(self._config)\n        return self._provider_models\n\n    def set_provider_models(self, provider_models: Optional[ProviderModels]):\n        \"\"\"Set provider models. Used by external caching.\"\"\"\n        if provider_models is None:\n            self._provider_models = ProviderModels(self._config)\n        else:\n            self._provider_models = provider_models\n\n    def get_agent_public_key(self, agent_name: str) -&gt; str:\n        \"\"\"Request agent public key.\"\"\"\n        headers = {\n            \"Content-Type\": \"application/json\",\n        }\n\n        data = {\"agent_name\": agent_name}\n\n        endpoint = f\"{self._config.base_url}/get_agent_public_key\"\n\n        try:\n            response = requests.post(endpoint, headers=headers, params=data)\n            response.raise_for_status()\n            return response.json()\n        except requests.RequestException as e:\n            raise ValueError(f\"Failed to get agent public key: {e}\") from None\n\n    def completions(\n        self,\n        model: str,\n        messages: Iterable[ChatCompletionMessageParam],\n        stream: bool = False,\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None,\n        **kwargs: Any,\n    ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n        \"\"\"Takes a `model` and `messages` and returns completions.\n\n        `model` can be:\n        1. full path `provider::model_full_path`.\n        2. `model_short_name`. Default provider will be used.\n        \"\"\"\n        if self._config.base_url != self._config.default_provider:\n            provider, model = self.provider_models.match_provider_model(model)\n        else:\n            provider = self._config.default_provider\n\n        if temperature is None:\n            temperature = DEFAULT_MODEL_TEMPERATURE\n\n        if max_tokens is None:\n            max_tokens = DEFAULT_MODEL_MAX_TOKENS\n\n        # NOTE(#246): this is to disable \"Provider List\" messages.\n        litellm.suppress_debug_info = True\n\n        # lite_llm uses the openai.request_timeout to set the timeout for the request of \"openai\" custom provider\n        openai.timeout = DEFAULT_TIMEOUT\n        openai.max_retries = DEFAULT_MAX_RETRIES\n\n        for i in range(0, self._config.num_inference_retries):\n            try:\n                # Create a dictionary for the arguments\n                completion_args = {\n                    \"model\": model,\n                    \"messages\": messages,\n                    \"stream\": stream,\n                    \"custom_llm_provider\": self._config.custom_llm_provider,\n                    \"input_cost_per_token\": 0,\n                    \"output_cost_per_token\": 0,\n                    \"temperature\": temperature,\n                    \"max_tokens\": max_tokens,\n                    \"base_url\": self._config.base_url,\n                    \"api_key\": self._auth,\n                    \"timeout\": DEFAULT_TIMEOUT,\n                    \"request_timeout\": DEFAULT_TIMEOUT,\n                    \"num_retries\": 1,\n                }\n                # Only add provider parameter if base_url is different from default_provider\n                if self._config.base_url != self._config.default_provider:\n                    completion_args[\"provider\"] = provider\n                # Add any additional kwargs\n                completion_args.update(kwargs)\n                result: Union[ModelResponse, CustomStreamWrapper] = litellm_completion(**completion_args)\n                break\n            except Exception as e:\n                print(\"Completions exception:\", e)\n                if i == self._config.num_inference_retries - 1:\n                    raise ValueError(f\"Bad request: {e}\") from None\n                else:\n                    print(\"Retrying...\")\n\n        return result\n\n    def query_vector_store(\n        self, vector_store_id: str, query: str, full_files: bool = False\n    ) -&gt; Union[List[SimilaritySearch], List[SimilaritySearchFile]]:\n        \"\"\"Query a vector store.\"\"\"\n        if self._config is None:\n            raise ValueError(\"Missing NEAR AI Hub config\")\n\n        auth_bearer_token = self._auth\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {auth_bearer_token}\",\n        }\n\n        data = {\"query\": query, \"full_files\": full_files}\n\n        endpoint = f\"{self._config.base_url}/vector_stores/{vector_store_id}/search\"\n\n        try:\n            response = requests.post(endpoint, headers=headers, json=data)\n            response.raise_for_status()\n            return response.json()\n        except requests.RequestException as e:\n            raise ValueError(f\"Error querying vector store: {e}\") from None\n\n    def upload_file(\n        self,\n        file_content: str,\n        purpose: Literal[\"assistants\", \"batch\", \"fine-tune\", \"vision\"],\n        encoding: Optional[str] = \"utf-8\",\n        file_name: Optional[str] = \"file.txt\",\n        file_type: Optional[str] = \"text/plain\",\n    ) -&gt; Optional[FileObject]:\n        \"\"\"Uploads a file.\"\"\"\n        client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n        if file_content:\n            file_data = io.BytesIO(file_content.encode(encoding or \"utf-8\"))\n            return client.files.create(file=(file_name, file_data, file_type), purpose=purpose)\n        else:\n            return None\n\n    def remove_file(self, file_id: str):\n        \"\"\"Removes a file.\"\"\"\n        client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n        return client.files.delete(file_id=file_id)\n\n    def add_file_to_vector_store(self, vector_store_id: str, file_id: str) -&gt; VectorStoreFile:\n        \"\"\"Adds a file to vector store.\"\"\"\n        client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n        return client.vector_stores.files.create(vector_store_id=vector_store_id, file_id=file_id)\n\n    def get_vector_store_files(self, vector_store_id: str) -&gt; Optional[List[VectorStoreFile]]:\n        \"\"\"Adds a file to vector store.\"\"\"\n        client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n        return client.vector_stores.files.list(vector_store_id=vector_store_id).data\n\n    def create_vector_store_from_source(\n        self,\n        name: str,\n        source: Union[GitHubSource, GitLabSource],\n        source_auth: Optional[str] = None,\n        chunking_strategy: Optional[ChunkingStrategy] = None,\n        expires_after: Optional[ExpiresAfter] = None,\n        metadata: Optional[Dict[str, str]] = None,\n    ) -&gt; VectorStore:\n        \"\"\"Creates a vector store from the given source.\n\n        Args:\n        ----\n            name (str): The name of the vector store.\n            source (Union[GitHubSource, GitLabSource]): The source from which to create the vector store.\n            source_auth (Optional[str]): The source authentication token.\n            chunking_strategy (Optional[ChunkingStrategy]): The chunking strategy to use.\n            expires_after (Optional[ExpiresAfter]): The expiration policy.\n            metadata (Optional[Dict[str, str]]): Additional metadata.\n\n        Returns:\n        -------\n            VectorStore: The created vector store.\n\n        \"\"\"\n        print(f\"Creating vector store from source: {source}\")\n        headers = {\n            \"Authorization\": f\"Bearer {self._auth}\",\n            \"Content-Type\": \"application/json\",\n        }\n        data = {\n            \"name\": name,\n            \"source\": source,\n            \"source_auth\": source_auth,\n            \"chunking_strategy\": chunking_strategy,\n            \"expires_after\": expires_after,\n            \"metadata\": metadata,\n        }\n        endpoint = f\"{self._config.base_url}/vector_stores/from_source\"\n\n        try:\n            response = requests.post(endpoint, headers=headers, json=data)\n            print(response.json())\n            response.raise_for_status()\n            return VectorStore(**response.json())\n        except requests.RequestException as e:\n            raise ValueError(f\"Failed to create vector store: {e}\") from None\n\n    def create_vector_store(\n        self,\n        name: str,\n        file_ids: List[str],\n        expires_after: Union[ExpiresAfter, NotGiven] = NOT_GIVEN,\n        chunking_strategy: Union[\n            AutoFileChunkingStrategyParam, StaticFileChunkingStrategyObjectParam, NotGiven\n        ] = NOT_GIVEN,\n        metadata: Optional[Dict[str, str]] = None,\n    ) -&gt; VectorStore:\n        \"\"\"Creates Vector Store.\n\n        :param name: Vector store name.\n        :param file_ids: Files to be added to the vector store.\n        :param expires_after: Expiration policy.\n        :param chunking_strategy: Chunking strategy.\n        :param metadata: Additional metadata.\n        :return: Returns the created vector store or error.\n        \"\"\"\n        client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n        return client.vector_stores.create(\n            file_ids=file_ids,\n            name=name,\n            expires_after=expires_after,\n            chunking_strategy=chunking_strategy,\n            metadata=metadata,\n        )\n\n    def get_vector_store(self, vector_store_id: str) -&gt; VectorStore:\n        \"\"\"Gets a vector store by id.\"\"\"\n        endpoint = f\"{self._config.base_url}/vector_stores/{vector_store_id}\"\n        auth_bearer_token = self._auth\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {auth_bearer_token}\",\n        }\n\n        response = requests.get(endpoint, headers=headers)\n        response.raise_for_status()\n        return VectorStore(**response.json())\n\n    def create_thread(self, messages):\n        \"\"\"Create a thread.\"\"\"\n        return self.client.beta.threads.create(messages=messages)\n\n    def get_thread(self, thread_id: str):\n        \"\"\"Get a thread.\"\"\"\n        return self.client.beta.threads.retrieve(thread_id=thread_id)\n\n    def threads_messages_create(self, thread_id: str, content: str, role: Literal[\"user\", \"assistant\"]):\n        \"\"\"Create a message in a thread.\"\"\"\n        return self.client.beta.threads.messages.create(thread_id=thread_id, content=content, role=role)\n\n    def threads_create_and_run_poll(self, assistant_id: str, model: str, messages: List[ChatCompletionMessageParam]):\n        \"\"\"Create a thread and run the assistant.\"\"\"\n        thread = self.create_thread(messages)\n        return self.client.beta.threads.create_and_run_poll(thread=thread, assistant_id=assistant_id, model=model)\n\n    def threads_list_messages(self, thread_id: str, order: Literal[\"asc\", \"desc\"] = \"asc\"):\n        \"\"\"List messages in a thread.\"\"\"\n        return self.client.beta.threads.messages.list(thread_id=thread_id, order=order)\n\n    def threads_fork(self, thread_id: str):\n        \"\"\"Fork a thread.\"\"\"\n        forked_thread = self.client.post(path=f\"{self._config.base_url}/threads/{thread_id}/fork\", cast_to=Thread)\n        return forked_thread\n\n    def create_subthread(\n        self,\n        thread_id: str,\n        messages_to_copy: Optional[List[str]] = None,\n        new_messages: Optional[List[ChatCompletionMessageParam]] = None,\n    ):\n        \"\"\"Create a subthread.\"\"\"\n        return self.client.post(\n            path=f\"{self._config.base_url}/threads/{thread_id}/subthread\",\n            body={messages_to_copy: messages_to_copy, new_messages: new_messages},\n            cast_to=Thread,\n        )\n\n    def threads_runs_create(self, thread_id: str, assistant_id: str, model: str):\n        \"\"\"Create a run in a thread.\"\"\"\n        return self.client.beta.threads.runs.create(thread_id=thread_id, assistant_id=assistant_id, model=model)\n\n    def run_agent(\n        self, run_on_thread_id: str, assistant_id: str, parent_run_id: str = \"\", run_mode: RunMode = RunMode.SIMPLE\n    ):\n        \"\"\"Starts a child agent run from a parent agent run.\"\"\"\n        extra_body = {}\n        if parent_run_id:\n            extra_body[\"parent_run_id\"] = parent_run_id\n        extra_body[\"run_mode\"] = run_mode.value  # type: ignore\n        return self.client.beta.threads.runs.create(\n            thread_id=run_on_thread_id,\n            assistant_id=assistant_id,\n            extra_body=extra_body,\n        )\n\n    def schedule_run(\n        self,\n        agent: str,\n        input_message: str,\n        thread_id: Optional[str],\n        run_params: Optional[Dict[str, str]],\n        run_at: datetime,\n    ):\n        \"\"\"Query a vector store.\"\"\"\n        if self._config is None:\n            raise ValueError(\"Missing NearAI Hub config\")\n\n        auth_bearer_token = self._auth\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {auth_bearer_token}\",\n        }\n\n        if run_params is None:\n            run_params = {}\n\n        data = {\n            \"agent\": agent,\n            \"input_message\": input_message,\n            \"thread_id\": thread_id,\n            \"run_params\": run_params,\n            \"run_at\": run_at,\n        }\n\n        endpoint = f\"{self._config.base_url}/schedule_run\"\n\n        try:\n            response = requests.post(endpoint, headers=headers, json=data)\n            response.raise_for_status()\n            return response.json()\n        except requests.RequestException as e:\n            raise ValueError(f\"Error querying schedule_run: {e}\") from None\n\n    def query_user_memory(self, query: str):\n        \"\"\"Query the user memory.\"\"\"\n        return self.client.post(\n            path=f\"{self._config.base_url}/vector_stores/memory/query\",\n            body={\"query\": query},\n            cast_to=str,\n        )\n\n    def add_user_memory(self, memory: str):\n        \"\"\"Add user memory.\"\"\"\n        return self.client.post(\n            path=f\"{self._config.base_url}/vector_stores/memory\",\n            body={\"memory\": memory},\n            cast_to=str,\n        )\n\n    def generate_image(self, prompt: str):\n        \"\"\"Generate an image.\"\"\"\n        return self.client.images.generate(prompt=prompt)\n\n    def save_agent_data(self, key: str, agent_data: Dict[str, Any]):\n        \"\"\"Save agent data for the agent this client was initialized with.\"\"\"\n        return self.client.post(\n            path=f\"{self._config.base_url}/agent_data\",\n            body={\n                \"key\": key,\n                \"value\": agent_data,\n            },\n            cast_to=Dict[str, Any],\n        )\n\n    def get_agent_data(self):\n        \"\"\"Get agent data for the agent this client was initialized with.\"\"\"\n        return self.client.get(\n            path=f\"{self._config.base_url}/agent_data\",\n            cast_to=Dict[str, str],\n        )\n\n    def get_agent_data_by_key(self, key: str):\n        \"\"\"Get agent data by key for the agent this client was initialized with.\"\"\"\n        return self.client.get(\n            path=f\"{self._config.base_url}/agent_data/{key}\",\n            cast_to=Dict[str, str],\n        )\n\n    def find_agents(\n        self,\n        owner_id: Optional[str] = None,\n        with_capabilities: Optional[bool] = False,\n        latest_versions_only: Optional[bool] = True,\n        limit: Optional[int] = None,\n        offset: Optional[int] = None,\n    ):\n        \"\"\"Filter agents.\"\"\"\n        return self.client.post(\n            path=f\"{self._config.base_url}/find_agents\",\n            body={\n                \"owner_id\": owner_id,\n                \"with_capabilities\": with_capabilities,\n                \"latest_versions_only\": latest_versions_only,\n                \"limit\": limit,\n                \"offset\": offset,\n            },\n            cast_to=List[Any],\n        )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.add_file_to_vector_store","title":"add_file_to_vector_store","text":"<pre><code>add_file_to_vector_store(\n    vector_store_id: str, file_id: str\n) -&gt; VectorStoreFile\n</code></pre> <p>Adds a file to vector store.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def add_file_to_vector_store(self, vector_store_id: str, file_id: str) -&gt; VectorStoreFile:\n    \"\"\"Adds a file to vector store.\"\"\"\n    client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n    return client.vector_stores.files.create(vector_store_id=vector_store_id, file_id=file_id)\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.add_user_memory","title":"add_user_memory","text":"<pre><code>add_user_memory(memory: str)\n</code></pre> <p>Add user memory.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def add_user_memory(self, memory: str):\n    \"\"\"Add user memory.\"\"\"\n    return self.client.post(\n        path=f\"{self._config.base_url}/vector_stores/memory\",\n        body={\"memory\": memory},\n        cast_to=str,\n    )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.completions","title":"completions","text":"<pre><code>completions(\n    model: str,\n    messages: Iterable[ChatCompletionMessageParam],\n    stream: bool = False,\n    temperature: Optional[float] = None,\n    max_tokens: Optional[int] = None,\n    **kwargs: Any,\n) -&gt; Union[ModelResponse, CustomStreamWrapper]\n</code></pre> <p>Takes a <code>model</code> and <code>messages</code> and returns completions.</p> <p><code>model</code> can be: 1. full path <code>provider::model_full_path</code>. 2. <code>model_short_name</code>. Default provider will be used.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def completions(\n    self,\n    model: str,\n    messages: Iterable[ChatCompletionMessageParam],\n    stream: bool = False,\n    temperature: Optional[float] = None,\n    max_tokens: Optional[int] = None,\n    **kwargs: Any,\n) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n    \"\"\"Takes a `model` and `messages` and returns completions.\n\n    `model` can be:\n    1. full path `provider::model_full_path`.\n    2. `model_short_name`. Default provider will be used.\n    \"\"\"\n    if self._config.base_url != self._config.default_provider:\n        provider, model = self.provider_models.match_provider_model(model)\n    else:\n        provider = self._config.default_provider\n\n    if temperature is None:\n        temperature = DEFAULT_MODEL_TEMPERATURE\n\n    if max_tokens is None:\n        max_tokens = DEFAULT_MODEL_MAX_TOKENS\n\n    # NOTE(#246): this is to disable \"Provider List\" messages.\n    litellm.suppress_debug_info = True\n\n    # lite_llm uses the openai.request_timeout to set the timeout for the request of \"openai\" custom provider\n    openai.timeout = DEFAULT_TIMEOUT\n    openai.max_retries = DEFAULT_MAX_RETRIES\n\n    for i in range(0, self._config.num_inference_retries):\n        try:\n            # Create a dictionary for the arguments\n            completion_args = {\n                \"model\": model,\n                \"messages\": messages,\n                \"stream\": stream,\n                \"custom_llm_provider\": self._config.custom_llm_provider,\n                \"input_cost_per_token\": 0,\n                \"output_cost_per_token\": 0,\n                \"temperature\": temperature,\n                \"max_tokens\": max_tokens,\n                \"base_url\": self._config.base_url,\n                \"api_key\": self._auth,\n                \"timeout\": DEFAULT_TIMEOUT,\n                \"request_timeout\": DEFAULT_TIMEOUT,\n                \"num_retries\": 1,\n            }\n            # Only add provider parameter if base_url is different from default_provider\n            if self._config.base_url != self._config.default_provider:\n                completion_args[\"provider\"] = provider\n            # Add any additional kwargs\n            completion_args.update(kwargs)\n            result: Union[ModelResponse, CustomStreamWrapper] = litellm_completion(**completion_args)\n            break\n        except Exception as e:\n            print(\"Completions exception:\", e)\n            if i == self._config.num_inference_retries - 1:\n                raise ValueError(f\"Bad request: {e}\") from None\n            else:\n                print(\"Retrying...\")\n\n    return result\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.create_subthread","title":"create_subthread","text":"<pre><code>create_subthread(\n    thread_id: str,\n    messages_to_copy: Optional[List[str]] = None,\n    new_messages: Optional[\n        List[ChatCompletionMessageParam]\n    ] = None,\n)\n</code></pre> <p>Create a subthread.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def create_subthread(\n    self,\n    thread_id: str,\n    messages_to_copy: Optional[List[str]] = None,\n    new_messages: Optional[List[ChatCompletionMessageParam]] = None,\n):\n    \"\"\"Create a subthread.\"\"\"\n    return self.client.post(\n        path=f\"{self._config.base_url}/threads/{thread_id}/subthread\",\n        body={messages_to_copy: messages_to_copy, new_messages: new_messages},\n        cast_to=Thread,\n    )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.create_thread","title":"create_thread","text":"<pre><code>create_thread(messages)\n</code></pre> <p>Create a thread.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def create_thread(self, messages):\n    \"\"\"Create a thread.\"\"\"\n    return self.client.beta.threads.create(messages=messages)\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.create_vector_store","title":"create_vector_store","text":"<pre><code>create_vector_store(\n    name: str,\n    file_ids: List[str],\n    expires_after: Union[\n        ExpiresAfter, NotGiven\n    ] = NOT_GIVEN,\n    chunking_strategy: Union[\n        AutoFileChunkingStrategyParam,\n        StaticFileChunkingStrategyObjectParam,\n        NotGiven,\n    ] = NOT_GIVEN,\n    metadata: Optional[Dict[str, str]] = None,\n) -&gt; VectorStore\n</code></pre> <p>Creates Vector Store.</p> <p>:param name: Vector store name. :param file_ids: Files to be added to the vector store. :param expires_after: Expiration policy. :param chunking_strategy: Chunking strategy. :param metadata: Additional metadata. :return: Returns the created vector store or error.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def create_vector_store(\n    self,\n    name: str,\n    file_ids: List[str],\n    expires_after: Union[ExpiresAfter, NotGiven] = NOT_GIVEN,\n    chunking_strategy: Union[\n        AutoFileChunkingStrategyParam, StaticFileChunkingStrategyObjectParam, NotGiven\n    ] = NOT_GIVEN,\n    metadata: Optional[Dict[str, str]] = None,\n) -&gt; VectorStore:\n    \"\"\"Creates Vector Store.\n\n    :param name: Vector store name.\n    :param file_ids: Files to be added to the vector store.\n    :param expires_after: Expiration policy.\n    :param chunking_strategy: Chunking strategy.\n    :param metadata: Additional metadata.\n    :return: Returns the created vector store or error.\n    \"\"\"\n    client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n    return client.vector_stores.create(\n        file_ids=file_ids,\n        name=name,\n        expires_after=expires_after,\n        chunking_strategy=chunking_strategy,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.create_vector_store_from_source","title":"create_vector_store_from_source","text":"<pre><code>create_vector_store_from_source(\n    name: str,\n    source: Union[GitHubSource, GitLabSource],\n    source_auth: Optional[str] = None,\n    chunking_strategy: Optional[ChunkingStrategy] = None,\n    expires_after: Optional[ExpiresAfter] = None,\n    metadata: Optional[Dict[str, str]] = None,\n) -&gt; VectorStore\n</code></pre> <p>Creates a vector store from the given source.</p> <pre><code>name (str): The name of the vector store.\nsource (Union[GitHubSource, GitLabSource]): The source from which to create the vector store.\nsource_auth (Optional[str]): The source authentication token.\nchunking_strategy (Optional[ChunkingStrategy]): The chunking strategy to use.\nexpires_after (Optional[ExpiresAfter]): The expiration policy.\nmetadata (Optional[Dict[str, str]]): Additional metadata.\n</code></pre> <pre><code>VectorStore: The created vector store.\n</code></pre> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def create_vector_store_from_source(\n    self,\n    name: str,\n    source: Union[GitHubSource, GitLabSource],\n    source_auth: Optional[str] = None,\n    chunking_strategy: Optional[ChunkingStrategy] = None,\n    expires_after: Optional[ExpiresAfter] = None,\n    metadata: Optional[Dict[str, str]] = None,\n) -&gt; VectorStore:\n    \"\"\"Creates a vector store from the given source.\n\n    Args:\n    ----\n        name (str): The name of the vector store.\n        source (Union[GitHubSource, GitLabSource]): The source from which to create the vector store.\n        source_auth (Optional[str]): The source authentication token.\n        chunking_strategy (Optional[ChunkingStrategy]): The chunking strategy to use.\n        expires_after (Optional[ExpiresAfter]): The expiration policy.\n        metadata (Optional[Dict[str, str]]): Additional metadata.\n\n    Returns:\n    -------\n        VectorStore: The created vector store.\n\n    \"\"\"\n    print(f\"Creating vector store from source: {source}\")\n    headers = {\n        \"Authorization\": f\"Bearer {self._auth}\",\n        \"Content-Type\": \"application/json\",\n    }\n    data = {\n        \"name\": name,\n        \"source\": source,\n        \"source_auth\": source_auth,\n        \"chunking_strategy\": chunking_strategy,\n        \"expires_after\": expires_after,\n        \"metadata\": metadata,\n    }\n    endpoint = f\"{self._config.base_url}/vector_stores/from_source\"\n\n    try:\n        response = requests.post(endpoint, headers=headers, json=data)\n        print(response.json())\n        response.raise_for_status()\n        return VectorStore(**response.json())\n    except requests.RequestException as e:\n        raise ValueError(f\"Failed to create vector store: {e}\") from None\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.find_agents","title":"find_agents","text":"<pre><code>find_agents(\n    owner_id: Optional[str] = None,\n    with_capabilities: Optional[bool] = False,\n    latest_versions_only: Optional[bool] = True,\n    limit: Optional[int] = None,\n    offset: Optional[int] = None,\n)\n</code></pre> <p>Filter agents.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def find_agents(\n    self,\n    owner_id: Optional[str] = None,\n    with_capabilities: Optional[bool] = False,\n    latest_versions_only: Optional[bool] = True,\n    limit: Optional[int] = None,\n    offset: Optional[int] = None,\n):\n    \"\"\"Filter agents.\"\"\"\n    return self.client.post(\n        path=f\"{self._config.base_url}/find_agents\",\n        body={\n            \"owner_id\": owner_id,\n            \"with_capabilities\": with_capabilities,\n            \"latest_versions_only\": latest_versions_only,\n            \"limit\": limit,\n            \"offset\": offset,\n        },\n        cast_to=List[Any],\n    )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.generate_auth_for_current_agent","title":"generate_auth_for_current_agent","text":"<pre><code>generate_auth_for_current_agent(config, agent_identifier)\n</code></pre> <p>Regenerate auth for the current agent.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def generate_auth_for_current_agent(self, config, agent_identifier):\n    \"\"\"Regenerate auth for the current agent.\"\"\"\n    self.agent_identifier = agent_identifier\n    if config.auth is not None:\n        auth_bearer_token = config.auth.generate_bearer_token()\n        new_token = json.loads(auth_bearer_token)\n        new_token[\"runner_data\"] = json.dumps({\"agent\": agent_identifier, \"runner_api_key\": self.runner_api_key})\n        auth_bearer_token = json.dumps(new_token)\n        self._auth = auth_bearer_token\n    else:\n        self._auth = None\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.generate_image","title":"generate_image","text":"<pre><code>generate_image(prompt: str)\n</code></pre> <p>Generate an image.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def generate_image(self, prompt: str):\n    \"\"\"Generate an image.\"\"\"\n    return self.client.images.generate(prompt=prompt)\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.get_agent_data","title":"get_agent_data","text":"<pre><code>get_agent_data()\n</code></pre> <p>Get agent data for the agent this client was initialized with.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def get_agent_data(self):\n    \"\"\"Get agent data for the agent this client was initialized with.\"\"\"\n    return self.client.get(\n        path=f\"{self._config.base_url}/agent_data\",\n        cast_to=Dict[str, str],\n    )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.get_agent_data_by_key","title":"get_agent_data_by_key","text":"<pre><code>get_agent_data_by_key(key: str)\n</code></pre> <p>Get agent data by key for the agent this client was initialized with.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def get_agent_data_by_key(self, key: str):\n    \"\"\"Get agent data by key for the agent this client was initialized with.\"\"\"\n    return self.client.get(\n        path=f\"{self._config.base_url}/agent_data/{key}\",\n        cast_to=Dict[str, str],\n    )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.get_agent_public_key","title":"get_agent_public_key","text":"<pre><code>get_agent_public_key(agent_name: str) -&gt; str\n</code></pre> <p>Request agent public key.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def get_agent_public_key(self, agent_name: str) -&gt; str:\n    \"\"\"Request agent public key.\"\"\"\n    headers = {\n        \"Content-Type\": \"application/json\",\n    }\n\n    data = {\"agent_name\": agent_name}\n\n    endpoint = f\"{self._config.base_url}/get_agent_public_key\"\n\n    try:\n        response = requests.post(endpoint, headers=headers, params=data)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as e:\n        raise ValueError(f\"Failed to get agent public key: {e}\") from None\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.get_thread","title":"get_thread","text":"<pre><code>get_thread(thread_id: str)\n</code></pre> <p>Get a thread.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def get_thread(self, thread_id: str):\n    \"\"\"Get a thread.\"\"\"\n    return self.client.beta.threads.retrieve(thread_id=thread_id)\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.get_vector_store","title":"get_vector_store","text":"<pre><code>get_vector_store(vector_store_id: str) -&gt; VectorStore\n</code></pre> <p>Gets a vector store by id.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def get_vector_store(self, vector_store_id: str) -&gt; VectorStore:\n    \"\"\"Gets a vector store by id.\"\"\"\n    endpoint = f\"{self._config.base_url}/vector_stores/{vector_store_id}\"\n    auth_bearer_token = self._auth\n\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {auth_bearer_token}\",\n    }\n\n    response = requests.get(endpoint, headers=headers)\n    response.raise_for_status()\n    return VectorStore(**response.json())\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.get_vector_store_files","title":"get_vector_store_files","text":"<pre><code>get_vector_store_files(\n    vector_store_id: str,\n) -&gt; Optional[List[VectorStoreFile]]\n</code></pre> <p>Adds a file to vector store.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def get_vector_store_files(self, vector_store_id: str) -&gt; Optional[List[VectorStoreFile]]:\n    \"\"\"Adds a file to vector store.\"\"\"\n    client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n    return client.vector_stores.files.list(vector_store_id=vector_store_id).data\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.query_user_memory","title":"query_user_memory","text":"<pre><code>query_user_memory(query: str)\n</code></pre> <p>Query the user memory.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def query_user_memory(self, query: str):\n    \"\"\"Query the user memory.\"\"\"\n    return self.client.post(\n        path=f\"{self._config.base_url}/vector_stores/memory/query\",\n        body={\"query\": query},\n        cast_to=str,\n    )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.query_vector_store","title":"query_vector_store","text":"<pre><code>query_vector_store(\n    vector_store_id: str,\n    query: str,\n    full_files: bool = False,\n) -&gt; Union[\n    List[SimilaritySearch], List[SimilaritySearchFile]\n]\n</code></pre> <p>Query a vector store.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def query_vector_store(\n    self, vector_store_id: str, query: str, full_files: bool = False\n) -&gt; Union[List[SimilaritySearch], List[SimilaritySearchFile]]:\n    \"\"\"Query a vector store.\"\"\"\n    if self._config is None:\n        raise ValueError(\"Missing NEAR AI Hub config\")\n\n    auth_bearer_token = self._auth\n\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {auth_bearer_token}\",\n    }\n\n    data = {\"query\": query, \"full_files\": full_files}\n\n    endpoint = f\"{self._config.base_url}/vector_stores/{vector_store_id}/search\"\n\n    try:\n        response = requests.post(endpoint, headers=headers, json=data)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as e:\n        raise ValueError(f\"Error querying vector store: {e}\") from None\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.remove_file","title":"remove_file","text":"<pre><code>remove_file(file_id: str)\n</code></pre> <p>Removes a file.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def remove_file(self, file_id: str):\n    \"\"\"Removes a file.\"\"\"\n    client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n    return client.files.delete(file_id=file_id)\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.run_agent","title":"run_agent","text":"<pre><code>run_agent(\n    run_on_thread_id: str,\n    assistant_id: str,\n    parent_run_id: str = \"\",\n    run_mode: RunMode = SIMPLE,\n)\n</code></pre> <p>Starts a child agent run from a parent agent run.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def run_agent(\n    self, run_on_thread_id: str, assistant_id: str, parent_run_id: str = \"\", run_mode: RunMode = RunMode.SIMPLE\n):\n    \"\"\"Starts a child agent run from a parent agent run.\"\"\"\n    extra_body = {}\n    if parent_run_id:\n        extra_body[\"parent_run_id\"] = parent_run_id\n    extra_body[\"run_mode\"] = run_mode.value  # type: ignore\n    return self.client.beta.threads.runs.create(\n        thread_id=run_on_thread_id,\n        assistant_id=assistant_id,\n        extra_body=extra_body,\n    )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.save_agent_data","title":"save_agent_data","text":"<pre><code>save_agent_data(key: str, agent_data: Dict[str, Any])\n</code></pre> <p>Save agent data for the agent this client was initialized with.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def save_agent_data(self, key: str, agent_data: Dict[str, Any]):\n    \"\"\"Save agent data for the agent this client was initialized with.\"\"\"\n    return self.client.post(\n        path=f\"{self._config.base_url}/agent_data\",\n        body={\n            \"key\": key,\n            \"value\": agent_data,\n        },\n        cast_to=Dict[str, Any],\n    )\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.schedule_run","title":"schedule_run","text":"<pre><code>schedule_run(\n    agent: str,\n    input_message: str,\n    thread_id: Optional[str],\n    run_params: Optional[Dict[str, str]],\n    run_at: datetime,\n)\n</code></pre> <p>Query a vector store.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def schedule_run(\n    self,\n    agent: str,\n    input_message: str,\n    thread_id: Optional[str],\n    run_params: Optional[Dict[str, str]],\n    run_at: datetime,\n):\n    \"\"\"Query a vector store.\"\"\"\n    if self._config is None:\n        raise ValueError(\"Missing NearAI Hub config\")\n\n    auth_bearer_token = self._auth\n\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {auth_bearer_token}\",\n    }\n\n    if run_params is None:\n        run_params = {}\n\n    data = {\n        \"agent\": agent,\n        \"input_message\": input_message,\n        \"thread_id\": thread_id,\n        \"run_params\": run_params,\n        \"run_at\": run_at,\n    }\n\n    endpoint = f\"{self._config.base_url}/schedule_run\"\n\n    try:\n        response = requests.post(endpoint, headers=headers, json=data)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as e:\n        raise ValueError(f\"Error querying schedule_run: {e}\") from None\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.set_provider_models","title":"set_provider_models","text":"<pre><code>set_provider_models(\n    provider_models: Optional[ProviderModels],\n)\n</code></pre> <p>Set provider models. Used by external caching.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def set_provider_models(self, provider_models: Optional[ProviderModels]):\n    \"\"\"Set provider models. Used by external caching.\"\"\"\n    if provider_models is None:\n        self._provider_models = ProviderModels(self._config)\n    else:\n        self._provider_models = provider_models\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.threads_create_and_run_poll","title":"threads_create_and_run_poll","text":"<pre><code>threads_create_and_run_poll(\n    assistant_id: str,\n    model: str,\n    messages: List[ChatCompletionMessageParam],\n)\n</code></pre> <p>Create a thread and run the assistant.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def threads_create_and_run_poll(self, assistant_id: str, model: str, messages: List[ChatCompletionMessageParam]):\n    \"\"\"Create a thread and run the assistant.\"\"\"\n    thread = self.create_thread(messages)\n    return self.client.beta.threads.create_and_run_poll(thread=thread, assistant_id=assistant_id, model=model)\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.threads_fork","title":"threads_fork","text":"<pre><code>threads_fork(thread_id: str)\n</code></pre> <p>Fork a thread.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def threads_fork(self, thread_id: str):\n    \"\"\"Fork a thread.\"\"\"\n    forked_thread = self.client.post(path=f\"{self._config.base_url}/threads/{thread_id}/fork\", cast_to=Thread)\n    return forked_thread\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.threads_list_messages","title":"threads_list_messages","text":"<pre><code>threads_list_messages(\n    thread_id: str, order: Literal[\"asc\", \"desc\"] = \"asc\"\n)\n</code></pre> <p>List messages in a thread.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def threads_list_messages(self, thread_id: str, order: Literal[\"asc\", \"desc\"] = \"asc\"):\n    \"\"\"List messages in a thread.\"\"\"\n    return self.client.beta.threads.messages.list(thread_id=thread_id, order=order)\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.threads_messages_create","title":"threads_messages_create","text":"<pre><code>threads_messages_create(\n    thread_id: str,\n    content: str,\n    role: Literal[\"user\", \"assistant\"],\n)\n</code></pre> <p>Create a message in a thread.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def threads_messages_create(self, thread_id: str, content: str, role: Literal[\"user\", \"assistant\"]):\n    \"\"\"Create a message in a thread.\"\"\"\n    return self.client.beta.threads.messages.create(thread_id=thread_id, content=content, role=role)\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.threads_runs_create","title":"threads_runs_create","text":"<pre><code>threads_runs_create(\n    thread_id: str, assistant_id: str, model: str\n)\n</code></pre> <p>Create a run in a thread.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def threads_runs_create(self, thread_id: str, assistant_id: str, model: str):\n    \"\"\"Create a run in a thread.\"\"\"\n    return self.client.beta.threads.runs.create(thread_id=thread_id, assistant_id=assistant_id, model=model)\n</code></pre>"},{"location":"api/#nearai.shared.inference_client.InferenceClient.upload_file","title":"upload_file","text":"<pre><code>upload_file(\n    file_content: str,\n    purpose: Literal[\n        \"assistants\", \"batch\", \"fine-tune\", \"vision\"\n    ],\n    encoding: Optional[str] = \"utf-8\",\n    file_name: Optional[str] = \"file.txt\",\n    file_type: Optional[str] = \"text/plain\",\n) -&gt; Optional[FileObject]\n</code></pre> <p>Uploads a file.</p> Source code in <code>nearai/shared/inference_client.py</code> <pre><code>def upload_file(\n    self,\n    file_content: str,\n    purpose: Literal[\"assistants\", \"batch\", \"fine-tune\", \"vision\"],\n    encoding: Optional[str] = \"utf-8\",\n    file_name: Optional[str] = \"file.txt\",\n    file_type: Optional[str] = \"text/plain\",\n) -&gt; Optional[FileObject]:\n    \"\"\"Uploads a file.\"\"\"\n    client = openai.OpenAI(base_url=self._config.base_url, api_key=self._auth)\n    if file_content:\n        file_data = io.BytesIO(file_content.encode(encoding or \"utf-8\"))\n        return client.files.create(file=(file_name, file_data, file_type), purpose=purpose)\n    else:\n        return None\n</code></pre>"},{"location":"api/#nearai.shared.models","title":"models","text":""},{"location":"api/#nearai.shared.models.AutoFileChunkingStrategyParam","title":"AutoFileChunkingStrategyParam","text":"<p>               Bases: <code>TypedDict</code></p> Source code in <code>nearai/shared/models.py</code> <pre><code>class AutoFileChunkingStrategyParam(TypedDict, total=False):\n    type: Required[Literal[\"auto\"]]\n    \"\"\"Always `auto`.\"\"\"\n</code></pre>"},{"location":"api/#nearai.shared.models.AutoFileChunkingStrategyParam.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[Literal['auto']]\n</code></pre> <p>Always <code>auto</code>.</p>"},{"location":"api/#nearai.shared.models.ChunkingStrategy","title":"ChunkingStrategy","text":"<p>               Bases: <code>BaseModel</code></p> <p>Defines the chunking strategy for vector stores.</p> Source code in <code>nearai/shared/models.py</code> <pre><code>class ChunkingStrategy(BaseModel):\n    \"\"\"Defines the chunking strategy for vector stores.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#nearai.shared.models.CreateVectorStoreRequest","title":"CreateVectorStoreRequest","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request model for creating a new vector store.</p> Source code in <code>nearai/shared/models.py</code> <pre><code>class CreateVectorStoreRequest(BaseModel):\n    \"\"\"Request model for creating a new vector store.\"\"\"\n\n    chunking_strategy: Union[AutoFileChunkingStrategyParam, StaticFileChunkingStrategyParam, None] = None\n    \"\"\"The chunking strategy to use for the vector store.\"\"\"\n    expires_after: Optional[ExpiresAfter] = None\n    \"\"\"The expiration time for the vector store.\"\"\"\n    file_ids: Optional[List[str]] = None\n    \"\"\"The file IDs to attach to the vector store.\"\"\"\n    metadata: Optional[Dict[str, str]] = None\n    \"\"\"The metadata to attach to the vector store.\"\"\"\n    name: str\n    \"\"\"The name of the vector store.\"\"\"\n</code></pre>"},{"location":"api/#nearai.shared.models.CreateVectorStoreRequest.chunking_strategy","title":"chunking_strategy  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>chunking_strategy: Union[\n    AutoFileChunkingStrategyParam,\n    StaticFileChunkingStrategyParam,\n    None,\n] = None\n</code></pre> <p>The chunking strategy to use for the vector store.</p>"},{"location":"api/#nearai.shared.models.CreateVectorStoreRequest.expires_after","title":"expires_after  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>expires_after: Optional[ExpiresAfter] = None\n</code></pre> <p>The expiration time for the vector store.</p>"},{"location":"api/#nearai.shared.models.CreateVectorStoreRequest.file_ids","title":"file_ids  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>file_ids: Optional[List[str]] = None\n</code></pre> <p>The file IDs to attach to the vector store.</p>"},{"location":"api/#nearai.shared.models.CreateVectorStoreRequest.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: Optional[Dict[str, str]] = None\n</code></pre> <p>The metadata to attach to the vector store.</p>"},{"location":"api/#nearai.shared.models.CreateVectorStoreRequest.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of the vector store.</p>"},{"location":"api/#nearai.shared.models.ExpiresAfter","title":"ExpiresAfter","text":"<p>               Bases: <code>TypedDict</code></p> Source code in <code>nearai/shared/models.py</code> <pre><code>class ExpiresAfter(TypedDict, total=False):\n    anchor: Required[Literal[\"last_active_at\"]]\n    \"\"\"Anchor timestamp after which the expiration policy applies.\n\n    Supported anchors: `last_active_at`.\n    \"\"\"\n\n    days: Required[int]\n    \"\"\"The number of days after the anchor time that the vector store will expire.\"\"\"\n</code></pre>"},{"location":"api/#nearai.shared.models.ExpiresAfter.anchor","title":"anchor  <code>instance-attribute</code>","text":"<pre><code>anchor: Required[Literal['last_active_at']]\n</code></pre> <p>Anchor timestamp after which the expiration policy applies.</p> <p>Supported anchors: <code>last_active_at</code>.</p>"},{"location":"api/#nearai.shared.models.ExpiresAfter.days","title":"days  <code>instance-attribute</code>","text":"<pre><code>days: Required[int]\n</code></pre> <p>The number of days after the anchor time that the vector store will expire.</p>"},{"location":"api/#nearai.shared.models.StaticFileChunkingStrategyParam","title":"StaticFileChunkingStrategyParam","text":"<p>               Bases: <code>TypedDict</code></p> Source code in <code>nearai/shared/models.py</code> <pre><code>class StaticFileChunkingStrategyParam(TypedDict, total=False):\n    chunk_overlap_tokens: Required[int]\n    \"\"\"The number of tokens that overlap between chunks. The default value is `400`.\n\n    Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n    \"\"\"\n\n    max_chunk_size_tokens: Required[int]\n    \"\"\"The maximum number of tokens in each chunk.\n\n    The default value is `800`. The minimum value is `100` and the maximum value is\n    `4096`.\n    \"\"\"\n</code></pre>"},{"location":"api/#nearai.shared.models.StaticFileChunkingStrategyParam.chunk_overlap_tokens","title":"chunk_overlap_tokens  <code>instance-attribute</code>","text":"<pre><code>chunk_overlap_tokens: Required[int]\n</code></pre> <p>The number of tokens that overlap between chunks. The default value is <code>400</code>.</p> <p>Note that the overlap must not exceed half of <code>max_chunk_size_tokens</code>.</p>"},{"location":"api/#nearai.shared.models.StaticFileChunkingStrategyParam.max_chunk_size_tokens","title":"max_chunk_size_tokens  <code>instance-attribute</code>","text":"<pre><code>max_chunk_size_tokens: Required[int]\n</code></pre> <p>The maximum number of tokens in each chunk.</p> <p>The default value is <code>800</code>. The minimum value is <code>100</code> and the maximum value is <code>4096</code>.</p>"},{"location":"api/#nearai.shared.models.VectorStoreFileCreate","title":"VectorStoreFileCreate","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request model for creating a vector store file.</p> Source code in <code>nearai/shared/models.py</code> <pre><code>class VectorStoreFileCreate(BaseModel):\n    \"\"\"Request model for creating a vector store file.\"\"\"\n\n    file_id: str\n    \"\"\"File ID returned from upload file endpoint.\"\"\"\n</code></pre>"},{"location":"api/#nearai.shared.models.VectorStoreFileCreate.file_id","title":"file_id  <code>instance-attribute</code>","text":"<pre><code>file_id: str\n</code></pre> <p>File ID returned from upload file endpoint.</p>"},{"location":"api/#nearai.shared.naming","title":"naming","text":""},{"location":"api/#nearai.shared.naming.NamespacedName","title":"NamespacedName","text":"Source code in <code>nearai/shared/naming.py</code> <pre><code>class NamespacedName:\n    def __init__(self, name: str, namespace: str = \"\"):  # noqa: D107\n        self.name = name\n        self.namespace = namespace\n\n    def __eq__(self, other):  # noqa: D105\n        if not isinstance(other, NamespacedName):\n            return NotImplemented\n        return self.name == other.name and self.namespace == other.namespace\n\n    def __hash__(self):  # noqa: D105\n        return hash((self.name, self.namespace))\n\n    def __str__(self):  # noqa: D105\n        if self.namespace:\n            return f\"{self.namespace}/{self.name}\"\n        return self.name\n\n    def __repr__(self):  # noqa: D105\n        return f\"NamespacedName(name='{self.name}', namespace='{self.namespace}')\"\n\n    def canonical(self) -&gt; \"NamespacedName\":  # noqa: D105\n        \"\"\"Returns canonical NamespacedName.\"\"\"\n        return NamespacedName(\n            name=get_canonical_name(self.name),\n            namespace=get_canonical_name(self.namespace) if self.namespace != DEFAULT_NAMESPACE else \"\",\n        )\n</code></pre>"},{"location":"api/#nearai.shared.naming.NamespacedName.canonical","title":"canonical","text":"<pre><code>canonical() -&gt; NamespacedName\n</code></pre> <p>Returns canonical NamespacedName.</p> Source code in <code>nearai/shared/naming.py</code> <pre><code>def canonical(self) -&gt; \"NamespacedName\":  # noqa: D105\n    \"\"\"Returns canonical NamespacedName.\"\"\"\n    return NamespacedName(\n        name=get_canonical_name(self.name),\n        namespace=get_canonical_name(self.namespace) if self.namespace != DEFAULT_NAMESPACE else \"\",\n    )\n</code></pre>"},{"location":"api/#nearai.shared.naming.create_registry_name","title":"create_registry_name","text":"<pre><code>create_registry_name(name: str) -&gt; str\n</code></pre> <p>Formats <code>name</code> for a suitable registry name.</p> Source code in <code>nearai/shared/naming.py</code> <pre><code>def create_registry_name(name: str) -&gt; str:\n    \"\"\"Formats `name` for a suitable registry name.\"\"\"\n    # Convert to lowercase\n    name = name.lower()\n    # Convert '.' between digits to 'p'\n    name = re.sub(r\"(\\d)\\.(\\d)\", r\"\\1p\\2\", name)\n    # Convert '&lt;digit&gt;v&lt;digit&gt;' -&gt; '&lt;digit&gt;-&lt;digit&gt;'\n    name = re.sub(r\"(\\d)v(\\d)\", r\"\\1-\\2\", name)\n    # Convert '&lt;not letter&gt;v&lt;digit&gt;' -&gt; '&lt;not letter&gt;&lt;digit&gt;'\n    name = re.sub(r\"(^|[^a-z])v(\\d)\", r\"\\1\\2\", name)\n    # Replace non-alphanumeric characters between digits with '-'\n    name = re.sub(r\"(\\d)[^a-z0-9]+(\\d)\", r\"\\1-\\2\", name)\n    # Remove remaining non-alphanumeric characters, except '-'\n    name = re.sub(r\"[^a-z0-9-]\", \"\", name)\n    # Convert 'metallama' or 'meta-llama' to 'llama'\n    name = name.replace(\"metallama\", \"llama\")\n    name = name.replace(\"meta-llama\", \"llama\")\n    # Convert 'qwenq' or 'qwen-q' to 'q'\n    name = name.replace(\"qwenq\", \"q\")\n    name = name.replace(\"qwen-q\", \"q\")\n    return name\n</code></pre>"},{"location":"api/#nearai.shared.naming.get_canonical_name","title":"get_canonical_name","text":"<pre><code>get_canonical_name(name: str) -&gt; str\n</code></pre> <p>Returns a name that can be used for matching entities.</p> <p>Applies such transformations: 1. All letters lowercase. 2. Strips '.near' extensions. 3. Convert '.' between digits to 'p'. 4. Convert 'v' -&gt; '' 5. Remove all non-alphanumeric characters except between digits.     Use '_' between digits. 6. Convert 'metallama' -&gt; 'llama'. <p>e.g. \"llama-3.1-70b-instruct\" -&gt; \"llama3p1_70binstruct\"</p> Source code in <code>nearai/shared/naming.py</code> <pre><code>def get_canonical_name(name: str) -&gt; str:\n    \"\"\"Returns a name that can be used for matching entities.\n\n    Applies such transformations:\n    1. All letters lowercase.\n    2. Strips '.near' extensions.\n    3. Convert '.' between digits to 'p'.\n    4. Convert '&lt;not letter&gt;v&lt;digit&gt;' -&gt; '&lt;not letter&gt;&lt;digit&gt;'\n    5. Remove all non-alphanumeric characters except between digits.\n        Use '_' between digits.\n    6. Convert 'metallama' -&gt; 'llama'.\n\n    e.g. \"llama-3.1-70b-instruct\" -&gt; \"llama3p1_70binstruct\"\n    \"\"\"\n    # Convert to lowercase\n    name = name.lower()\n    # Strip .near extension if present\n    if name.endswith(\".near\"):\n        name = name[:-5]  # Remove last 5 characters ('.near')\n    # Convert '.' between digits to 'p'\n    name = re.sub(r\"(\\d)\\.(\\d)\", r\"\\1p\\2\", name)\n    # Convert '&lt;digit&gt;v&lt;digit&gt;' -&gt; '&lt;digit&gt;_&lt;digit&gt;'\n    name = re.sub(r\"(\\d)v(\\d)\", r\"\\1_\\2\", name)\n    # Convert '&lt;not letter&gt;v&lt;digit&gt;' -&gt; '&lt;not letter&gt;&lt;digit&gt;'\n    name = re.sub(r\"(^|[^a-z])v(\\d)\", r\"\\1\\2\", name)\n    # Replace non-alphanumeric characters between digits with '_'\n    name = re.sub(r\"(\\d)[^a-z0-9]+(\\d)\", r\"\\1_\\2\", name)\n    # Remove remaining non-alphanumeric characters, except '_'\n    name = re.sub(r\"[^a-z0-9_]\", \"\", name)\n    # Remove any remaining underscores that are not between digits\n    name = re.sub(r\"(?&lt;!\\d)_|_(?!\\d)\", \"\", name)\n    # Convert 'metallama' to 'llama'\n    name = name.replace(\"metallama\", \"llama\")\n    # Convert 'qwenq' to 'q'\n    name = name.replace(\"qwenq\", \"q\")\n    return name\n</code></pre>"},{"location":"api/#nearai.shared.near","title":"near","text":""},{"location":"api/#nearai.shared.near.sign","title":"sign","text":""},{"location":"api/#nearai.shared.near.sign.SignatureVerificationResult","title":"SignatureVerificationResult","text":"<p>               Bases: <code>Enum</code></p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>class SignatureVerificationResult(Enum):\n    TRUE = True\n    FALSE = False\n    VERIFY_ACCESS_KEY_OWNER_SERVICE_NOT_AVAILABLE = \"verify_access_key_owner_not_available\"\n\n    @classmethod\n    def from_bool(cls, value: bool):\n        \"\"\"Gets VerificationResult based on a boolean value.\"\"\"\n        return cls.TRUE if value else cls.FALSE\n\n    def __bool__(self):\n        \"\"\"Overrides the behavior when checking for truthiness.\"\"\"\n        return self == SignatureVerificationResult.TRUE\n</code></pre> __bool__ \u00b6 <pre><code>__bool__()\n</code></pre> <p>Overrides the behavior when checking for truthiness.</p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>def __bool__(self):\n    \"\"\"Overrides the behavior when checking for truthiness.\"\"\"\n    return self == SignatureVerificationResult.TRUE\n</code></pre> from_bool <code>classmethod</code> \u00b6 <pre><code>from_bool(value: bool)\n</code></pre> <p>Gets VerificationResult based on a boolean value.</p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>@classmethod\ndef from_bool(cls, value: bool):\n    \"\"\"Gets VerificationResult based on a boolean value.\"\"\"\n    return cls.TRUE if value else cls.FALSE\n</code></pre>"},{"location":"api/#nearai.shared.near.sign.convert_nonce","title":"convert_nonce","text":"<pre><code>convert_nonce(value: Union[str, bytes, list[int]])\n</code></pre> <p>Converts a given value to a 32-byte nonce.</p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>def convert_nonce(value: Union[str, bytes, list[int]]):\n    \"\"\"Converts a given value to a 32-byte nonce.\"\"\"\n    if isinstance(value, bytes):\n        if len(value) &gt; 32:\n            raise ValueError(\"Invalid nonce length\")\n        if len(value) &lt; 32:\n            value = value.rjust(32, b\"0\")\n        return value\n    elif isinstance(value, str):\n        nonce_bytes = value.encode(\"utf-8\")\n        if len(nonce_bytes) &gt; 32:\n            raise ValueError(\"Invalid nonce length\")\n        if len(nonce_bytes) &lt; 32:\n            nonce_bytes = nonce_bytes.rjust(32, b\"0\")\n        return nonce_bytes\n    elif isinstance(value, list):\n        if len(value) != 32:\n            raise ValueError(\"Invalid nonce length\")\n        return bytes(value)\n    else:\n        raise ValueError(\"Invalid nonce format\")\n</code></pre>"},{"location":"api/#nearai.shared.near.sign.create_inference_signature","title":"create_inference_signature","text":"<pre><code>create_inference_signature(\n    private_key: str, payload: CompletionSignaturePayload\n) -&gt; tuple[str, str]\n</code></pre> <p>Creates a cryptographic signature for a given extended inference payload using a specified private key.</p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>def create_inference_signature(private_key: str, payload: CompletionSignaturePayload) -&gt; tuple[str, str]:\n    \"\"\"Creates a cryptographic signature for a given extended inference payload using a specified private key.\"\"\"\n    borsh_payload = BinarySerializer(dict(COMPLETION_PAYLOAD_SCHEMA)).serialize(payload)\n\n    to_sign = hashlib.sha256(borsh_payload).digest()\n\n    private_key_base58 = private_key[len(ED_PREFIX) :]\n    private_key_bytes = base58.b58decode(private_key_base58)\n\n    if len(private_key_bytes) != 64:\n        raise ValueError(\"The private key must be exactly 64 bytes long\")\n\n    private_key_seed = private_key_bytes[:32]\n\n    signing_key = nacl.signing.SigningKey(private_key_seed)\n    public_key = signing_key.verify_key\n\n    signed = signing_key.sign(to_sign)\n    signature = base64.b64encode(signed.signature).decode(\"utf-8\")\n\n    public_key_base58 = base58.b58encode(public_key.encode()).decode(\"utf-8\")\n    full_public_key = ED_PREFIX + public_key_base58\n\n    return signature, full_public_key\n</code></pre>"},{"location":"api/#nearai.shared.near.sign.create_signature","title":"create_signature","text":"<pre><code>create_signature(\n    private_key: str, payload: Payload\n) -&gt; tuple[str, str]\n</code></pre> <p>Creates a cryptographic signature for a given payload using a specified private key.</p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>def create_signature(private_key: str, payload: Payload) -&gt; tuple[str, str]:\n    \"\"\"Creates a cryptographic signature for a given payload using a specified private key.\"\"\"\n    borsh_payload = BinarySerializer(dict(PAYLOAD_SCHEMA)).serialize(payload)\n\n    to_sign = hashlib.sha256(borsh_payload).digest()\n\n    # Extract and decode the private key\n    private_key_base58 = private_key[len(ED_PREFIX) :]\n    private_key_bytes = base58.b58decode(private_key_base58)\n\n    if len(private_key_bytes) != 64:\n        raise ValueError(\"The private key must be exactly 64 bytes long\")\n\n    # Use only the first 32 bytes as the seed\n    private_key_seed = private_key_bytes[:32]\n\n    signing_key = nacl.signing.SigningKey(private_key_seed)\n    public_key = signing_key.verify_key\n\n    signed = signing_key.sign(to_sign)\n    signature = base64.b64encode(signed.signature).decode(\"utf-8\")\n\n    public_key_base58 = base58.b58encode(public_key.encode()).decode(\"utf-8\")\n    full_public_key = ED_PREFIX + public_key_base58\n\n    return signature, full_public_key\n</code></pre>"},{"location":"api/#nearai.shared.near.sign.validate_completion_signature","title":"validate_completion_signature","text":"<pre><code>validate_completion_signature(\n    public_key: str,\n    signature: str,\n    payload: CompletionSignaturePayload,\n)\n</code></pre> <p>Validates a cryptographic signature for a given payload using a specified public key.</p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>def validate_completion_signature(public_key: str, signature: str, payload: CompletionSignaturePayload):\n    \"\"\"Validates a cryptographic signature for a given payload using a specified public key.\"\"\"\n    borsh_payload = BinarySerializer(dict(COMPLETION_PAYLOAD_SCHEMA)).serialize(payload)\n    to_sign = hashlib.sha256(borsh_payload).digest()\n    real_signature = base64.b64decode(signature)\n\n    verify_key: nacl.signing.VerifyKey = nacl.signing.VerifyKey(base58.b58decode(public_key[len(ED_PREFIX) :]))\n\n    try:\n        verify_key.verify(to_sign, real_signature)\n        return True\n    except nacl.exceptions.BadSignatureError:\n        return False\n</code></pre>"},{"location":"api/#nearai.shared.near.sign.validate_nonce","title":"validate_nonce","text":"<pre><code>validate_nonce(value: Union[str, bytes, list[int]])\n</code></pre> <p>Ensures that the nonce is a valid timestamp.</p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>def validate_nonce(value: Union[str, bytes, list[int]]):\n    \"\"\"Ensures that the nonce is a valid timestamp.\"\"\"\n    nonce = convert_nonce(value)\n    nonce_int = int(nonce.decode(\"utf-8\"))\n\n    now = int(time.time() * 1000)\n\n    if nonce_int &gt; now:\n        raise ValueError(\"Nonce is in the future\")\n    if now - nonce_int &gt; 10 * 365 * 24 * 60 * 60 * 1000:\n        \"\"\"If the timestamp is older than 10 years, it is considered invalid. Forcing apps to use unique nonces.\"\"\"\n        raise ValueError(\"Nonce is too old\")\n\n    return nonce\n</code></pre>"},{"location":"api/#nearai.shared.near.sign.validate_signature","title":"validate_signature","text":"<pre><code>validate_signature(\n    public_key: str, signature: str, payload: Payload\n)\n</code></pre> <p>Validates a cryptographic signature for a given payload using a specified public key.</p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>def validate_signature(public_key: str, signature: str, payload: Payload):\n    \"\"\"Validates a cryptographic signature for a given payload using a specified public key.\"\"\"\n    borsh_payload = BinarySerializer(dict(PAYLOAD_SCHEMA)).serialize(payload)\n    to_sign = hashlib.sha256(borsh_payload).digest()\n    real_signature = base64.b64decode(signature)\n\n    verify_key: nacl.signing.VerifyKey = nacl.signing.VerifyKey(base58.b58decode(public_key[len(ED_PREFIX) :]))\n\n    try:\n        verify_key.verify(to_sign, real_signature)\n        # print(\"Signature is valid.\")\n        return True\n    except nacl.exceptions.BadSignatureError:\n        # print(\"Signature was forged or corrupt.\")\n        return False\n</code></pre>"},{"location":"api/#nearai.shared.near.sign.verify_access_key_owner","title":"verify_access_key_owner","text":"<pre><code>verify_access_key_owner(\n    public_key, account_id\n) -&gt; SignatureVerificationResult\n</code></pre> <p>Verifies if a given public key belongs to a specified account ID using FastNEAR API.</p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>@mem_cache_with_timeout(300)\ndef verify_access_key_owner(public_key, account_id) -&gt; SignatureVerificationResult:\n    \"\"\"Verifies if a given public key belongs to a specified account ID using FastNEAR API.\"\"\"\n    try:\n        logger.info(f\"Verifying access key owner for public key: {public_key}, account_id: {account_id}\")\n        url = f\"https://api.fastnear.com/v0/public_key/{public_key}\"\n        response = requests.get(url)\n        response.raise_for_status()\n        content = response.json()\n        account_ids = content.get(\"account_ids\", [])\n        key_owner_verified = account_id in account_ids\n        if not key_owner_verified:\n            logger.info(\"Key's owner verification failed. Only NEAR Mainnet accounts are supported.\")\n        return SignatureVerificationResult.from_bool(key_owner_verified)\n    except requests.exceptions.HTTPError as http_err:\n        logger.error(f\"HTTP error occurred: {http_err}\")\n    except Exception as err:\n        logger.error(f\"Other error occurred: {err}\")\n\n    return SignatureVerificationResult.VERIFY_ACCESS_KEY_OWNER_SERVICE_NOT_AVAILABLE\n</code></pre>"},{"location":"api/#nearai.shared.near.sign.verify_signed_message","title":"verify_signed_message","text":"<pre><code>verify_signed_message(\n    account_id,\n    public_key,\n    signature,\n    message,\n    nonce,\n    recipient,\n    callback_url,\n) -&gt; SignatureVerificationResult\n</code></pre> <p>Verifies a signed message and ensures the public key belongs to the specified account.</p> Source code in <code>nearai/shared/near/sign.py</code> <pre><code>def verify_signed_message(\n    account_id, public_key, signature, message, nonce, recipient, callback_url\n) -&gt; SignatureVerificationResult:\n    \"\"\"Verifies a signed message and ensures the public key belongs to the specified account.\"\"\"\n    is_valid = validate_signature(public_key, signature, Payload(message, nonce, recipient, callback_url))\n\n    if not is_valid and callback_url is not None:\n        is_valid = validate_signature(public_key, signature, Payload(message, nonce, recipient, None))\n\n    if is_valid:\n        # verify that key belongs to `account_id`\n        return verify_access_key_owner(public_key, account_id)\n\n    # TODO verifies that key is a FULL ACCESS KEY\n\n    return SignatureVerificationResult.FALSE\n</code></pre>"},{"location":"api/#nearai.shared.provider_models","title":"provider_models","text":""},{"location":"api/#nearai.shared.provider_models.ProviderModels","title":"ProviderModels","text":"Source code in <code>nearai/shared/provider_models.py</code> <pre><code>class ProviderModels:\n    def __init__(self, config: ClientConfig) -&gt; None:  # noqa: D107\n        self._config = config\n\n    @cached_property\n    def provider_models(self) -&gt; Dict[NamespacedName, Dict[str, str]]:\n        \"\"\"Returns a mapping canonical-&gt;provider-&gt;model_full_name.\"\"\"\n        client = self._config.get_hub_client()\n\n        try:\n            models = client.models.list()\n\n            assert len(models.data) &gt; 0, \"No models found\"\n            result: Dict[NamespacedName, Dict[str, str]] = {}\n            for model in models.data:\n                provider, namespaced_model = get_provider_namespaced_model(model.id)\n                namespaced_model = namespaced_model.canonical()\n                if namespaced_model not in result:\n                    result[namespaced_model] = {}\n                if provider in result[namespaced_model]:\n                    raise ValueError(f\"Duplicate entry for provider {provider} and model {namespaced_model}\")\n                result[namespaced_model][provider] = model.id\n\n            return result\n\n        except requests.RequestException as e:\n            raise RuntimeError(f\"Error fetching models: {str(e)}\") from e\n\n    def available_provider_matches(self, model: NamespacedName) -&gt; Dict[str, str]:\n        \"\"\"Returns provider matches for `model`.\"\"\"\n        return self.provider_models.get(model.canonical(), {})\n\n    def match_provider_model(self, model: str, provider: Optional[str] = None) -&gt; Tuple[str, str]:\n        \"\"\"Returns provider and model_full_path for given `model` and optional `provider`.\n\n        `model` may take different formats. Supported ones:\n        1. model_full_path, e.g. \"fireworks::accounts/yi-01-ai/models/yi-large\"\n        2. model_full_path without provider, e.g. \"accounts/yi-01-ai/models/yi-large\"\n        3. model_short_name as used by provider, e.g. \"llama-v3-70b-instruct\"\n        4. namespace/model_short_name as used by provider, e.g. \"yi-01-ai/yi-large\"\n        5. model_name as used in registry, e.g. \"llama-3-70b-instruct\"\n        6. namespace/model_name as used in registry, e.g. \"near.ai/llama-3-70b-instruct\"\n        7. provider base url/model-name, e.g. \"https://api.openai.com/v1::gpt-4o\"\n        \"\"\"\n        if provider == \"\":\n            provider = None\n        matched_provider, namespaced_model = get_provider_namespaced_model(model, provider)\n        if matched_provider.startswith(\"https://\"):\n            return matched_provider, namespaced_model.name\n        namespaced_model = namespaced_model.canonical()\n        if namespaced_model not in self.provider_models:\n            raise ValueError(f\"Model {namespaced_model} not present in provider models {self.provider_models}\")\n        available_matches = self.provider_models[namespaced_model]\n        if matched_provider not in available_matches:\n            for match in available_matches.keys():\n                matched_provider = match\n                break\n        if provider and provider != matched_provider:\n            raise ValueError(\n                f\"Requested provider {provider} for model {model} does not match matched_provider {matched_provider}\"\n            )\n        return matched_provider, available_matches[matched_provider]\n\n    def get_unregistered_common_provider_models(\n        self, registry_models: Dict[NamespacedName, NamespacedName]\n    ) -&gt; List[Dict[str, str]]:\n        \"\"\"Returns provider matches for unregistered provider models with default namespace.\"\"\"\n        result: List[Dict[str, str]] = []\n        for namespaced_name, available_matches in self.provider_models.items():\n            if namespaced_name.namespace != \"\" or namespaced_name in registry_models:\n                continue\n            result.append(available_matches)\n        return result\n</code></pre>"},{"location":"api/#nearai.shared.provider_models.ProviderModels.provider_models","title":"provider_models  <code>cached</code> <code>property</code>","text":"<pre><code>provider_models: Dict[NamespacedName, Dict[str, str]]\n</code></pre> <p>Returns a mapping canonical-&gt;provider-&gt;model_full_name.</p>"},{"location":"api/#nearai.shared.provider_models.ProviderModels.available_provider_matches","title":"available_provider_matches","text":"<pre><code>available_provider_matches(\n    model: NamespacedName,\n) -&gt; Dict[str, str]\n</code></pre> <p>Returns provider matches for <code>model</code>.</p> Source code in <code>nearai/shared/provider_models.py</code> <pre><code>def available_provider_matches(self, model: NamespacedName) -&gt; Dict[str, str]:\n    \"\"\"Returns provider matches for `model`.\"\"\"\n    return self.provider_models.get(model.canonical(), {})\n</code></pre>"},{"location":"api/#nearai.shared.provider_models.ProviderModels.get_unregistered_common_provider_models","title":"get_unregistered_common_provider_models","text":"<pre><code>get_unregistered_common_provider_models(\n    registry_models: Dict[NamespacedName, NamespacedName],\n) -&gt; List[Dict[str, str]]\n</code></pre> <p>Returns provider matches for unregistered provider models with default namespace.</p> Source code in <code>nearai/shared/provider_models.py</code> <pre><code>def get_unregistered_common_provider_models(\n    self, registry_models: Dict[NamespacedName, NamespacedName]\n) -&gt; List[Dict[str, str]]:\n    \"\"\"Returns provider matches for unregistered provider models with default namespace.\"\"\"\n    result: List[Dict[str, str]] = []\n    for namespaced_name, available_matches in self.provider_models.items():\n        if namespaced_name.namespace != \"\" or namespaced_name in registry_models:\n            continue\n        result.append(available_matches)\n    return result\n</code></pre>"},{"location":"api/#nearai.shared.provider_models.ProviderModels.match_provider_model","title":"match_provider_model","text":"<pre><code>match_provider_model(\n    model: str, provider: Optional[str] = None\n) -&gt; Tuple[str, str]\n</code></pre> <p>Returns provider and model_full_path for given <code>model</code> and optional <code>provider</code>.</p> <p><code>model</code> may take different formats. Supported ones: 1. model_full_path, e.g. \"fireworks::accounts/yi-01-ai/models/yi-large\" 2. model_full_path without provider, e.g. \"accounts/yi-01-ai/models/yi-large\" 3. model_short_name as used by provider, e.g. \"llama-v3-70b-instruct\" 4. namespace/model_short_name as used by provider, e.g. \"yi-01-ai/yi-large\" 5. model_name as used in registry, e.g. \"llama-3-70b-instruct\" 6. namespace/model_name as used in registry, e.g. \"near.ai/llama-3-70b-instruct\" 7. provider base url/model-name, e.g. \"https://api.openai.com/v1::gpt-4o\"</p> Source code in <code>nearai/shared/provider_models.py</code> <pre><code>def match_provider_model(self, model: str, provider: Optional[str] = None) -&gt; Tuple[str, str]:\n    \"\"\"Returns provider and model_full_path for given `model` and optional `provider`.\n\n    `model` may take different formats. Supported ones:\n    1. model_full_path, e.g. \"fireworks::accounts/yi-01-ai/models/yi-large\"\n    2. model_full_path without provider, e.g. \"accounts/yi-01-ai/models/yi-large\"\n    3. model_short_name as used by provider, e.g. \"llama-v3-70b-instruct\"\n    4. namespace/model_short_name as used by provider, e.g. \"yi-01-ai/yi-large\"\n    5. model_name as used in registry, e.g. \"llama-3-70b-instruct\"\n    6. namespace/model_name as used in registry, e.g. \"near.ai/llama-3-70b-instruct\"\n    7. provider base url/model-name, e.g. \"https://api.openai.com/v1::gpt-4o\"\n    \"\"\"\n    if provider == \"\":\n        provider = None\n    matched_provider, namespaced_model = get_provider_namespaced_model(model, provider)\n    if matched_provider.startswith(\"https://\"):\n        return matched_provider, namespaced_model.name\n    namespaced_model = namespaced_model.canonical()\n    if namespaced_model not in self.provider_models:\n        raise ValueError(f\"Model {namespaced_model} not present in provider models {self.provider_models}\")\n    available_matches = self.provider_models[namespaced_model]\n    if matched_provider not in available_matches:\n        for match in available_matches.keys():\n            matched_provider = match\n            break\n    if provider and provider != matched_provider:\n        raise ValueError(\n            f\"Requested provider {provider} for model {model} does not match matched_provider {matched_provider}\"\n        )\n    return matched_provider, available_matches[matched_provider]\n</code></pre>"},{"location":"api/#nearai.shared.provider_models.get_provider_model","title":"get_provider_model","text":"<pre><code>get_provider_model(\n    provider: Optional[str], model: str\n) -&gt; Tuple[Optional[str], str]\n</code></pre> <p>Splits the <code>model</code> string based on a predefined separator and returns the components.</p> <pre><code>provider (Optional[str]): The default provider name. Can be `None` if the provider\n                          is included in the `model` string.\nmodel (str): The model identifier, which may include the provider name separated by\n             a specific delimiter (defined by `PROVIDER_MODEL_SEP`, e.g. `::`).\n</code></pre> Source code in <code>nearai/shared/provider_models.py</code> <pre><code>def get_provider_model(provider: Optional[str], model: str) -&gt; Tuple[Optional[str], str]:\n    \"\"\"Splits the `model` string based on a predefined separator and returns the components.\n\n    Args:\n    ----\n        provider (Optional[str]): The default provider name. Can be `None` if the provider\n                                  is included in the `model` string.\n        model (str): The model identifier, which may include the provider name separated by\n                     a specific delimiter (defined by `PROVIDER_MODEL_SEP`, e.g. `::`).\n\n    \"\"\"\n    if PROVIDER_MODEL_SEP in model:\n        parts = model.split(PROVIDER_MODEL_SEP)\n        assert len(parts) == 2\n        return parts[0], parts[1]\n    return provider, model\n</code></pre>"},{"location":"api/#nearai.shared.provider_models.get_provider_namespaced_model","title":"get_provider_namespaced_model","text":"<pre><code>get_provider_namespaced_model(\n    provider_model: str, provider: Optional[str] = None\n) -&gt; Tuple[str, NamespacedName]\n</code></pre> <p>Given <code>provider_model</code> returns provider and namespaced model.</p> Source code in <code>nearai/shared/provider_models.py</code> <pre><code>def get_provider_namespaced_model(provider_model: str, provider: Optional[str] = None) -&gt; Tuple[str, NamespacedName]:\n    \"\"\"Given `provider_model` returns provider and namespaced model.\"\"\"\n    provider_opt, provider_model = get_provider_model(DEFAULT_PROVIDER if not provider else provider, provider_model)\n    provider = cast(str, provider_opt)\n\n    if provider.startswith(\"https://\"):\n        return provider, NamespacedName(name=provider_model)\n    if provider == \"local\":\n        return provider, NamespacedName(name=provider_model)\n\n    provider_model = provider_model.replace(\"accounts/\", \"\")\n    provider_model = provider_model.replace(\"fireworks/\", \"\")\n    provider_model = provider_model.replace(\"models/\", \"\")\n    if provider == \"hyperbolic\":\n        provider_model = re.sub(r\".*/\", \"\", provider_model)\n        return provider, NamespacedName(provider_model)\n    if provider == \"fireworks\":\n        parts = provider_model.split(\"/\")\n        if len(parts) == 1:\n            return provider, NamespacedName(name=parts[0])\n        elif len(parts) == 2:\n            return provider, NamespacedName(namespace=parts[0], name=parts[1])\n        else:\n            raise ValueError(f\"Invalid model format for Fireworks: {provider_model}\")\n    raise ValueError(f\"Unrecognized provider: {provider}\")\n</code></pre>"},{"location":"api/#nearai.shared.secure_openai_clients","title":"secure_openai_clients","text":""},{"location":"api/#nearai.shared.secure_openai_clients.SecureAsyncOpenAI","title":"SecureAsyncOpenAI","text":"<p>Secure Async OpenAI client where api key is only accessible in constructor.</p> Source code in <code>nearai/shared/secure_openai_clients.py</code> <pre><code>class SecureAsyncOpenAI:\n    \"\"\"Secure Async OpenAI client where api key is only accessible in constructor.\"\"\"\n\n    def __init__(self, api_key, base_url, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize with auth token that's only accessible in constructor.\"\"\"\n        client = AsyncOpenAI(api_key=api_key, base_url=base_url, **kwargs)\n\n        # Define secure method using closure\n        async def create(self, **params: Any) -&gt; Any:\n            \"\"\"Create a chat completion with secure auth.\"\"\"\n            return await client.chat.completions.create(**params)\n\n        # Create completions class\n        CompletionsClass = type(\"AsyncCompletions\", (), {\"create\": create})  # noqa: N806\n\n        # Create chat class\n        ChatClass = type(\"AsyncChat\", (), {\"completions\": CompletionsClass()})  # noqa: N806\n\n        # Attach chat instance\n        self.chat = ChatClass()\n</code></pre>"},{"location":"api/#nearai.shared.secure_openai_clients.SecureAsyncOpenAI.__init__","title":"__init__","text":"<pre><code>__init__(api_key, base_url, **kwargs: Any) -&gt; None\n</code></pre> <p>Initialize with auth token that's only accessible in constructor.</p> Source code in <code>nearai/shared/secure_openai_clients.py</code> <pre><code>def __init__(self, api_key, base_url, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize with auth token that's only accessible in constructor.\"\"\"\n    client = AsyncOpenAI(api_key=api_key, base_url=base_url, **kwargs)\n\n    # Define secure method using closure\n    async def create(self, **params: Any) -&gt; Any:\n        \"\"\"Create a chat completion with secure auth.\"\"\"\n        return await client.chat.completions.create(**params)\n\n    # Create completions class\n    CompletionsClass = type(\"AsyncCompletions\", (), {\"create\": create})  # noqa: N806\n\n    # Create chat class\n    ChatClass = type(\"AsyncChat\", (), {\"completions\": CompletionsClass()})  # noqa: N806\n\n    # Attach chat instance\n    self.chat = ChatClass()\n</code></pre>"},{"location":"api/#nearai.shared.secure_openai_clients.SecureOpenAI","title":"SecureOpenAI","text":"<p>Secure OpenAI client where api key is only accessible in constructor.</p> Source code in <code>nearai/shared/secure_openai_clients.py</code> <pre><code>class SecureOpenAI:\n    \"\"\"Secure OpenAI client where api key is only accessible in constructor.\"\"\"\n\n    def __init__(self, api_key, base_url, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize with auth token that's only accessible in constructor.\"\"\"\n        client = OpenAI(api_key=api_key, base_url=base_url, **kwargs)\n\n        # Define secure method using closure\n        def create(self, **params: Any) -&gt; Any:\n            \"\"\"Create a chat completion with secure auth.\"\"\"\n            return client.chat.completions.create(**params)\n\n        # Create completions class\n        CompletionsClass = type(\"Completions\", (), {\"create\": create})  # noqa: N806\n\n        # Create chat class\n        ChatClass = type(\"Chat\", (), {\"completions\": CompletionsClass()})  # noqa: N806\n\n        # Attach chat instance\n        self.chat = ChatClass()\n</code></pre>"},{"location":"api/#nearai.shared.secure_openai_clients.SecureOpenAI.__init__","title":"__init__","text":"<pre><code>__init__(api_key, base_url, **kwargs: Any) -&gt; None\n</code></pre> <p>Initialize with auth token that's only accessible in constructor.</p> Source code in <code>nearai/shared/secure_openai_clients.py</code> <pre><code>def __init__(self, api_key, base_url, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize with auth token that's only accessible in constructor.\"\"\"\n    client = OpenAI(api_key=api_key, base_url=base_url, **kwargs)\n\n    # Define secure method using closure\n    def create(self, **params: Any) -&gt; Any:\n        \"\"\"Create a chat completion with secure auth.\"\"\"\n        return client.chat.completions.create(**params)\n\n    # Create completions class\n    CompletionsClass = type(\"Completions\", (), {\"create\": create})  # noqa: N806\n\n    # Create chat class\n    ChatClass = type(\"Chat\", (), {\"completions\": CompletionsClass()})  # noqa: N806\n\n    # Attach chat instance\n    self.chat = ChatClass()\n</code></pre>"},{"location":"api/#nearai.solvers","title":"solvers","text":""},{"location":"api/#nearai.solvers.DDOTSV0Solver","title":"DDOTSV0Solver","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for competitive programming problems live on DDOTS.</p> <p>This dataset will run agents in an Agent environment previously prepared.</p> <p>workspace/     .id             -- Id of the problem     PROBLEM.txt     -- Description of the problem</p> <p>The agent should call env.submit_python(code) to submit the code to the DDOTS server.</p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>class DDOTSV0Solver(SolverStrategy):\n    \"\"\"Solver strategy for competitive programming problems live on DDOTS.\n\n    This dataset will run agents in an Agent environment previously prepared.\n\n    workspace/\n        .id             -- Id of the problem\n        PROBLEM.txt     -- Description of the problem\n\n    The agent should call env.submit_python(code) to submit the code to the DDOTS server.\n\n    \"\"\"\n\n    def __init__(self, dataset_ref: Dataset, agents: str, max_iterations: int, save_snapshots: bool = False):  # noqa: D107\n        client_config = ClientConfig(\n            base_url=CONFIG.nearai_hub.base_url,\n            auth=CONFIG.auth,\n        )\n        self.agents = [Agent.load_agent(agent, client_config) for agent in agents.split(\",\")]\n        self.max_iterations = max_iterations\n\n        date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n        rnd_id = random.randint(10**8, 10**9 - 1)\n        self._saved_trajectories = DATA_FOLDER / \"data\" / \"ddots_v0_trajectories\" / f\"{date}_{rnd_id}\"\n        self._saved_trajectories.mkdir(parents=True, exist_ok=True)\n\n        self.save_snapshots = save_snapshots\n        print(\"Saving trajectories to\", self._saved_trajectories)\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"ddots\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"ddots_codeforces_small/v0\", \"datasets/ddots_codeforces_medium_A_B/v0\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        problem_id = datum[\"problem_id\"]\n        description = datum[\"description\"]\n\n        client_config = ClientConfig(\n            base_url=CONFIG.nearai_hub.base_url,\n            auth=CONFIG.auth,\n        )\n        client = InferenceClient(client_config)\n        env = DDOTSEnvironment(self.agents, problem_id, description, client)\n        env.write_file(\".solved\", str(False))\n\n        try:\n            env.run(description, max_iterations=self.max_iterations)\n            env.write_file(\".solved\", str(env.solved))\n\n        except Exception as e:\n            print(f\"Error running task: {e}\")\n\n        finally:\n            if self.save_snapshots:\n                snapshot = env.create_snapshot()\n                with open(self._saved_trajectories / f\"{problem_id}.tar.gz\", \"wb\") as f:\n                    f.write(snapshot)\n\n        return env.solved\n</code></pre>"},{"location":"api/#nearai.solvers.GSM8KSolverStrategy","title":"GSM8KSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the GSM8K dataset.</p> Source code in <code>nearai/solvers/gsm8k_solver.py</code> <pre><code>class GSM8KSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the GSM8K dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str = \"\", agent: str = \"\") -&gt; None:  # noqa: D107\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"gsm8k\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"gsm8k\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        parsed_datum: GSM8KDatum = GSM8KDatum(**datum)\n\n        problem_shots_indices = list(range(0, self.SHOTS))\n        problem_shots = list(\n            map(\n                lambda i: GSM8KDatum(**self.dataset_ref[\"train\"][i]).model_dump(),\n                problem_shots_indices,\n            )\n        )\n\n        session = self.start_inference_session(\"\")\n        session.add_system_message(\n            dedent(\n                \"\"\"\n                    You are a helpful assistant. You're goal is to answer word based math questions.\n                    \"\"\"\n                + \"\\n\\n\"\n                + \"Here are some examples of math questions and their answers:\"\n                + \"\\n\\n\".join([f\"Question: {shot['question']}\\nAnswer: {shot['answer']}\" for shot in problem_shots])\n                + \"\\n\\n\"\n                + \"Now, answer the next question provided in the user prompt. \"\n                + \"Think step by step about how to solve the problem. \"\n                + \"Then, provide the answer.\"\n            )\n        )\n        res_output = session.run_task(parsed_datum.question).strip()\n\n        ## cleanup the output\n        session = self.start_inference_session(\"\")\n        res_refined_output = session.run_task(\n            dedent(\n                f\"\"\"\n                    You are a helpful assistant. You're goal is to answer math questions.\n\n                    You have just answered a math question with the following response:\n\n                    --- BEGIN RESPONSE ---\n                    {res_output}\n                    --- END RESPONSE ---\n\n                    Please refine your answer.\n\n                    Only output the final number *without units* as your answer. Nothing else.\n                    \"\"\"\n            )\n        ).strip()\n        res_refined_output = res_refined_output.replace(\"$\", \"\").replace(\",\", \"\")\n        if \" \" in res_refined_output:\n            res_refined_output = res_refined_output.split(\" \")[0]\n        try:\n            res_refined_output = str(int(res_refined_output))\n        except Exception:\n            pass\n        try:\n            res_refined_output = str(int(float(res_refined_output)))\n        except Exception:\n            pass\n\n        refined_answer = parsed_datum.answer.replace(\"$\", \"\").replace(\",\", \"\")\n        print(res_refined_output, refined_answer)\n        return res_refined_output == refined_answer\n</code></pre>"},{"location":"api/#nearai.solvers.HellaswagSolverStrategy","title":"HellaswagSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/hellaswag_solver.py</code> <pre><code>class HellaswagSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], model: str = \"\", agent: str = \"\", shots: int = 8\n    ) -&gt; None:\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n        self.shots = shots\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return f\"hellaswag_{self.shots}shots\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"hellaswag\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = HellaswagDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.shots, 5))\n        example_problems = list(\n            map(\n                lambda d: HellaswagDatum(**d).model_dump(),\n                [self.dataset_ref[\"validation\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_verbose_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n        response = self.start_inference_session(\"\").run_task(base_prompt)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_extract_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        response = self.start_inference_session(\"\").run_task(extract_answer_prompt)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == int(datum[\"label\"]))\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.LeanSolverStrategy","title":"LeanSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy to evaluate against Lean problems.</p> Source code in <code>nearai/solvers/lean_solver.py</code> <pre><code>class LeanSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy to evaluate against Lean problems.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], model: str = \"\", agent: str = \"\"\n    ) -&gt; None:\n        super().__init__(model, agent)\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        assert self.dataset_evaluation_name\n        return self.dataset_evaluation_name\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"lean\"]\n\n    def solve(self, datum: dict) -&gt; Tuple[bool, dict]:  # noqa: D102\n        lean_datum = LeanDatum.model_validate(datum)\n        lean_datum.url = load_repository(lean_datum.url)\n\n        info: dict = {}\n        info[\"verbose\"] = {}\n\n        lean_task = LeanTaskInfo(\n            lean_datum.url,\n            lean_datum.commit,\n            lean_datum.filename,\n            lean_datum.theorem,\n            load_theorem(lean_datum),\n        )\n        info[\"verbose\"][\"theorem_raw\"] = lean_task.theorem_raw\n\n        base_prompt = Template(open(PROMPTS_FOLDER / \"lean_answer.j2\").read(), trim_blocks=True).render(\n            url=lean_task.url,\n            commit=lean_task.commit,\n            filepath=lean_task.filename,\n            theorem_name=lean_task.theorem,\n            theorem_raw=lean_task.theorem_raw,\n            begin_marker=BEGIN_MARKER,\n            end_marker=END_MARKER,\n        )\n        response = self.start_inference_session(\"\").run_task(base_prompt)\n\n        json_response = extract_between_markers(response)\n        if not json_response:\n            info[\"error\"] = \"Failed to extract between markers.\"\n            info[\"verbose\"][\"response\"] = response\n            return False, info\n\n        tactics = parse_tactics(json_response)\n        if not tactics:\n            info[\"error\"] = \"Failed to parse tactics.\"\n            info[\"verbose\"][\"response\"] = json_response\n            return False, info\n\n        # Sometimes, there are timeout errors.\n        num_attempts = 3\n        info[\"tactics\"] = tactics\n        for i in range(0, num_attempts):\n            if i != 0:\n                info[\"check_solution_attempts\"] = f\"{i + 1} (max: {num_attempts})\"\n            try:\n                r, m = check_solution(lean_datum, tactics)\n                if r:\n                    info[\"verbose\"][\"check_solution_message\"] = m\n                else:\n                    info[\"check_solution_message\"] = m\n                return r, info\n            except Exception as e:\n                if i == num_attempts - 1:\n                    error_message = f\"Exception while checking solution: {str(e)}.\"\n                    print(error_message)\n                    info[\"error\"] = error_message\n        return False, info\n</code></pre>"},{"location":"api/#nearai.solvers.LiveBenchSolverStrategy","title":"LiveBenchSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the live bench dataset.</p> Source code in <code>nearai/solvers/livebench_solver.py</code> <pre><code>class LiveBenchSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the live bench dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: str, model: str = \"\", agent: str = \"\", step: str = \"all\"\n    ) -&gt; None:\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n        self.step = step\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"live_bench\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"live_bench\"]\n\n    def get_custom_tasks(self) -&gt; List[dict]:  # noqa: D102\n        return [{\"summary\": \"all\"}]\n\n    @property\n    def evaluated_entry_name(self) -&gt; str:  # noqa: D102\n        name = \"\"\n        if self.agent:\n            name = self.agent_name()\n            if self.model_name != \"\":\n                name += f\"_with_model_{self.model_name}\"\n        else:\n            name = self.model_name\n        clean_name = re.sub(r\"[^a-zA-Z0-9_\\-.]\", \"_\", name)\n        return clean_name.lower()\n\n    @SolverStrategyClassProperty\n    def scoring_method(self) -&gt; SolverScoringMethod:  # noqa: D102\n        return SolverScoringMethod.Custom\n\n    def solve(self, _datum: dict) -&gt; Tuple[bool, dict]:  # noqa: D102\n        if self.step == \"gen_model_answer\":\n            self.gen_model_answer()\n            return True, {}\n        if self.step == \"gen_ground_truth_judgement\":\n            return self.gen_ground_truth_judgement(), {}\n        if self.step == \"show_livebench_results\":\n            return self.show_livebench_results()\n        if self.step == \"all\":\n            self.gen_model_answer()\n            if not self.gen_ground_truth_judgement():\n                return False, {}\n            return self.show_livebench_results()\n        return False, {}\n\n    def gen_model_answer(self) -&gt; None:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step gen_model_answer -----------\")\n        print(\"\")\n        list_of_question_files = glob.glob(f\"{self.dataset_ref}/**/question.jsonl\", recursive=True)\n        for question_file in list_of_question_files:\n            questions = load_questions_jsonl(question_file)\n            bench_name = os.path.dirname(question_file).split(str(self.dataset_ref))[-1]\n            answer_file = _get_answer_file_path(bench_name, self.evaluated_entry_name)\n            print(f\"Questions from {question_file}\")\n            print(f\"Output to {answer_file}\")\n            self.run_eval(questions, answer_file)\n\n    def run_eval(self, questions, answer_file) -&gt; None:  # noqa: D102\n        answer_file = os.path.expanduser(answer_file)\n\n        # Load existing answers\n        existing_answers = set()\n        if os.path.exists(answer_file):\n            print(\n                f\"Answer file {answer_file} exists. Will skip already answered questions. Delete this file if that is not intended.\"  # noqa: E501\n            )\n            with open(answer_file, \"r\") as fin:\n                for line in fin:\n                    answer = json.loads(line)\n                    existing_answers.add(answer[\"question_id\"])\n\n        for question in tqdm(questions):\n            if question[\"question_id\"] in existing_answers:\n                continue\n            choices = self.answer_question(question)\n\n            ans_json = {\n                \"question_id\": question[\"question_id\"],\n                \"answer_id\": shortuuid.uuid(),\n                \"model_id\": self.evaluated_entry_name,\n                \"choices\": choices,\n                \"tstamp\": time.time(),\n            }\n\n            os.makedirs(os.path.dirname(answer_file), exist_ok=True)\n            with open(answer_file, \"a\") as fout:\n                fout.write(json.dumps(ans_json) + \"\\n\")\n\n    def answer_question(self, question) -&gt; List[dict]:  # noqa: D102\n        turns = []\n        session = self.start_inference_session(question[\"question_id\"])\n        for qs in question[\"turns\"]:\n            output = session.run_task(qs)\n            turns.append(output)\n\n        return [{\"index\": 0, \"turns\": turns}]\n\n    def gen_ground_truth_judgement(self) -&gt; bool:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step gen_ground_truth_judgement -----------\")\n        print(\"\")\n        script_path = \"nearai/projects/live_bench/gen_ground_truth_judgement.sh\"\n\n        try:\n            # Run the script without capturing output\n            subprocess.run([\"/bin/bash\", script_path, self.evaluated_entry_name, self.dataset_ref], check=True)\n            return True\n\n        except subprocess.CalledProcessError as e:\n            print(f\"An error occurred while running the script: {e}\")\n            return False\n\n    def show_livebench_results(self) -&gt; Tuple[bool, dict]:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step show_livebench_results -----------\")\n        print(\"\")\n        script_path = \"nearai/projects/live_bench/show_livebench_results.sh\"\n\n        try:\n            # Run the script without capturing output\n            subprocess.run([\"/bin/bash\", script_path, self.evaluated_entry_name], check=True)\n\n        except subprocess.CalledProcessError as e:\n            print(f\"An error occurred while running the script: {e}\")\n            return False, {}\n\n        return self.create_result_dict()\n\n    def read_csv_to_dict(self, file_path) -&gt; dict:  # noqa: D102\n        file_path = os.path.expanduser(file_path)\n        with open(file_path, \"r\") as f:\n            reader = csv.DictReader(f)\n            matching_rows = [row for row in reader if row[\"model\"] == self.evaluated_entry_name]\n            return matching_rows[-1] if matching_rows else {}  # Get the last matching row\n\n    def create_result_dict(self) -&gt; Tuple[bool, dict]:  # noqa: D102\n        tasks_data = self.read_csv_to_dict(_get_all_tasks_csv_file())\n        groups_data = self.read_csv_to_dict(_get_all_groups_csv_file())\n\n        if not tasks_data or not groups_data:\n            return False, {}  # Return None if the model is not found in either file\n\n        result: dict = {\"tasks\": {}, \"groups\": {}}\n\n        for key, value in tasks_data.items():\n            if key != \"model\":\n                result[\"tasks\"][key] = float(value)\n\n        for key, value in groups_data.items():\n            if key != \"model\":\n                result[\"groups\"][key] = float(value)\n\n        return True, result\n\n    def get_evaluation_metrics(self, tasks_results: List[Tuple[bool, Any]]) -&gt; Dict[str, Any]:  # noqa: D102\n        results: Dict[str, Dict[str, Any]] = tasks_results[-1][1]\n        if len(results) == 0:\n            raise ValueError(\"Cache empty. Rerun the job with --force. Use --step arg to specify a step.\")\n        metrics: Dict[str, Any] = {\"average\": results[\"groups\"][\"average\"]}\n\n        for group, score in results[\"groups\"].items():\n            if group == \"average\":\n                continue\n            metrics[f\"group/{group}\"] = score\n\n        for task, score in results[\"tasks\"].items():\n            metrics[f\"task/{task}\"] = score\n\n        return metrics\n</code></pre>"},{"location":"api/#nearai.solvers.MBPPSolverStrategy","title":"MBPPSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MBPP dataset.</p> Source code in <code>nearai/solvers/mbpp_solver.py</code> <pre><code>class MBPPSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MBPP dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], model: str = \"\", agent: str = \"\", shots: int = 3\n    ) -&gt; None:\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n        self.shots = shots\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        prefix = self.dataset_evaluation_name if self.dataset_evaluation_name else \"mbpp\"\n        return f\"{prefix}_{self.shots}shots\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mbpp\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MBPPDatum(**datum).model_dump()\n\n        ## Allow LLM to think \"out loud\" for it's answer\n        function_name = get_function_name(datum[\"code\"])\n        example_problems = list(islice(self.dataset_ref[\"prompt\"], self.shots))\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mbpp_verbose_answer.j2\").read(), trim_blocks=True).render(\n            function_name=function_name,\n            example_problems=example_problems,\n            challenge_problem=datum,\n        )\n        response = self.start_inference_session(str(datum[\"task_id\"])).run_task(base_prompt)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mbpp_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            function_name=function_name,\n            answer_text=response,\n        )\n        response = self.start_inference_session(str(datum[\"task_id\"])).run_task(extract_answer_prompt)\n\n        ## Parse the python code\n        python_code_blocks = parse_python_code_block(response) + parse_code_block(response)\n        code = \"\"\n        if len(python_code_blocks) == 0:\n            code = response\n        else:\n            code = python_code_blocks[0]\n\n        ## Evaluate the code\n        try:\n            for test in datum[\"test_list\"] + datum[\"challenge_test_list\"]:\n                test_code = code + \"\\n\" + test\n                if not run_with_timeout(test_code):\n                    return False\n            return True\n        except Exception:\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.MMLUSolverStrategy","title":"MMLUSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/mmlu_solver.py</code> <pre><code>class MMLUSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], model: str = \"\", agent: str = \"\", shots: int = 8\n    ) -&gt; None:\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n        self.shots = shots\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        prefix = self.dataset_evaluation_name if self.dataset_evaluation_name else \"mmlu\"\n        return f\"{prefix}_{self.shots}shots\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mmlu\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MMLUDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.shots, 5))\n        example_problems = list(\n            map(\n                lambda d: MMLUDatum(**d).model_dump(),\n                [self.dataset_ref[\"dev\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mmlu_verbose_answer.j2\").read(), trim_blocks=True).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n\n        response = self.start_inference_session(\"\").run_task(base_prompt)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mmlu_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        response = self.start_inference_session(\"\").run_task(extract_answer_prompt)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == datum[\"answer\"])\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy","title":"SolverStrategy","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract class for solver strategies.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>class SolverStrategy(ABC, metaclass=SolverStrategyMeta):\n    \"\"\"Abstract class for solver strategies.\"\"\"\n\n    def __init__(self, model: str = \"\", agent: str = \"\") -&gt; None:\n        CONFIG.confirm_commands = False\n        self.client_config = CONFIG.get_client_config()\n        self.client = InferenceClient(self.client_config)\n        assert model != \"\" or agent != \"\"\n        self.dataset_evaluation_name = \"\"\n\n        self.provider = \"\"\n        self.model_namespace = \"\"\n        self.model_full_path = \"\"\n        self.model_name = \"\"\n        if model != \"\":\n            self.provider, self.model_full_path = self.client.provider_models.match_provider_model(model)\n            self.provider, namespaced_model = get_provider_namespaced_model(self.model_full_path, self.provider)\n            self.model_namespace = namespaced_model.namespace\n            self.model_name = namespaced_model.name\n\n        # If provider specified is a url, recreate a `client`.\n        if self.provider.startswith(\"https://\"):\n            self.client_config.base_url = self.provider\n            self.client_config.auth = None\n            self.client_config.default_provider = self.provider\n            print(self.client_config)\n            self.client = InferenceClient(self.client_config)\n\n        self.agent = agent\n        self.agent_params = {\n            \"api_url\": CONFIG.api_url,\n            \"data_source\": \"local_files\",\n            \"temperature\": 0.0,\n            \"record_run\": False,\n            \"verbose\": False,\n            \"change_to_agent_temp_dir\": False,\n        }\n        if self.model_full_path:\n            self.agent_params[\"model\"] = self.model_full_path\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Returns the name of the solver strategy.\"\"\"\n        return type(self).__name__\n\n    @SolverStrategyClassProperty\n    def scoring_method(self) -&gt; SolverScoringMethod:\n        return SolverScoringMethod.TrueOrFalseList\n\n    @abstractmethod\n    def evaluation_name(self) -&gt; str:\n        \"\"\"Returns a unique name for (benchmark, solver) tuple, e.g. 'mbpp' or 'live_bench' or 'mmlu-5-shot'.\"\"\"\n        ...\n\n    @abstractmethod\n    def compatible_datasets(self) -&gt; List[str]:\n        \"\"\"Returns the list of datasets that the solver strategy is compatible with.\"\"\"\n        ...\n\n    def agent_name(self) -&gt; str:\n        \"\"\"Returns agent name that is evaluated.\"\"\"\n        if not self.agent:\n            return \"\"\n        path = Path(self.agent)\n        return path.parent.name\n\n    def agent_version(self) -&gt; str:\n        \"\"\"Returns agent name that is evaluated.\"\"\"\n        if not self.agent:\n            return \"\"\n        path = Path(self.agent)\n        return path.name\n\n    def evaluated_entry_namespace(self) -&gt; str:\n        \"\"\"Returns namespace of a model or agent to be evaluated.\"\"\"\n        if self.agent:\n            path = Path(self.agent)\n            return path.parent.parent.name\n        return self.model_namespace\n\n    def model_provider(self) -&gt; str:\n        \"\"\"Returns model provider.\"\"\"\n        if self.provider != \"\":\n            return self.provider\n        if self.agent != \"\":\n            agent_obj = Agent.load_agent(self.agent, self.client_config, local=True)\n            return agent_obj.model_provider\n        return \"\"\n\n    @abstractmethod\n    def solve(self, datum: dict) -&gt; Union[bool, Tuple[bool, Any]]:\n        \"\"\"Solves the task for the given datum.\"\"\"\n        ...\n\n    def get_custom_tasks(self) -&gt; List[dict]:\n        \"\"\"Custom tasks for custom benchmark.\"\"\"\n        if self.scoring_method == SolverScoringMethod.Custom:\n            raise NotImplementedError(\"get_custom_tasks must be implemented for Custom scoring method\")\n        else:\n            raise AttributeError(\"get_custom_tasks is only applicable for Custom scoring method\")\n\n    def get_evaluation_metrics(self, tasks_results: List[Tuple[bool, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Given results for all datums, returns evaluation metrics.\n\n        Not used by TrueOrFalseList scoring method.\n        Do not prepend with evaluation_name. If hierarchical, use slashes /.\n        Expected metrics is a dict of scores, e.g.: {\"average\": &lt;val&gt;, \"group/coding\": &lt;val&gt;}.\n        \"\"\"\n        raise NotImplementedError(\"get_evaluation_metrics not implemented\")\n\n    def start_inference_session(self, task_id: str) -&gt; SolverInferenceSession:\n        return SolverInferenceSession(\n            self.agent, self.agent_params, self.model_full_path, self.client, self.evaluation_name()\n        ).start_inference_session(task_id)\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Returns the name of the solver strategy.</p>"},{"location":"api/#nearai.solvers.SolverStrategy.agent_name","title":"agent_name","text":"<pre><code>agent_name() -&gt; str\n</code></pre> <p>Returns agent name that is evaluated.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>def agent_name(self) -&gt; str:\n    \"\"\"Returns agent name that is evaluated.\"\"\"\n    if not self.agent:\n        return \"\"\n    path = Path(self.agent)\n    return path.parent.name\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.agent_version","title":"agent_version","text":"<pre><code>agent_version() -&gt; str\n</code></pre> <p>Returns agent name that is evaluated.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>def agent_version(self) -&gt; str:\n    \"\"\"Returns agent name that is evaluated.\"\"\"\n    if not self.agent:\n        return \"\"\n    path = Path(self.agent)\n    return path.name\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.compatible_datasets","title":"compatible_datasets  <code>abstractmethod</code>","text":"<pre><code>compatible_datasets() -&gt; List[str]\n</code></pre> <p>Returns the list of datasets that the solver strategy is compatible with.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>@abstractmethod\ndef compatible_datasets(self) -&gt; List[str]:\n    \"\"\"Returns the list of datasets that the solver strategy is compatible with.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.evaluated_entry_namespace","title":"evaluated_entry_namespace","text":"<pre><code>evaluated_entry_namespace() -&gt; str\n</code></pre> <p>Returns namespace of a model or agent to be evaluated.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>def evaluated_entry_namespace(self) -&gt; str:\n    \"\"\"Returns namespace of a model or agent to be evaluated.\"\"\"\n    if self.agent:\n        path = Path(self.agent)\n        return path.parent.parent.name\n    return self.model_namespace\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.evaluation_name","title":"evaluation_name  <code>abstractmethod</code>","text":"<pre><code>evaluation_name() -&gt; str\n</code></pre> <p>Returns a unique name for (benchmark, solver) tuple, e.g. 'mbpp' or 'live_bench' or 'mmlu-5-shot'.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>@abstractmethod\ndef evaluation_name(self) -&gt; str:\n    \"\"\"Returns a unique name for (benchmark, solver) tuple, e.g. 'mbpp' or 'live_bench' or 'mmlu-5-shot'.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.get_custom_tasks","title":"get_custom_tasks","text":"<pre><code>get_custom_tasks() -&gt; List[dict]\n</code></pre> <p>Custom tasks for custom benchmark.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>def get_custom_tasks(self) -&gt; List[dict]:\n    \"\"\"Custom tasks for custom benchmark.\"\"\"\n    if self.scoring_method == SolverScoringMethod.Custom:\n        raise NotImplementedError(\"get_custom_tasks must be implemented for Custom scoring method\")\n    else:\n        raise AttributeError(\"get_custom_tasks is only applicable for Custom scoring method\")\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.get_evaluation_metrics","title":"get_evaluation_metrics","text":"<pre><code>get_evaluation_metrics(\n    tasks_results: List[Tuple[bool, Any]],\n) -&gt; Dict[str, Any]\n</code></pre> <p>Given results for all datums, returns evaluation metrics.</p> <p>Not used by TrueOrFalseList scoring method. Do not prepend with evaluation_name. If hierarchical, use slashes /. Expected metrics is a dict of scores, e.g.: {\"average\": , \"group/coding\": }. Source code in <code>nearai/solvers/__init__.py</code> <pre><code>def get_evaluation_metrics(self, tasks_results: List[Tuple[bool, Any]]) -&gt; Dict[str, Any]:\n    \"\"\"Given results for all datums, returns evaluation metrics.\n\n    Not used by TrueOrFalseList scoring method.\n    Do not prepend with evaluation_name. If hierarchical, use slashes /.\n    Expected metrics is a dict of scores, e.g.: {\"average\": &lt;val&gt;, \"group/coding\": &lt;val&gt;}.\n    \"\"\"\n    raise NotImplementedError(\"get_evaluation_metrics not implemented\")\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.model_provider","title":"model_provider","text":"<pre><code>model_provider() -&gt; str\n</code></pre> <p>Returns model provider.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>def model_provider(self) -&gt; str:\n    \"\"\"Returns model provider.\"\"\"\n    if self.provider != \"\":\n        return self.provider\n    if self.agent != \"\":\n        agent_obj = Agent.load_agent(self.agent, self.client_config, local=True)\n        return agent_obj.model_provider\n    return \"\"\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.solve","title":"solve  <code>abstractmethod</code>","text":"<pre><code>solve(datum: dict) -&gt; Union[bool, Tuple[bool, Any]]\n</code></pre> <p>Solves the task for the given datum.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>@abstractmethod\ndef solve(self, datum: dict) -&gt; Union[bool, Tuple[bool, Any]]:\n    \"\"\"Solves the task for the given datum.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategyMeta","title":"SolverStrategyMeta","text":"<p>               Bases: <code>ABCMeta</code></p> <p>Metaclass that automatically registers subclasses in the SolverStrategyRegistry.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>class SolverStrategyMeta(ABCMeta):\n    \"\"\"Metaclass that automatically registers subclasses in the SolverStrategyRegistry.\"\"\"\n\n    def __new__(cls, name: str, bases: tuple, namespace: dict) -&gt; Any:\n        new_class = super().__new__(cls, name, bases, namespace)\n        if bases != (ABC,):  # Avoid registering the abstract base class itself\n            SolverStrategyRegistry[new_class.__name__] = new_class  # type: ignore\n        return new_class\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver","title":"ddot_v0_solver","text":""},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSEnvironment","title":"DDOTSEnvironment","text":"<p>               Bases: <code>Environment</code></p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>class DDOTSEnvironment(Environment):\n    def __init__(self, agents: List[Agent], problem_id: str, description: str, client):  # noqa: D107\n        self.tdir = TemporaryDirectory()\n        self.hub_client = get_hub_client()\n        thread = self.hub_client.beta.threads.create()\n        super().__init__(\n            self.tdir.name,\n            agents,\n            client,\n            self.hub_client,\n            thread.id,\n            \"todo\",\n            approvals={\"confirm_execution\": lambda _: False},\n        )\n\n        self.problem_id = problem_id\n        self.solved = False\n\n        files = {\n            \".id\": problem_id,\n            \"PROBLEM.txt\": description,\n            \"solution.py\": \"\",\n            \"test.in\": \"\",\n            \"test.sh\": \"#!/bin/bash\\npython3 solution.py &lt; test.in\",\n        }\n        for fname, content in files.items():\n            with open(self.tdir.name + \"/\" + fname, \"w\") as f:\n                f.write(content)\n\n    async def async_submit(self, code: str) -&gt; Tuple[bool, str]:  # noqa: D102\n        submission_id = await submit_problem(self.problem_id, code, Extensions.PYTHON)\n\n        try:\n            await is_output_ready(submission_id)\n        except Exception:\n            print(\"WARNING: Submission took too long to execute on DDOTS\")\n            self.mark_done()\n            return False, \"Submission took too long to execute on the platform\"\n\n        ok = await submission_accepted(submission_id)\n\n        if ok:\n            self.solved = True\n            self.mark_done()\n            return True, \"\"\n\n        output = await get_output(submission_id)\n\n        return False, output\n\n    def submit_python(self, code: str) -&gt; Tuple[bool, str]:\n        \"\"\"Returns True if the submission was accepted, False otherwise.\n\n        The second element of the tuple is the output of the checker if the submission was rejected.\n        \"\"\"\n        return asyncio.run(self.async_submit(code))\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSEnvironment.submit_python","title":"submit_python","text":"<pre><code>submit_python(code: str) -&gt; Tuple[bool, str]\n</code></pre> <p>Returns True if the submission was accepted, False otherwise.</p> <p>The second element of the tuple is the output of the checker if the submission was rejected.</p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>def submit_python(self, code: str) -&gt; Tuple[bool, str]:\n    \"\"\"Returns True if the submission was accepted, False otherwise.\n\n    The second element of the tuple is the output of the checker if the submission was rejected.\n    \"\"\"\n    return asyncio.run(self.async_submit(code))\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSV0Solver","title":"DDOTSV0Solver","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for competitive programming problems live on DDOTS.</p> <p>This dataset will run agents in an Agent environment previously prepared.</p> <p>workspace/     .id             -- Id of the problem     PROBLEM.txt     -- Description of the problem</p> <p>The agent should call env.submit_python(code) to submit the code to the DDOTS server.</p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>class DDOTSV0Solver(SolverStrategy):\n    \"\"\"Solver strategy for competitive programming problems live on DDOTS.\n\n    This dataset will run agents in an Agent environment previously prepared.\n\n    workspace/\n        .id             -- Id of the problem\n        PROBLEM.txt     -- Description of the problem\n\n    The agent should call env.submit_python(code) to submit the code to the DDOTS server.\n\n    \"\"\"\n\n    def __init__(self, dataset_ref: Dataset, agents: str, max_iterations: int, save_snapshots: bool = False):  # noqa: D107\n        client_config = ClientConfig(\n            base_url=CONFIG.nearai_hub.base_url,\n            auth=CONFIG.auth,\n        )\n        self.agents = [Agent.load_agent(agent, client_config) for agent in agents.split(\",\")]\n        self.max_iterations = max_iterations\n\n        date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n        rnd_id = random.randint(10**8, 10**9 - 1)\n        self._saved_trajectories = DATA_FOLDER / \"data\" / \"ddots_v0_trajectories\" / f\"{date}_{rnd_id}\"\n        self._saved_trajectories.mkdir(parents=True, exist_ok=True)\n\n        self.save_snapshots = save_snapshots\n        print(\"Saving trajectories to\", self._saved_trajectories)\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"ddots\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"ddots_codeforces_small/v0\", \"datasets/ddots_codeforces_medium_A_B/v0\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        problem_id = datum[\"problem_id\"]\n        description = datum[\"description\"]\n\n        client_config = ClientConfig(\n            base_url=CONFIG.nearai_hub.base_url,\n            auth=CONFIG.auth,\n        )\n        client = InferenceClient(client_config)\n        env = DDOTSEnvironment(self.agents, problem_id, description, client)\n        env.write_file(\".solved\", str(False))\n\n        try:\n            env.run(description, max_iterations=self.max_iterations)\n            env.write_file(\".solved\", str(env.solved))\n\n        except Exception as e:\n            print(f\"Error running task: {e}\")\n\n        finally:\n            if self.save_snapshots:\n                snapshot = env.create_snapshot()\n                with open(self._saved_trajectories / f\"{problem_id}.tar.gz\", \"wb\") as f:\n                    f.write(snapshot)\n\n        return env.solved\n</code></pre>"},{"location":"api/#nearai.solvers.gsm8k_solver","title":"gsm8k_solver","text":""},{"location":"api/#nearai.solvers.gsm8k_solver.GSM8KSolverStrategy","title":"GSM8KSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the GSM8K dataset.</p> Source code in <code>nearai/solvers/gsm8k_solver.py</code> <pre><code>class GSM8KSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the GSM8K dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str = \"\", agent: str = \"\") -&gt; None:  # noqa: D107\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"gsm8k\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"gsm8k\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        parsed_datum: GSM8KDatum = GSM8KDatum(**datum)\n\n        problem_shots_indices = list(range(0, self.SHOTS))\n        problem_shots = list(\n            map(\n                lambda i: GSM8KDatum(**self.dataset_ref[\"train\"][i]).model_dump(),\n                problem_shots_indices,\n            )\n        )\n\n        session = self.start_inference_session(\"\")\n        session.add_system_message(\n            dedent(\n                \"\"\"\n                    You are a helpful assistant. You're goal is to answer word based math questions.\n                    \"\"\"\n                + \"\\n\\n\"\n                + \"Here are some examples of math questions and their answers:\"\n                + \"\\n\\n\".join([f\"Question: {shot['question']}\\nAnswer: {shot['answer']}\" for shot in problem_shots])\n                + \"\\n\\n\"\n                + \"Now, answer the next question provided in the user prompt. \"\n                + \"Think step by step about how to solve the problem. \"\n                + \"Then, provide the answer.\"\n            )\n        )\n        res_output = session.run_task(parsed_datum.question).strip()\n\n        ## cleanup the output\n        session = self.start_inference_session(\"\")\n        res_refined_output = session.run_task(\n            dedent(\n                f\"\"\"\n                    You are a helpful assistant. You're goal is to answer math questions.\n\n                    You have just answered a math question with the following response:\n\n                    --- BEGIN RESPONSE ---\n                    {res_output}\n                    --- END RESPONSE ---\n\n                    Please refine your answer.\n\n                    Only output the final number *without units* as your answer. Nothing else.\n                    \"\"\"\n            )\n        ).strip()\n        res_refined_output = res_refined_output.replace(\"$\", \"\").replace(\",\", \"\")\n        if \" \" in res_refined_output:\n            res_refined_output = res_refined_output.split(\" \")[0]\n        try:\n            res_refined_output = str(int(res_refined_output))\n        except Exception:\n            pass\n        try:\n            res_refined_output = str(int(float(res_refined_output)))\n        except Exception:\n            pass\n\n        refined_answer = parsed_datum.answer.replace(\"$\", \"\").replace(\",\", \"\")\n        print(res_refined_output, refined_answer)\n        return res_refined_output == refined_answer\n</code></pre>"},{"location":"api/#nearai.solvers.hellaswag_solver","title":"hellaswag_solver","text":""},{"location":"api/#nearai.solvers.hellaswag_solver.HellaswagSolverStrategy","title":"HellaswagSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/hellaswag_solver.py</code> <pre><code>class HellaswagSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], model: str = \"\", agent: str = \"\", shots: int = 8\n    ) -&gt; None:\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n        self.shots = shots\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return f\"hellaswag_{self.shots}shots\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"hellaswag\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = HellaswagDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.shots, 5))\n        example_problems = list(\n            map(\n                lambda d: HellaswagDatum(**d).model_dump(),\n                [self.dataset_ref[\"validation\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_verbose_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n        response = self.start_inference_session(\"\").run_task(base_prompt)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_extract_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        response = self.start_inference_session(\"\").run_task(extract_answer_prompt)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == int(datum[\"label\"]))\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.lean_solver","title":"lean_solver","text":""},{"location":"api/#nearai.solvers.lean_solver.LeanSolverStrategy","title":"LeanSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy to evaluate against Lean problems.</p> Source code in <code>nearai/solvers/lean_solver.py</code> <pre><code>class LeanSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy to evaluate against Lean problems.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], model: str = \"\", agent: str = \"\"\n    ) -&gt; None:\n        super().__init__(model, agent)\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        assert self.dataset_evaluation_name\n        return self.dataset_evaluation_name\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"lean\"]\n\n    def solve(self, datum: dict) -&gt; Tuple[bool, dict]:  # noqa: D102\n        lean_datum = LeanDatum.model_validate(datum)\n        lean_datum.url = load_repository(lean_datum.url)\n\n        info: dict = {}\n        info[\"verbose\"] = {}\n\n        lean_task = LeanTaskInfo(\n            lean_datum.url,\n            lean_datum.commit,\n            lean_datum.filename,\n            lean_datum.theorem,\n            load_theorem(lean_datum),\n        )\n        info[\"verbose\"][\"theorem_raw\"] = lean_task.theorem_raw\n\n        base_prompt = Template(open(PROMPTS_FOLDER / \"lean_answer.j2\").read(), trim_blocks=True).render(\n            url=lean_task.url,\n            commit=lean_task.commit,\n            filepath=lean_task.filename,\n            theorem_name=lean_task.theorem,\n            theorem_raw=lean_task.theorem_raw,\n            begin_marker=BEGIN_MARKER,\n            end_marker=END_MARKER,\n        )\n        response = self.start_inference_session(\"\").run_task(base_prompt)\n\n        json_response = extract_between_markers(response)\n        if not json_response:\n            info[\"error\"] = \"Failed to extract between markers.\"\n            info[\"verbose\"][\"response\"] = response\n            return False, info\n\n        tactics = parse_tactics(json_response)\n        if not tactics:\n            info[\"error\"] = \"Failed to parse tactics.\"\n            info[\"verbose\"][\"response\"] = json_response\n            return False, info\n\n        # Sometimes, there are timeout errors.\n        num_attempts = 3\n        info[\"tactics\"] = tactics\n        for i in range(0, num_attempts):\n            if i != 0:\n                info[\"check_solution_attempts\"] = f\"{i + 1} (max: {num_attempts})\"\n            try:\n                r, m = check_solution(lean_datum, tactics)\n                if r:\n                    info[\"verbose\"][\"check_solution_message\"] = m\n                else:\n                    info[\"check_solution_message\"] = m\n                return r, info\n            except Exception as e:\n                if i == num_attempts - 1:\n                    error_message = f\"Exception while checking solution: {str(e)}.\"\n                    print(error_message)\n                    info[\"error\"] = error_message\n        return False, info\n</code></pre>"},{"location":"api/#nearai.solvers.lean_solver.load_theorem","title":"load_theorem","text":"<pre><code>load_theorem(task: LeanDatum) -&gt; str\n</code></pre> <p>Use local copy of the repository.</p> Source code in <code>nearai/solvers/lean_solver.py</code> <pre><code>def load_theorem(task: LeanDatum) -&gt; str:\n    \"\"\"Use local copy of the repository.\"\"\"\n    repo = LeanGitRepo(task.url, task.commit)\n    theorem = Theorem(repo, task.filename, task.theorem)\n    with Dojo(theorem) as (_, state):\n        return state.pp\n</code></pre>"},{"location":"api/#nearai.solvers.livebench_solver","title":"livebench_solver","text":""},{"location":"api/#nearai.solvers.livebench_solver.LiveBenchSolverStrategy","title":"LiveBenchSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the live bench dataset.</p> Source code in <code>nearai/solvers/livebench_solver.py</code> <pre><code>class LiveBenchSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the live bench dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: str, model: str = \"\", agent: str = \"\", step: str = \"all\"\n    ) -&gt; None:\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n        self.step = step\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"live_bench\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"live_bench\"]\n\n    def get_custom_tasks(self) -&gt; List[dict]:  # noqa: D102\n        return [{\"summary\": \"all\"}]\n\n    @property\n    def evaluated_entry_name(self) -&gt; str:  # noqa: D102\n        name = \"\"\n        if self.agent:\n            name = self.agent_name()\n            if self.model_name != \"\":\n                name += f\"_with_model_{self.model_name}\"\n        else:\n            name = self.model_name\n        clean_name = re.sub(r\"[^a-zA-Z0-9_\\-.]\", \"_\", name)\n        return clean_name.lower()\n\n    @SolverStrategyClassProperty\n    def scoring_method(self) -&gt; SolverScoringMethod:  # noqa: D102\n        return SolverScoringMethod.Custom\n\n    def solve(self, _datum: dict) -&gt; Tuple[bool, dict]:  # noqa: D102\n        if self.step == \"gen_model_answer\":\n            self.gen_model_answer()\n            return True, {}\n        if self.step == \"gen_ground_truth_judgement\":\n            return self.gen_ground_truth_judgement(), {}\n        if self.step == \"show_livebench_results\":\n            return self.show_livebench_results()\n        if self.step == \"all\":\n            self.gen_model_answer()\n            if not self.gen_ground_truth_judgement():\n                return False, {}\n            return self.show_livebench_results()\n        return False, {}\n\n    def gen_model_answer(self) -&gt; None:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step gen_model_answer -----------\")\n        print(\"\")\n        list_of_question_files = glob.glob(f\"{self.dataset_ref}/**/question.jsonl\", recursive=True)\n        for question_file in list_of_question_files:\n            questions = load_questions_jsonl(question_file)\n            bench_name = os.path.dirname(question_file).split(str(self.dataset_ref))[-1]\n            answer_file = _get_answer_file_path(bench_name, self.evaluated_entry_name)\n            print(f\"Questions from {question_file}\")\n            print(f\"Output to {answer_file}\")\n            self.run_eval(questions, answer_file)\n\n    def run_eval(self, questions, answer_file) -&gt; None:  # noqa: D102\n        answer_file = os.path.expanduser(answer_file)\n\n        # Load existing answers\n        existing_answers = set()\n        if os.path.exists(answer_file):\n            print(\n                f\"Answer file {answer_file} exists. Will skip already answered questions. Delete this file if that is not intended.\"  # noqa: E501\n            )\n            with open(answer_file, \"r\") as fin:\n                for line in fin:\n                    answer = json.loads(line)\n                    existing_answers.add(answer[\"question_id\"])\n\n        for question in tqdm(questions):\n            if question[\"question_id\"] in existing_answers:\n                continue\n            choices = self.answer_question(question)\n\n            ans_json = {\n                \"question_id\": question[\"question_id\"],\n                \"answer_id\": shortuuid.uuid(),\n                \"model_id\": self.evaluated_entry_name,\n                \"choices\": choices,\n                \"tstamp\": time.time(),\n            }\n\n            os.makedirs(os.path.dirname(answer_file), exist_ok=True)\n            with open(answer_file, \"a\") as fout:\n                fout.write(json.dumps(ans_json) + \"\\n\")\n\n    def answer_question(self, question) -&gt; List[dict]:  # noqa: D102\n        turns = []\n        session = self.start_inference_session(question[\"question_id\"])\n        for qs in question[\"turns\"]:\n            output = session.run_task(qs)\n            turns.append(output)\n\n        return [{\"index\": 0, \"turns\": turns}]\n\n    def gen_ground_truth_judgement(self) -&gt; bool:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step gen_ground_truth_judgement -----------\")\n        print(\"\")\n        script_path = \"nearai/projects/live_bench/gen_ground_truth_judgement.sh\"\n\n        try:\n            # Run the script without capturing output\n            subprocess.run([\"/bin/bash\", script_path, self.evaluated_entry_name, self.dataset_ref], check=True)\n            return True\n\n        except subprocess.CalledProcessError as e:\n            print(f\"An error occurred while running the script: {e}\")\n            return False\n\n    def show_livebench_results(self) -&gt; Tuple[bool, dict]:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step show_livebench_results -----------\")\n        print(\"\")\n        script_path = \"nearai/projects/live_bench/show_livebench_results.sh\"\n\n        try:\n            # Run the script without capturing output\n            subprocess.run([\"/bin/bash\", script_path, self.evaluated_entry_name], check=True)\n\n        except subprocess.CalledProcessError as e:\n            print(f\"An error occurred while running the script: {e}\")\n            return False, {}\n\n        return self.create_result_dict()\n\n    def read_csv_to_dict(self, file_path) -&gt; dict:  # noqa: D102\n        file_path = os.path.expanduser(file_path)\n        with open(file_path, \"r\") as f:\n            reader = csv.DictReader(f)\n            matching_rows = [row for row in reader if row[\"model\"] == self.evaluated_entry_name]\n            return matching_rows[-1] if matching_rows else {}  # Get the last matching row\n\n    def create_result_dict(self) -&gt; Tuple[bool, dict]:  # noqa: D102\n        tasks_data = self.read_csv_to_dict(_get_all_tasks_csv_file())\n        groups_data = self.read_csv_to_dict(_get_all_groups_csv_file())\n\n        if not tasks_data or not groups_data:\n            return False, {}  # Return None if the model is not found in either file\n\n        result: dict = {\"tasks\": {}, \"groups\": {}}\n\n        for key, value in tasks_data.items():\n            if key != \"model\":\n                result[\"tasks\"][key] = float(value)\n\n        for key, value in groups_data.items():\n            if key != \"model\":\n                result[\"groups\"][key] = float(value)\n\n        return True, result\n\n    def get_evaluation_metrics(self, tasks_results: List[Tuple[bool, Any]]) -&gt; Dict[str, Any]:  # noqa: D102\n        results: Dict[str, Dict[str, Any]] = tasks_results[-1][1]\n        if len(results) == 0:\n            raise ValueError(\"Cache empty. Rerun the job with --force. Use --step arg to specify a step.\")\n        metrics: Dict[str, Any] = {\"average\": results[\"groups\"][\"average\"]}\n\n        for group, score in results[\"groups\"].items():\n            if group == \"average\":\n                continue\n            metrics[f\"group/{group}\"] = score\n\n        for task, score in results[\"tasks\"].items():\n            metrics[f\"task/{task}\"] = score\n\n        return metrics\n</code></pre>"},{"location":"api/#nearai.solvers.mbpp_solver","title":"mbpp_solver","text":""},{"location":"api/#nearai.solvers.mbpp_solver.MBPPSolverStrategy","title":"MBPPSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MBPP dataset.</p> Source code in <code>nearai/solvers/mbpp_solver.py</code> <pre><code>class MBPPSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MBPP dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], model: str = \"\", agent: str = \"\", shots: int = 3\n    ) -&gt; None:\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n        self.shots = shots\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        prefix = self.dataset_evaluation_name if self.dataset_evaluation_name else \"mbpp\"\n        return f\"{prefix}_{self.shots}shots\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mbpp\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MBPPDatum(**datum).model_dump()\n\n        ## Allow LLM to think \"out loud\" for it's answer\n        function_name = get_function_name(datum[\"code\"])\n        example_problems = list(islice(self.dataset_ref[\"prompt\"], self.shots))\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mbpp_verbose_answer.j2\").read(), trim_blocks=True).render(\n            function_name=function_name,\n            example_problems=example_problems,\n            challenge_problem=datum,\n        )\n        response = self.start_inference_session(str(datum[\"task_id\"])).run_task(base_prompt)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mbpp_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            function_name=function_name,\n            answer_text=response,\n        )\n        response = self.start_inference_session(str(datum[\"task_id\"])).run_task(extract_answer_prompt)\n\n        ## Parse the python code\n        python_code_blocks = parse_python_code_block(response) + parse_code_block(response)\n        code = \"\"\n        if len(python_code_blocks) == 0:\n            code = response\n        else:\n            code = python_code_blocks[0]\n\n        ## Evaluate the code\n        try:\n            for test in datum[\"test_list\"] + datum[\"challenge_test_list\"]:\n                test_code = code + \"\\n\" + test\n                if not run_with_timeout(test_code):\n                    return False\n            return True\n        except Exception:\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.mmlu_solver","title":"mmlu_solver","text":""},{"location":"api/#nearai.solvers.mmlu_solver.MMLUSolverStrategy","title":"MMLUSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/mmlu_solver.py</code> <pre><code>class MMLUSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], model: str = \"\", agent: str = \"\", shots: int = 8\n    ) -&gt; None:\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n        self.shots = shots\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        prefix = self.dataset_evaluation_name if self.dataset_evaluation_name else \"mmlu\"\n        return f\"{prefix}_{self.shots}shots\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mmlu\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MMLUDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.shots, 5))\n        example_problems = list(\n            map(\n                lambda d: MMLUDatum(**d).model_dump(),\n                [self.dataset_ref[\"dev\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mmlu_verbose_answer.j2\").read(), trim_blocks=True).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n\n        response = self.start_inference_session(\"\").run_task(base_prompt)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mmlu_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        response = self.start_inference_session(\"\").run_task(extract_answer_prompt)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == datum[\"answer\"])\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.tests","title":"tests","text":""},{"location":"api/#nearai.tests.test_provider_models","title":"test_provider_models","text":""},{"location":"api/#nearai.tests.test_provider_models.TestMatchProviderModel","title":"TestMatchProviderModel","text":"<p>               Bases: <code>TestCase</code></p> <p>Unit tests for get_provider_namespaced_model.</p> Source code in <code>nearai/tests/test_provider_models.py</code> <pre><code>class TestMatchProviderModel(unittest.TestCase):\n    \"\"\"Unit tests for get_provider_namespaced_model.\"\"\"\n\n    def __init__(self, method_name=\"runTest\"):  # noqa: D107\n        super().__init__(method_name)\n        self.provider_models = ProviderModels(CONFIG.get_client_config())\n\n    def test_fireworks(self):  # noqa: D102\n        self.assertEqual(\n            self.provider_models.match_provider_model(\"fireworks::accounts/yi-01-ai/models/yi-large\"),\n            (\"fireworks\", \"fireworks::accounts/yi-01-ai/models/yi-large\"),\n        )\n        self.assertEqual(\n            self.provider_models.match_provider_model(\"accounts/yi-01-ai/models/yi-large\"),\n            (\"fireworks\", \"fireworks::accounts/yi-01-ai/models/yi-large\"),\n        )\n        self.assertEqual(\n            self.provider_models.match_provider_model(\"llama-v3-70b-instruct\"),\n            (\"fireworks\", \"fireworks::accounts/fireworks/models/llama-v3-70b-instruct\"),\n        )\n        self.assertEqual(\n            self.provider_models.match_provider_model(\"yi-01-ai/yi-large\"),\n            (\"fireworks\", \"fireworks::accounts/yi-01-ai/models/yi-large\"),\n        )\n\n    def test_hyperbolic(self):  # noqa: D102\n        self.assertEqual(\n            self.provider_models.match_provider_model(\"hyperbolic::StableDiffusion\"),\n            (\"hyperbolic\", \"hyperbolic::StableDiffusion\"),\n        )\n        self.assertEqual(\n            self.provider_models.match_provider_model(\"hyperbolic::meta-llama/Meta-Llama-3.1-70B-Instruct\"),\n            (\"hyperbolic\", \"hyperbolic::meta-llama/Meta-Llama-3.1-70B-Instruct\"),\n        )\n        self.assertEqual(\n            self.provider_models.match_provider_model(\"hyperbolic::Meta-Llama-3.1-70B-Instruct\"),\n            (\"hyperbolic\", \"hyperbolic::meta-llama/Meta-Llama-3.1-70B-Instruct\"),\n        )\n\n    def test_registry_with_multiple_providers(self):  # noqa: D102\n        self.assertEqual(\n            self.provider_models.match_provider_model(\"llama-3.1-70b-instruct\"),\n            (\"fireworks\", \"fireworks::accounts/fireworks/models/llama-v3p1-70b-instruct\"),\n        )\n        self.assertEqual(\n            self.provider_models.match_provider_model(\"llama-3.1-70b-instruct\", provider=\"hyperbolic\"),\n            (\"hyperbolic\", \"hyperbolic::meta-llama/Meta-Llama-3.1-70B-Instruct\"),\n        )\n        self.assertEqual(\n            self.provider_models.match_provider_model(\"near.ai/llama-3.1-70b-instruct\", provider=\"hyperbolic\"),\n            (\"hyperbolic\", \"hyperbolic::meta-llama/Meta-Llama-3.1-70B-Instruct\"),\n        )\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli","title":"test_registry_cli","text":""},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload","title":"TestRegistryCliUpload","text":"<p>Tests for the RegistryCli.upload method.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>class TestRegistryCliUpload:\n    \"\"\"Tests for the RegistryCli.upload method.\"\"\"\n\n    def test_successful_upload(self, mock_registry, mock_config, tmp_path):\n        \"\"\"Test successful upload when version doesn't exist.\"\"\"\n        # Mock the helper functions\n        with (\n            patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n            patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n        ):\n            # Setup mocks\n            mock_load_metadata.return_value = ({\"name\": \"test-agent\", \"version\": \"0.0.1\"}, None)\n            mock_check_version.return_value = (False, None)\n            mock_registry.upload.return_value = EntryLocation(namespace=\"user\", name=\"test-agent\", version=\"0.0.1\")\n\n            # Call the method\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path))\n\n            # Assertions\n            assert result is not None\n            assert result.namespace == \"user\"\n            assert result.name == \"test-agent\"\n            assert result.version == \"0.0.1\"\n            mock_registry.upload.assert_called_once()\n\n    def test_version_already_exists(self, mock_registry, mock_config, tmp_path, capsys):\n        \"\"\"Test upload failure when version already exists.\"\"\"\n        # Mock the helper functions\n        with (\n            patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n            patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n        ):\n            # Setup mocks\n            mock_load_metadata.return_value = ({\"name\": \"test-agent\", \"version\": \"0.0.1\"}, None)\n            mock_check_version.return_value = (True, None)\n\n            # Call the method\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path))\n\n            # Assertions\n            assert result is None\n            captured = capsys.readouterr()\n            # Check for the new Rich-formatted output\n            assert \"Version 0.0.1 already exists\" in captured.out\n            assert \"Version Conflict\" in captured.out\n            assert \"To upload a new version\" in captured.out\n            assert \"--bump\" in captured.out\n            assert \"--minor-bump\" in captured.out\n            assert \"--major-bump\" in captured.out\n            mock_registry.upload.assert_not_called()\n\n    def test_metadata_file_not_found(self, mock_registry, mock_config, tmp_path, capsys):\n        \"\"\"Test upload failure when metadata.json is missing.\"\"\"\n        # Mock the helper function\n        with patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata:\n            # Setup mock\n            mock_load_metadata.return_value = (None, \"Error: metadata.json not found\")\n\n            # Call the method\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path))\n\n            # Assertions\n            assert result is None\n            captured = capsys.readouterr()\n            assert \"Error: metadata.json not found\" in captured.out\n            mock_registry.upload.assert_not_called()\n\n    def test_invalid_json_metadata(self, mock_registry, mock_config, tmp_path, capsys):\n        \"\"\"Test upload failure when metadata.json is not valid JSON.\"\"\"\n        # Mock the helper function\n        with patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata:\n            # Setup mock\n            mock_load_metadata.return_value = (None, \"Error: metadata.json is not a valid JSON file\")\n\n            # Call the method\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path))\n\n            # Assertions\n            assert result is None\n            captured = capsys.readouterr()\n            assert \"Error: metadata.json is not a valid JSON file\" in captured.out\n            mock_registry.upload.assert_not_called()\n\n    def test_missing_required_fields(self, mock_registry, mock_config, tmp_path, capsys):\n        \"\"\"Test upload failure when required fields are missing in metadata.json.\"\"\"\n        # Mock the helper function\n        with patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata:\n            # Setup mock\n            mock_load_metadata.return_value = (None, \"Error: metadata.json must contain 'name' and 'version' fields\")\n\n            # Call the method\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path))\n\n            # Assertions\n            assert result is None\n            captured = capsys.readouterr()\n            assert \"Error: metadata.json must contain 'name' and 'version' fields\" in captured.out\n            mock_registry.upload.assert_not_called()\n\n    def test_not_logged_in(self, mock_registry, mock_config, tmp_path, capsys):\n        \"\"\"Test upload failure when user is not logged in.\"\"\"\n        # Mock the helper function\n        with patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata:\n            # Setup mock\n            mock_load_metadata.return_value = (None, \"Please login with `nearai login` before uploading\")\n\n            # Call the method\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path))\n\n            # Assertions\n            assert result is None\n            captured = capsys.readouterr()\n            assert \"Please login with `nearai login` before uploading\" in captured.out\n            mock_registry.upload.assert_not_called()\n\n    def test_other_registry_error(self, mock_registry, mock_config, tmp_path, capsys):\n        \"\"\"Test upload failure when an unexpected error occurs during registry info check.\"\"\"\n        # Mock the helper functions\n        with (\n            patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n            patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n        ):\n            # Setup mocks\n            mock_load_metadata.return_value = ({\"name\": \"test-agent\", \"version\": \"0.0.1\"}, None)\n            mock_check_version.return_value = (False, \"Error checking registry: Connection failed\")\n\n            # Call the method\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path))\n\n            # Assertions\n            assert result is None\n            captured = capsys.readouterr()\n            assert \"Error checking registry: Connection failed\" in captured.out\n            mock_registry.upload.assert_not_called()\n\n    def test_auto_bump_version(self, mock_registry, mock_config, tmp_path, capsys):\n        \"\"\"Test auto-increment feature when version already exists.\"\"\"\n        # Create a real metadata.json for this test\n        metadata = {\"name\": \"test-agent\", \"version\": \"0.0.1\"}\n        metadata_path = tmp_path / \"metadata.json\"\n        with open(metadata_path, \"w\") as f:\n            json.dump(metadata, f)\n\n        # Mock the helper functions\n        with (\n            patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n            patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n            patch(\"nearai.cli.increment_version_by_type\") as mock_increment,\n        ):\n            # Setup mocks for first check (version exists) and second check (new version doesn't exist)\n            mock_load_metadata.return_value = (metadata, None)\n            mock_check_version.side_effect = [(True, None), (False, None)]\n            mock_increment.return_value = \"0.0.2\"\n            mock_registry.upload.return_value = EntryLocation(namespace=\"user\", name=\"test-agent\", version=\"0.0.2\")\n\n            # Call the method with bump=True\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path), bump=True)\n\n            # Assertions\n            assert result is not None\n            assert result.version == \"0.0.2\"\n            mock_increment.assert_called_once_with(\"0.0.1\", \"patch\")\n            mock_registry.upload.assert_called_once()\n\n            # Check that metadata.json was updated\n            with open(metadata_path, \"r\") as f:\n                updated_metadata = json.load(f)\n                assert updated_metadata[\"version\"] == \"0.0.2\"\n\n            # Check console output for the new Rich-formatted panel\n            captured = capsys.readouterr()\n            assert \"Bump\" in captured.out\n            assert \"Previous version: 0.0.1\" in captured.out\n            assert \"New version:\" in captured.out\n            assert \"0.0.2\" in captured.out\n            assert \"Increment type: patch\" in captured.out\n\n    def test_minor_bump_version(self, mock_registry, mock_config, tmp_path, capsys):\n        \"\"\"Test minor bump feature when version already exists.\"\"\"\n        # Create a real metadata.json for this test\n        metadata = {\"name\": \"test-agent\", \"version\": \"0.0.1\"}\n        metadata_path = tmp_path / \"metadata.json\"\n        with open(metadata_path, \"w\") as f:\n            json.dump(metadata, f)\n\n        # Mock the helper functions\n        with (\n            patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n            patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n            patch(\"nearai.cli.increment_version_by_type\") as mock_increment,\n        ):\n            # Setup mocks for first check (version exists) and second check (new version doesn't exist)\n            mock_load_metadata.return_value = (metadata, None)\n            mock_check_version.side_effect = [(True, None), (False, None)]\n            mock_increment.return_value = \"0.1.0\"\n            mock_registry.upload.return_value = EntryLocation(namespace=\"user\", name=\"test-agent\", version=\"0.1.0\")\n\n            # Call the method with minor_bump=True\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path), minor_bump=True)\n\n            # Assertions\n            assert result is not None\n            assert result.version == \"0.1.0\"\n            mock_increment.assert_called_once_with(\"0.0.1\", \"minor\")\n            mock_registry.upload.assert_called_once()\n\n            # Check that metadata.json was updated\n            with open(metadata_path, \"r\") as f:\n                updated_metadata = json.load(f)\n                assert updated_metadata[\"version\"] == \"0.1.0\"\n\n            # Check console output for the new Rich-formatted panel\n            captured = capsys.readouterr()\n            assert \"Bump\" in captured.out\n            assert \"Previous version: 0.0.1\" in captured.out\n            assert \"New version:\" in captured.out\n            assert \"0.1.0\" in captured.out\n            assert \"Increment type: minor\" in captured.out\n\n    def test_major_bump_version(self, mock_registry, mock_config, tmp_path, capsys):\n        \"\"\"Test major bump feature when version already exists.\"\"\"\n        # Create a real metadata.json for this test\n        metadata = {\"name\": \"test-agent\", \"version\": \"0.0.1\"}\n        metadata_path = tmp_path / \"metadata.json\"\n        with open(metadata_path, \"w\") as f:\n            json.dump(metadata, f)\n\n        # Mock the helper functions\n        with (\n            patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n            patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n            patch(\"nearai.cli.increment_version_by_type\") as mock_increment,\n        ):\n            # Setup mocks for first check (version exists) and second check (new version doesn't exist)\n            mock_load_metadata.return_value = (metadata, None)\n            mock_check_version.side_effect = [(True, None), (False, None)]\n            mock_increment.return_value = \"1.0.0\"\n            mock_registry.upload.return_value = EntryLocation(namespace=\"user\", name=\"test-agent\", version=\"1.0.0\")\n\n            # Call the method with major_bump=True\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path), major_bump=True)\n\n            # Assertions\n            assert result is not None\n            assert result.version == \"1.0.0\"\n            mock_increment.assert_called_once_with(\"0.0.1\", \"major\")\n            mock_registry.upload.assert_called_once()\n\n            # Check that metadata.json was updated\n            with open(metadata_path, \"r\") as f:\n                updated_metadata = json.load(f)\n                assert updated_metadata[\"version\"] == \"1.0.0\"\n\n            # Check console output for the new Rich-formatted panel\n            captured = capsys.readouterr()\n            assert \"Bump\" in captured.out\n            assert \"Previous version: 0.0.1\" in captured.out\n            assert \"New version:\" in captured.out\n            assert \"1.0.0\" in captured.out\n            assert \"Increment type: major\" in captured.out\n\n    def test_pep440_version_validation(self, mock_registry, mock_config, tmp_path):\n        \"\"\"Test that version validation follows PEP 440 standards.\"\"\"\n        # Import the actual validation function\n        from packaging.version import InvalidVersion, Version\n\n        from nearai.cli_helpers import validate_version\n\n        # Test valid versions according to PEP 440\n        valid_versions = [\n            \"1.0.0\",\n            \"0.1.0\",\n            \"0.0.1\",  # Simple versions\n            \"1.0.0rc1\",\n            \"1.0.0a1\",\n            \"1.0.0b1\",  # Pre-releases\n            \"2.0.0.dev1\",  # Dev releases\n            \"1.0.0.post1\",  # Post releases\n            \"1!1.0.0\",  # With epoch\n            \"1.0.0+local.1\",  # Local version\n            \"1.0\",  # Implicit zero\n            \"1.0.0.0.0\",  # Many segments (valid in PEP 440)\n            \"01.02.03\",  # Leading zeros (valid in PEP 440)\n            \"1.0a\",\n            \"1.0.post\",\n            \"1.0.dev\",  # Optional numbers in pre/post/dev\n        ]\n\n        for version in valid_versions:\n            # Verify with packaging.version first\n            try:\n                Version(version)\n                is_valid_pep440 = True\n            except InvalidVersion:\n                is_valid_pep440 = False\n\n            assert is_valid_pep440, f\"Version {version} should be valid according to PEP 440\"\n\n            # Now test our validation function\n            is_valid, error_msg = validate_version(version)\n            assert is_valid, f\"Valid version {version} was rejected with error: {error_msg}\"\n\n        # Test invalid versions\n        invalid_versions = [\n            # Non-Numeric Versions\n            \"version1.0.0\",  # Arbitrary text is not allowed\n            \"hithere\",\n            \"12-212.23\",\n            \"1.0_final\",  # Underscore is not allowed in this context\n            \"1..0\",  # Empty segments are not allowed\n            \"1.0.\",  # Trailing dot is not allowed\n        ]\n\n        for version in invalid_versions:\n            # Verify with packaging.version first\n            try:\n                Version(version)\n                is_valid_pep440 = True\n            except InvalidVersion:\n                is_valid_pep440 = False\n\n            assert not is_valid_pep440, f\"Version {version} should be invalid according to PEP 440\"\n\n            # Now test our validation function\n            is_valid, error_msg = validate_version(version)\n            assert not is_valid, f\"Invalid version {version} was accepted\"\n            assert \"Invalid version format\" in error_msg or \"not a valid version\" in error_msg\n\n    def test_auto_increment_version(self, mock_registry, mock_config, tmp_path, capsys):\n        \"\"\"Test auto-increment feature when version already exists.\"\"\"\n        # Create a real metadata.json for this test\n        metadata = {\"name\": \"test-agent\", \"version\": \"0.0.1\"}\n        metadata_path = tmp_path / \"metadata.json\"\n        with open(metadata_path, \"w\") as f:\n            json.dump(metadata, f)\n\n        # Mock the helper functions\n        with (\n            patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n            patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n            patch(\"nearai.cli.increment_version_by_type\") as mock_increment,\n        ):\n            # Setup mocks for first check (version exists) and second check (new version doesn't exist)\n            mock_load_metadata.return_value = (metadata, None)\n            mock_check_version.side_effect = [(True, None), (False, None)]\n            mock_increment.return_value = \"0.0.2\"\n            mock_registry.upload.return_value = EntryLocation(namespace=\"user\", name=\"test-agent\", version=\"0.0.2\")\n\n            # Call the method with bump=True\n            cli = RegistryCli()\n            result = cli.upload(str(tmp_path), bump=True)\n\n            # Assertions\n            assert result is not None\n            assert result.version == \"0.0.2\"\n            mock_increment.assert_called_once_with(\"0.0.1\", \"patch\")\n            mock_registry.upload.assert_called_once()\n\n            # Check that metadata.json was updated\n            with open(metadata_path, \"r\") as f:\n                updated_metadata = json.load(f)\n                assert updated_metadata[\"version\"] == \"0.0.2\"\n\n            # Check console output for the new Rich-formatted panel\n            captured = capsys.readouterr()\n            assert \"Bump\" in captured.out\n            assert \"Previous version: 0.0.1\" in captured.out\n            assert \"New version:\" in captured.out\n            assert \"0.0.2\" in captured.out\n            assert \"Increment type: patch\" in captured.out\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_auto_bump_version","title":"test_auto_bump_version","text":"<pre><code>test_auto_bump_version(\n    mock_registry, mock_config, tmp_path, capsys\n)\n</code></pre> <p>Test auto-increment feature when version already exists.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_auto_bump_version(self, mock_registry, mock_config, tmp_path, capsys):\n    \"\"\"Test auto-increment feature when version already exists.\"\"\"\n    # Create a real metadata.json for this test\n    metadata = {\"name\": \"test-agent\", \"version\": \"0.0.1\"}\n    metadata_path = tmp_path / \"metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        json.dump(metadata, f)\n\n    # Mock the helper functions\n    with (\n        patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n        patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n        patch(\"nearai.cli.increment_version_by_type\") as mock_increment,\n    ):\n        # Setup mocks for first check (version exists) and second check (new version doesn't exist)\n        mock_load_metadata.return_value = (metadata, None)\n        mock_check_version.side_effect = [(True, None), (False, None)]\n        mock_increment.return_value = \"0.0.2\"\n        mock_registry.upload.return_value = EntryLocation(namespace=\"user\", name=\"test-agent\", version=\"0.0.2\")\n\n        # Call the method with bump=True\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path), bump=True)\n\n        # Assertions\n        assert result is not None\n        assert result.version == \"0.0.2\"\n        mock_increment.assert_called_once_with(\"0.0.1\", \"patch\")\n        mock_registry.upload.assert_called_once()\n\n        # Check that metadata.json was updated\n        with open(metadata_path, \"r\") as f:\n            updated_metadata = json.load(f)\n            assert updated_metadata[\"version\"] == \"0.0.2\"\n\n        # Check console output for the new Rich-formatted panel\n        captured = capsys.readouterr()\n        assert \"Bump\" in captured.out\n        assert \"Previous version: 0.0.1\" in captured.out\n        assert \"New version:\" in captured.out\n        assert \"0.0.2\" in captured.out\n        assert \"Increment type: patch\" in captured.out\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_auto_increment_version","title":"test_auto_increment_version","text":"<pre><code>test_auto_increment_version(\n    mock_registry, mock_config, tmp_path, capsys\n)\n</code></pre> <p>Test auto-increment feature when version already exists.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_auto_increment_version(self, mock_registry, mock_config, tmp_path, capsys):\n    \"\"\"Test auto-increment feature when version already exists.\"\"\"\n    # Create a real metadata.json for this test\n    metadata = {\"name\": \"test-agent\", \"version\": \"0.0.1\"}\n    metadata_path = tmp_path / \"metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        json.dump(metadata, f)\n\n    # Mock the helper functions\n    with (\n        patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n        patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n        patch(\"nearai.cli.increment_version_by_type\") as mock_increment,\n    ):\n        # Setup mocks for first check (version exists) and second check (new version doesn't exist)\n        mock_load_metadata.return_value = (metadata, None)\n        mock_check_version.side_effect = [(True, None), (False, None)]\n        mock_increment.return_value = \"0.0.2\"\n        mock_registry.upload.return_value = EntryLocation(namespace=\"user\", name=\"test-agent\", version=\"0.0.2\")\n\n        # Call the method with bump=True\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path), bump=True)\n\n        # Assertions\n        assert result is not None\n        assert result.version == \"0.0.2\"\n        mock_increment.assert_called_once_with(\"0.0.1\", \"patch\")\n        mock_registry.upload.assert_called_once()\n\n        # Check that metadata.json was updated\n        with open(metadata_path, \"r\") as f:\n            updated_metadata = json.load(f)\n            assert updated_metadata[\"version\"] == \"0.0.2\"\n\n        # Check console output for the new Rich-formatted panel\n        captured = capsys.readouterr()\n        assert \"Bump\" in captured.out\n        assert \"Previous version: 0.0.1\" in captured.out\n        assert \"New version:\" in captured.out\n        assert \"0.0.2\" in captured.out\n        assert \"Increment type: patch\" in captured.out\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_invalid_json_metadata","title":"test_invalid_json_metadata","text":"<pre><code>test_invalid_json_metadata(\n    mock_registry, mock_config, tmp_path, capsys\n)\n</code></pre> <p>Test upload failure when metadata.json is not valid JSON.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_invalid_json_metadata(self, mock_registry, mock_config, tmp_path, capsys):\n    \"\"\"Test upload failure when metadata.json is not valid JSON.\"\"\"\n    # Mock the helper function\n    with patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata:\n        # Setup mock\n        mock_load_metadata.return_value = (None, \"Error: metadata.json is not a valid JSON file\")\n\n        # Call the method\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path))\n\n        # Assertions\n        assert result is None\n        captured = capsys.readouterr()\n        assert \"Error: metadata.json is not a valid JSON file\" in captured.out\n        mock_registry.upload.assert_not_called()\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_major_bump_version","title":"test_major_bump_version","text":"<pre><code>test_major_bump_version(\n    mock_registry, mock_config, tmp_path, capsys\n)\n</code></pre> <p>Test major bump feature when version already exists.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_major_bump_version(self, mock_registry, mock_config, tmp_path, capsys):\n    \"\"\"Test major bump feature when version already exists.\"\"\"\n    # Create a real metadata.json for this test\n    metadata = {\"name\": \"test-agent\", \"version\": \"0.0.1\"}\n    metadata_path = tmp_path / \"metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        json.dump(metadata, f)\n\n    # Mock the helper functions\n    with (\n        patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n        patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n        patch(\"nearai.cli.increment_version_by_type\") as mock_increment,\n    ):\n        # Setup mocks for first check (version exists) and second check (new version doesn't exist)\n        mock_load_metadata.return_value = (metadata, None)\n        mock_check_version.side_effect = [(True, None), (False, None)]\n        mock_increment.return_value = \"1.0.0\"\n        mock_registry.upload.return_value = EntryLocation(namespace=\"user\", name=\"test-agent\", version=\"1.0.0\")\n\n        # Call the method with major_bump=True\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path), major_bump=True)\n\n        # Assertions\n        assert result is not None\n        assert result.version == \"1.0.0\"\n        mock_increment.assert_called_once_with(\"0.0.1\", \"major\")\n        mock_registry.upload.assert_called_once()\n\n        # Check that metadata.json was updated\n        with open(metadata_path, \"r\") as f:\n            updated_metadata = json.load(f)\n            assert updated_metadata[\"version\"] == \"1.0.0\"\n\n        # Check console output for the new Rich-formatted panel\n        captured = capsys.readouterr()\n        assert \"Bump\" in captured.out\n        assert \"Previous version: 0.0.1\" in captured.out\n        assert \"New version:\" in captured.out\n        assert \"1.0.0\" in captured.out\n        assert \"Increment type: major\" in captured.out\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_metadata_file_not_found","title":"test_metadata_file_not_found","text":"<pre><code>test_metadata_file_not_found(\n    mock_registry, mock_config, tmp_path, capsys\n)\n</code></pre> <p>Test upload failure when metadata.json is missing.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_metadata_file_not_found(self, mock_registry, mock_config, tmp_path, capsys):\n    \"\"\"Test upload failure when metadata.json is missing.\"\"\"\n    # Mock the helper function\n    with patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata:\n        # Setup mock\n        mock_load_metadata.return_value = (None, \"Error: metadata.json not found\")\n\n        # Call the method\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path))\n\n        # Assertions\n        assert result is None\n        captured = capsys.readouterr()\n        assert \"Error: metadata.json not found\" in captured.out\n        mock_registry.upload.assert_not_called()\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_minor_bump_version","title":"test_minor_bump_version","text":"<pre><code>test_minor_bump_version(\n    mock_registry, mock_config, tmp_path, capsys\n)\n</code></pre> <p>Test minor bump feature when version already exists.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_minor_bump_version(self, mock_registry, mock_config, tmp_path, capsys):\n    \"\"\"Test minor bump feature when version already exists.\"\"\"\n    # Create a real metadata.json for this test\n    metadata = {\"name\": \"test-agent\", \"version\": \"0.0.1\"}\n    metadata_path = tmp_path / \"metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        json.dump(metadata, f)\n\n    # Mock the helper functions\n    with (\n        patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n        patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n        patch(\"nearai.cli.increment_version_by_type\") as mock_increment,\n    ):\n        # Setup mocks for first check (version exists) and second check (new version doesn't exist)\n        mock_load_metadata.return_value = (metadata, None)\n        mock_check_version.side_effect = [(True, None), (False, None)]\n        mock_increment.return_value = \"0.1.0\"\n        mock_registry.upload.return_value = EntryLocation(namespace=\"user\", name=\"test-agent\", version=\"0.1.0\")\n\n        # Call the method with minor_bump=True\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path), minor_bump=True)\n\n        # Assertions\n        assert result is not None\n        assert result.version == \"0.1.0\"\n        mock_increment.assert_called_once_with(\"0.0.1\", \"minor\")\n        mock_registry.upload.assert_called_once()\n\n        # Check that metadata.json was updated\n        with open(metadata_path, \"r\") as f:\n            updated_metadata = json.load(f)\n            assert updated_metadata[\"version\"] == \"0.1.0\"\n\n        # Check console output for the new Rich-formatted panel\n        captured = capsys.readouterr()\n        assert \"Bump\" in captured.out\n        assert \"Previous version: 0.0.1\" in captured.out\n        assert \"New version:\" in captured.out\n        assert \"0.1.0\" in captured.out\n        assert \"Increment type: minor\" in captured.out\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_missing_required_fields","title":"test_missing_required_fields","text":"<pre><code>test_missing_required_fields(\n    mock_registry, mock_config, tmp_path, capsys\n)\n</code></pre> <p>Test upload failure when required fields are missing in metadata.json.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_missing_required_fields(self, mock_registry, mock_config, tmp_path, capsys):\n    \"\"\"Test upload failure when required fields are missing in metadata.json.\"\"\"\n    # Mock the helper function\n    with patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata:\n        # Setup mock\n        mock_load_metadata.return_value = (None, \"Error: metadata.json must contain 'name' and 'version' fields\")\n\n        # Call the method\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path))\n\n        # Assertions\n        assert result is None\n        captured = capsys.readouterr()\n        assert \"Error: metadata.json must contain 'name' and 'version' fields\" in captured.out\n        mock_registry.upload.assert_not_called()\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_not_logged_in","title":"test_not_logged_in","text":"<pre><code>test_not_logged_in(\n    mock_registry, mock_config, tmp_path, capsys\n)\n</code></pre> <p>Test upload failure when user is not logged in.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_not_logged_in(self, mock_registry, mock_config, tmp_path, capsys):\n    \"\"\"Test upload failure when user is not logged in.\"\"\"\n    # Mock the helper function\n    with patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata:\n        # Setup mock\n        mock_load_metadata.return_value = (None, \"Please login with `nearai login` before uploading\")\n\n        # Call the method\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path))\n\n        # Assertions\n        assert result is None\n        captured = capsys.readouterr()\n        assert \"Please login with `nearai login` before uploading\" in captured.out\n        mock_registry.upload.assert_not_called()\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_other_registry_error","title":"test_other_registry_error","text":"<pre><code>test_other_registry_error(\n    mock_registry, mock_config, tmp_path, capsys\n)\n</code></pre> <p>Test upload failure when an unexpected error occurs during registry info check.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_other_registry_error(self, mock_registry, mock_config, tmp_path, capsys):\n    \"\"\"Test upload failure when an unexpected error occurs during registry info check.\"\"\"\n    # Mock the helper functions\n    with (\n        patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n        patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n    ):\n        # Setup mocks\n        mock_load_metadata.return_value = ({\"name\": \"test-agent\", \"version\": \"0.0.1\"}, None)\n        mock_check_version.return_value = (False, \"Error checking registry: Connection failed\")\n\n        # Call the method\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path))\n\n        # Assertions\n        assert result is None\n        captured = capsys.readouterr()\n        assert \"Error checking registry: Connection failed\" in captured.out\n        mock_registry.upload.assert_not_called()\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_pep440_version_validation","title":"test_pep440_version_validation","text":"<pre><code>test_pep440_version_validation(\n    mock_registry, mock_config, tmp_path\n)\n</code></pre> <p>Test that version validation follows PEP 440 standards.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_pep440_version_validation(self, mock_registry, mock_config, tmp_path):\n    \"\"\"Test that version validation follows PEP 440 standards.\"\"\"\n    # Import the actual validation function\n    from packaging.version import InvalidVersion, Version\n\n    from nearai.cli_helpers import validate_version\n\n    # Test valid versions according to PEP 440\n    valid_versions = [\n        \"1.0.0\",\n        \"0.1.0\",\n        \"0.0.1\",  # Simple versions\n        \"1.0.0rc1\",\n        \"1.0.0a1\",\n        \"1.0.0b1\",  # Pre-releases\n        \"2.0.0.dev1\",  # Dev releases\n        \"1.0.0.post1\",  # Post releases\n        \"1!1.0.0\",  # With epoch\n        \"1.0.0+local.1\",  # Local version\n        \"1.0\",  # Implicit zero\n        \"1.0.0.0.0\",  # Many segments (valid in PEP 440)\n        \"01.02.03\",  # Leading zeros (valid in PEP 440)\n        \"1.0a\",\n        \"1.0.post\",\n        \"1.0.dev\",  # Optional numbers in pre/post/dev\n    ]\n\n    for version in valid_versions:\n        # Verify with packaging.version first\n        try:\n            Version(version)\n            is_valid_pep440 = True\n        except InvalidVersion:\n            is_valid_pep440 = False\n\n        assert is_valid_pep440, f\"Version {version} should be valid according to PEP 440\"\n\n        # Now test our validation function\n        is_valid, error_msg = validate_version(version)\n        assert is_valid, f\"Valid version {version} was rejected with error: {error_msg}\"\n\n    # Test invalid versions\n    invalid_versions = [\n        # Non-Numeric Versions\n        \"version1.0.0\",  # Arbitrary text is not allowed\n        \"hithere\",\n        \"12-212.23\",\n        \"1.0_final\",  # Underscore is not allowed in this context\n        \"1..0\",  # Empty segments are not allowed\n        \"1.0.\",  # Trailing dot is not allowed\n    ]\n\n    for version in invalid_versions:\n        # Verify with packaging.version first\n        try:\n            Version(version)\n            is_valid_pep440 = True\n        except InvalidVersion:\n            is_valid_pep440 = False\n\n        assert not is_valid_pep440, f\"Version {version} should be invalid according to PEP 440\"\n\n        # Now test our validation function\n        is_valid, error_msg = validate_version(version)\n        assert not is_valid, f\"Invalid version {version} was accepted\"\n        assert \"Invalid version format\" in error_msg or \"not a valid version\" in error_msg\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_successful_upload","title":"test_successful_upload","text":"<pre><code>test_successful_upload(\n    mock_registry, mock_config, tmp_path\n)\n</code></pre> <p>Test successful upload when version doesn't exist.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_successful_upload(self, mock_registry, mock_config, tmp_path):\n    \"\"\"Test successful upload when version doesn't exist.\"\"\"\n    # Mock the helper functions\n    with (\n        patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n        patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n    ):\n        # Setup mocks\n        mock_load_metadata.return_value = ({\"name\": \"test-agent\", \"version\": \"0.0.1\"}, None)\n        mock_check_version.return_value = (False, None)\n        mock_registry.upload.return_value = EntryLocation(namespace=\"user\", name=\"test-agent\", version=\"0.0.1\")\n\n        # Call the method\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path))\n\n        # Assertions\n        assert result is not None\n        assert result.namespace == \"user\"\n        assert result.name == \"test-agent\"\n        assert result.version == \"0.0.1\"\n        mock_registry.upload.assert_called_once()\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.TestRegistryCliUpload.test_version_already_exists","title":"test_version_already_exists","text":"<pre><code>test_version_already_exists(\n    mock_registry, mock_config, tmp_path, capsys\n)\n</code></pre> <p>Test upload failure when version already exists.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>def test_version_already_exists(self, mock_registry, mock_config, tmp_path, capsys):\n    \"\"\"Test upload failure when version already exists.\"\"\"\n    # Mock the helper functions\n    with (\n        patch(\"nearai.cli.load_and_validate_metadata\") as mock_load_metadata,\n        patch(\"nearai.cli.check_version_exists\") as mock_check_version,\n    ):\n        # Setup mocks\n        mock_load_metadata.return_value = ({\"name\": \"test-agent\", \"version\": \"0.0.1\"}, None)\n        mock_check_version.return_value = (True, None)\n\n        # Call the method\n        cli = RegistryCli()\n        result = cli.upload(str(tmp_path))\n\n        # Assertions\n        assert result is None\n        captured = capsys.readouterr()\n        # Check for the new Rich-formatted output\n        assert \"Version 0.0.1 already exists\" in captured.out\n        assert \"Version Conflict\" in captured.out\n        assert \"To upload a new version\" in captured.out\n        assert \"--bump\" in captured.out\n        assert \"--minor-bump\" in captured.out\n        assert \"--major-bump\" in captured.out\n        mock_registry.upload.assert_not_called()\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.mock_config","title":"mock_config","text":"<pre><code>mock_config()\n</code></pre> <p>Mock the CONFIG with auth data.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>@pytest.fixture\ndef mock_config():\n    \"\"\"Mock the CONFIG with auth data.\"\"\"\n    with patch(\"nearai.cli.CONFIG\") as mock_conf:\n        mock_conf.auth = MagicMock()\n        mock_conf.auth.namespace = \"test-namespace\"\n        yield mock_conf\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.mock_registry","title":"mock_registry","text":"<pre><code>mock_registry()\n</code></pre> <p>Mock the registry module.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>@pytest.fixture\ndef mock_registry():\n    \"\"\"Mock the registry module.\"\"\"\n    with patch(\"nearai.cli.registry\") as mock_reg:\n        yield mock_reg\n</code></pre>"},{"location":"api/#nearai.tests.test_registry_cli.temp_agent_dir","title":"temp_agent_dir","text":"<pre><code>temp_agent_dir(tmp_path)\n</code></pre> <p>Create a temporary agent directory with metadata.json.</p> Source code in <code>nearai/tests/test_registry_cli.py</code> <pre><code>@pytest.fixture\ndef temp_agent_dir(tmp_path):\n    \"\"\"Create a temporary agent directory with metadata.json.\"\"\"\n    agent_dir = tmp_path / \"test-namespace\" / \"test-agent\" / \"0.0.1\"\n    agent_dir.mkdir(parents=True)\n\n    # Create metadata.json\n    metadata = {\"name\": \"test-agent\", \"version\": \"0.0.1\", \"description\": \"Test agent\", \"category\": \"agent\"}\n\n    metadata_path = agent_dir / \"metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        json.dump(metadata, f)\n\n    # Create agent.py\n    agent_path = agent_dir / \"agent.py\"\n    with open(agent_path, \"w\") as f:\n        f.write(\"# Test agent\")\n\n    return agent_dir\n</code></pre>"},{"location":"cli/","title":"NEAR AI CLI","text":"<p>NEAR AI CLI allows you to create and deploy agents, train and test models, and more!</p>"},{"location":"cli/#requirements","title":"Requirements","text":"<ul> <li>Python 3.9 - 3.11 (3.12 - 3.13 is NOT supported)</li> <li>NEAR Account</li> </ul> <p>Additionally, we recommend creating a virtual environment to avoid conflicts with other Python packages.</p> uvcondapyenv <pre><code># Create a virtual environment with python 3.11\nuv venv --python 3.11\nsource .venv/bin/activate\n</code></pre> <pre><code># Create a virtual environment with python 3.11\nconda create -n nearai python=3.11\nconda activate nearai\n</code></pre> <pre><code># Install python 3.11\npyenv install 3.11\npyenv local 3.11\n\n# Create a virtual environment\npython -m venv .venv\nsource .venv/bin/activate\n</code></pre>"},{"location":"cli/#installing-near-ai-cli","title":"Installing NEAR AI CLI","text":"piplocal <pre><code>pip install nearai  # OR: python3 -m pip install nearai\n</code></pre> <pre><code># Clone the repository:\ngit clone git@github.com:nearai/nearai.git\ncd nearai\n\n# Install dependencies:\npip install -e .  # OR: python3 -m pip install -e .\n</code></pre> <p>Python version</p> <p>NEAR AI requires python <code>3.9 - 3.11</code>. We recommend you to create a virtual environment to avoid conflicts with other Python packages or globally installing dependencies if installing locally w/ repo. </p>"},{"location":"cli/#login-to-near-ai","title":"Login to NEAR AI","text":"<p>To create a new agent, first login with a NEAR Account. If you don't have one, we recommend creating a free account with Meteor Wallet:</p> <pre><code>nearai login # OR nearai login --remote\n</code></pre> <p>Example:</p> <pre><code>$&gt; nearai login\n\nPlease visit the following URL to complete the login process: https://auth.near.ai?message=Welcome+to+NEAR+AI&amp;nonce=&lt;xyzxyzxyzxyzx&gt;&amp;recipient=ai.near&amp;callbackUrl=http%3A%2F%2Flocalhost%3A63130%2Fcapture\n</code></pre> <p>After successfully logging in, you will see a confirmation screen. Close it and return to your terminal.</p> <p></p> Other Login Methods <p>If you have already logged in on <code>near-cli</code>, you know your account's private key, or you have the credentials on another device, you can use the following commands to login:</p> <pre><code>### Login with NEAR Account ID Only\nnearai login --accountId name.near\n\n### Login with Account ID and Private Key\nnearai login --accountId name.near --privateKey key\n\n### Login Remotely (only displays the login URL)\nnearai login --remote\n</code></pre>"},{"location":"cli/#next-steps","title":"Next Steps","text":"<p>That's it! Head over to the Agent Quickstart to get started creating your first agent! \ud83d\ude80</p>"},{"location":"contributing/","title":"Contribute to <code>nearai</code>","text":"<p>Everyone is welcome to contribute, and we value everybody's contribution. Code contributions are not the only way to help the community. Answering questions, helping others, and improving documentation are also immensely valuable.</p> <p>It also helps us if you spread the word! Reference the library in blog posts about the awesome projects it made possible, or even simply \u2b50\ufe0f the repository to say thank you.</p> <p>This guide was heavily inspired by the huggingface transformers guide to contributing.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to contribute","text":"<p>There are several ways you can contribute to <code>nearai</code>:</p> <ul> <li>Contribute to <code>nearai</code></li> <li>Ways to contribute</li> <li>Fixing outstanding issues</li> <li>Submitting a bug-related issue or feature request<ul> <li>Did you find a bug?</li> <li>Do you want a new feature?</li> </ul> </li> <li>Contribute Documentation</li> <li>Create a Pull Request<ul> <li>Pull request checklist</li> <li>Sync a forked repository with upstream main</li> </ul> </li> </ul>"},{"location":"contributing/#fixing-outstanding-issues","title":"Fixing outstanding issues","text":"<p>If you notice an issue with the existing code and have a fix in mind, feel free to start contributing and open a Pull Request!</p>"},{"location":"contributing/#submitting-a-bug-related-issue-or-feature-request","title":"Submitting a bug-related issue or feature request","text":"<p>Do your best to follow these guidelines when submitting a bug-related issue or a feature request. It will make it easier for us to come back to you quickly and with good feedback.</p>"},{"location":"contributing/#did-you-find-a-bug","title":"Did you find a bug?","text":"<p><code>nearai</code> is alpha software. This means there is a possibility of encountering issues in the code. With help from users like you who report problems, we can make it more robust and reliable.</p> <p>Before you report an issue, we would really appreciate it if you could make sure the bug was not already reported (use the search bar on GitHub under Issues). Your issue should also be related to bugs in the library itself, and not your code.</p> <p>Once you've confirmed the bug hasn't already been reported, please include the following information in your issue so we can quickly resolve it:</p> <ul> <li>What did you do?</li> <li>What did you expect to happen?</li> <li>What happened instead?</li> <li>Your OS type and version and Python, PyTorch and versions where applicable.</li> <li>A short, self-contained, code snippet that allows us to reproduce the bug in   less than 30s.</li> <li>The full traceback if an exception is raised.</li> <li>Attach any other additional information, like screenshots, you think may help.</li> </ul> <p>To get the OS and software versions automatically, run the following command:</p> <pre><code>uname -a\n</code></pre>"},{"location":"contributing/#do-you-want-a-new-feature","title":"Do you want a new feature?","text":"<p>If there is a new feature you'd like to see in <code>nearai</code>, please open an issue and describe:</p> <ol> <li>What is the motivation behind this feature? Is it related to a problem or frustration with the library? Is it a feature related to something you need for a project? Is it something you worked on and think it could benefit the community?</li> </ol> <p>Whatever it is, we'd love to hear about it!</p> <ol> <li>Describe your requested feature in as much detail as possible. The more you can tell us about it, the better we'll be able to help you.</li> <li>Provide a code snippet that demonstrates the feature usage.</li> <li>If the feature is related to a paper, please include a link.</li> </ol>"},{"location":"contributing/#contribute-documentation","title":"Contribute Documentation","text":"<p>If you discover any errors or omissions in our documentation, please open an issue and describe:</p> <ul> <li>Which explanation or code snippet is incorrect</li> <li>What concept is not clear or missing</li> <li>If you know, what would be the correct explanation or code snippet</li> </ul> <p>If you think you can contribute a fix for the issue, please feel free to open a Pull Request.</p> <p>To preview your changes locally, you will need to install all the dependencies for the documentation which can be easily installed through <code>pip</code> or <code>uv</code>:</p> pipuv <pre><code>pip install -e \".[docs]\"\n</code></pre> <pre><code>uv sync --group docs\n</code></pre> <p>Then simply test your changes locally using <code>mkdocs serve</code></p> <p>Cairo Graphics</p> <p>If you encounter a problem with <code>cairo</code>, please follow the mkdocs-material Requirements Guide</p>"},{"location":"contributing/#create-a-pull-request","title":"Create a Pull Request","text":"<p>Before writing any code, we strongly advise you to search through the existing PRs or issues to make sure nobody is already working on the same thing. If you are unsure, it is always a good idea to open an issue to get some feedback.</p> <p>You will need basic <code>git</code> proficiency to contribute to <code>nearai</code>. While <code>git</code> is not the easiest tool to use, it has the greatest manual. Type <code>git --help</code> in a shell and enjoy! If you prefer books, Pro Git is a very good reference. We also recommend asking any available AGI to help you with <code>git</code>.</p> <p>Follow the steps below to start contributing:</p> <ol> <li> <p>Fork the repository by    clicking on the Fork button on the repository's page. This creates a copy of the code    under your GitHub user account.</p> </li> <li> <p>Clone your fork to your local disk, and add the base repository as a remote:</p> </li> </ol> <pre><code>git clone git@github.com:&lt;your Github handle&gt;/nearai.git\ncd nearai\ngit remote add upstream https://github.com/nearai/nearai.git\n</code></pre> <ol> <li>Create a new branch to hold your development changes:</li> </ol> <pre><code>git checkout -b a-descriptive-name-for-my-changes\n</code></pre> <p>\ud83d\udea8 Do not work on the <code>main</code> branch!</p> <ol> <li> <p>Set up a development environment (follow steps in the README):</p> </li> <li> <p>Develop the features in your branch.</p> </li> </ol> <p>As you work on your code, you should make sure it functions as intended.</p> <p><code>nearai</code> relies on <code>ruff</code> and <code>mypy</code> to format and type check its source code    consistently. After you make your changes and are ready to PR them, ensure that    your code is formatted and type-checked by running:</p> <pre><code>./scripts/format_check.sh\n</code></pre> <pre><code>./scripts/lint_check.sh\n</code></pre> <pre><code>./scripts/type_check.sh\n</code></pre> <p>Once you're happy with your changes, add the changed files with <code>git add</code> and    record your changes locally with <code>git commit</code>:</p> <pre><code>git add modified_file.py\ngit commit\n</code></pre> <p>Please remember to write good commit    messages to clearly communicate the changes you made!</p> <p>To keep your copy of the code up to date with the original    repository, rebase your branch on <code>upstream/branch</code> before you open a pull request or if requested by a maintainer:</p> <pre><code>git fetch upstream\ngit rebase upstream/main\n</code></pre> <p>Push your changes to your branch:</p> <pre><code>git push -u origin a-descriptive-name-for-my-changes\n</code></pre> <p>If you've already opened a pull request, you'll need to force push with the <code>--force</code> flag. Otherwise, if the pull request hasn't been opened yet, you can just push your changes normally.</p> <ol> <li> <p>Now you can go to your fork of the repository on GitHub and click on Pull Request to open a pull request. Make sure you tick off all the boxes on our checklist below. When you're ready, you can send your changes to the project maintainers for review.</p> </li> <li> <p>It's ok if maintainers request changes, it happens to our core contributors    too! So everyone can see the changes in the pull request, work in your local    branch and push the changes to your fork. They will automatically appear in    the pull request.</p> </li> </ol>"},{"location":"contributing/#pull-request-checklist","title":"Pull request checklist","text":"<ul> <li>The pull request title should summarize your contribution.</li> <li>If your pull request addresses an issue, please mention the issue number in the pull request description to make sure they are linked (and people viewing the issue know you are working on it).</li> <li>To indicate a work in progress please prefix the title with <code>[WIP]</code>. These are useful to avoid duplicated work, and to differentiate it from PRs ready to be merged.</li> <li>Don't add any images, videos and other non-text files that'll significantly weigh down the repository. Instead, reference them by URL.</li> </ul>"},{"location":"contributing/#sync-a-forked-repository-with-upstream-main","title":"Sync a forked repository with upstream main","text":"<p>When updating the main branch of a forked repository, please follow these steps to avoid pinging the upstream repository which adds reference notes to each upstream PR, and sends unnecessary notifications to the developers involved in these PRs.</p> <ol> <li>When possible, avoid syncing with the upstream using a branch and PR on the forked repository. Instead, merge directly into the forked main.</li> <li>If a PR is absolutely necessary, use the following steps after checking out your branch:</li> </ol> <pre><code>git checkout -b your-branch-for-syncing\ngit pull --squash --no-commit upstream main\ngit commit -m '&lt;your message without GitHub references&gt;'\ngit push --set-upstream origin your-branch-for-syncing\n</code></pre>"},{"location":"decentralization/","title":"Decentralization","text":"<p>This document outlines process of progressive decentralization of NEAR AI capabilities.</p> <p>NEAR AI project approaches decentralization in a progressive way, starting with delivering best researcher, developer and user experience possible and progressively decentralizing and enabling privacy and trust features over time.</p> Component Objective Registry Decentralized storage with support of private and encrypted items Training / Fine-tuning Leveraging decentralized set of nodes to train models in a provable way Agent runner Using trusted execution environment to run agents privately and Agent memory Using FHE to do retrieval from encrypted storage Inter-agent communication Peer-to-peer protocol that supports identity,  payments and dispute resolution"},{"location":"inference/","title":"NEAR AI Inference API (OpenAI Compatible)","text":"<p>NEAR AI provides an OpenAI-compatible API for inference, allowing you to easily integrate powerful language models into your applications.</p> <p>This guide covers the basic inference endpoints and how to use them. For recommended usage of NEAR AI inference in agents explore agent examples below or jump to Model Match section.</p> <p>Agent examples are available here: nearai examples, nearai_langchain examples</p>"},{"location":"inference/#getting-started","title":"Getting Started","text":"<ol> <li>Install all dependencies</li> </ol> <p>a. using <code>pip</code>:</p> <pre><code># Create a virtual environment\npython -m venv nearai_env\n\n# Activate the virtual environment\n# On Windows:\n# nearai_env\\Scripts\\activate\n# On macOS and Linux:\nsource nearai_env/bin/activate\n\n# Install the package in editable mode\npip install -e .\n</code></pre> <p>b. using uv:</p> <pre><code>uv sync --group dev\n</code></pre> <ol> <li> <p>Set up authentication:</p> </li> <li> <p>Log in to NEAR AI using the CLI: <code>nearai login</code></p> </li> <li> <p>The auth object will be saved in <code>~/.nearai/config.json</code></p> </li> <li> <p>Import the required libraries and set up the client</p> </li> </ol> <pre><code>import openai\nimport json\nimport os\nimport nearai\n\nhub_url = \"https://api.near.ai/v1\"\n\n# Login to NEAR AI Hub using nearai CLI.\n# Read the auth object from ~/.nearai/config.json\nauth = nearai.config.load_config_file()[\"auth\"]\nsignature = json.dumps(auth)\n\nclient = openai.OpenAI(base_url=hub_url, api_key=signature)\n</code></pre>"},{"location":"inference/#list-models","title":"List Models","text":"<p>To list available models, use the <code>models.list()</code> method:</p> <pre><code>models = client.models.list()\nprint(models)\n</code></pre> <p>Different providers have different models, and different model formats. For example, fireworks has a format <code>fireworks::accounts/&lt;namespace&gt;/models/&lt;model_name&gt;</code>. To get all unique providers, do:</p> <pre><code>providers = set([model.id.split(\"::\")[0] for model in models])\nprint(providers)\n</code></pre>"},{"location":"inference/#create-a-chat-completion","title":"Create a Chat Completion","text":"<p>To create a chat completion, use the <code>chat.completions.create()</code> method. Here's an example:</p> <pre><code>completion = client.chat.completions.create(\n  model=\"fireworks::accounts/fireworks/models/qwen2p5-72b-instruct\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n  ]\n)\n\nprint(completion.choices[0].message.content)\n</code></pre> <p>This will send a request to the specified model with the given messages and return the model's response. The response can be accessed through the <code>choices</code> array in the returned object.</p>"},{"location":"inference/#error-handling","title":"Error Handling","text":"<p>When using the API, it's important to handle potential errors. Here's an example of how to implement basic error handling:</p> <pre><code>try:\n  completion = client.chat.completions.create(\n    model=\"fireworks::accounts/fireworks/models/qwen2p5-72b-instruct\",\n    messages=[\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n      {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n    ]\n  )\n  print(completion.choices[0].message.content)\nexcept openai.APIError as e:\n  print(f\"An API error occurred: {e}\")\nexcept Exception as e:\n  print(f\"An unexpected error occurred: {e}\")\n</code></pre>"},{"location":"inference/#model-match","title":"Model Match","text":"<p>For agents written in Python, we expect the model name to be given either in <code>metadata.json</code> or <code>env.completion</code> as <code>&lt;optional_namespace&gt;/&lt;model_name&gt;</code>. Examples: - \"llama-v3-70b-instruct\" - \"yi-01-ai/yi-large\"</p> <p>\"model_provider\" may also be optionally specified in <code>metadata.json</code>.</p> <p>Existing provider models are matched against the provided model name, and provider model full path is automatically determined using <code>def match_provider_model()</code> function. This function is executed when: - <code>env.completion()</code> function is called. - (<code>nearai_langchain</code> library) <code>orchestrator.chat_model</code> inference is called.</p>"},{"location":"inference/#additional-features","title":"Additional Features","text":"<p>The NEAR AI Inference API also supports other features such as:</p> <ol> <li>Streaming responses</li> <li>Function calling</li> <li>Custom parameters (temperature, max_tokens, etc.)</li> </ol> <p>For more information on these features, please refer to the full API documentation.</p>"},{"location":"inference/#conclusion","title":"Conclusion","text":"<p>This guide covers the basics of using the NEAR AI Inference API. By following these steps, you should be able to authenticate, list models, and create chat completions. For more advanced usage and detailed information, please refer to the complete API documentation or explore the provided examples.</p>"},{"location":"private-ml-sdk/","title":"Private and Verifiable AI","text":"<p>Thanks to a combination of cryptographic techniques and secure hardware, NEAR AI is private and verifiable every step of the way. From agent interactions to model training, our infrastructure ensures data privacy and result integrity throughout the entire process.</p> <p></p> <p>NEAR AI leverages technology from Intel and NVIDIA to keep your data safe and isolated</p> <p>To execute an agent securely, NEAR AI uses Intel TDX technology to create a Confidential Virtual Machine (CVM). This CVM is a virtual machine that runs in an isolated environment within the CPU, where a Docker container containing the agent's code and user data is deployed and executed. </p> <p>For model inference, an encrypted communication channel is established using NVIDIA TEE technology, which creates a Confidential Space within the GPU. The model runs in this isolated environment, protected from external access.</p> <p>It's important to note that the CPU and GPU Confidential Spaces operate in complete isolation from the rest of the system - neither the operating system nor the hypervisor (VM manager) can access the code or data being processed.</p> Want to dive deeper? <p>All technology that powers NEAR AI is open-sourced. If you want to dive deeper and learn more about how this secure and private AI is being developed, check out the Private ML SDK on GitHub. </p>"},{"location":"private-ml-sdk/#how-can-i-trust-it","title":"How Can I Trust It?","text":"<p>Before deployment, NEAR AI verifies both proper hardware configuration and Docker container image hash integrity. This ensures a secure runtime environment and that the exact code being executed matches expectations.</p> <p>After execution, NEAR AI validates security through TEE attestations - cryptographic proofs verify both a secure environment and data/code integrity. </p> <p>You can view and verify these attestations yourself or publish them on-chain with NEAR Protocol to allow anyone to verify them. This provides a cryptographically verifiable chain of trust through the entire stack from agent to inference to hardware; all the way down to the certifications from the chip manufacturers.</p>"},{"location":"private-ml-sdk/#how-can-i-use-it","title":"How Can I Use it?","text":"<p>Right now we are beta testing this technology, but soon we will open for public use. In the near future, all agents and models will run in this secure environment, ensuring that your data is always safe and the results are correct.</p> <p>Stay tuned for more updates!</p>"},{"location":"agents/quickstart/","title":"Agents Quickstart","text":"<p>In this Quickstart you will learn how to setup NEAR AI and then use it to build &amp; interact with an AI agent in less than one minute. \ud83c\udfc3\u200d\u2642\ufe0f</p> <p>NEAR AI Agents are programs that can act autonomously to solve a task, while adapting and reacting to their environment.  These agents can use various AI models, store data to remember past interactions, communicate with other agents, use tools to  interact with the environment, and much more.</p>"},{"location":"agents/quickstart/#prerequisites","title":"\u26a0\ufe0f Prerequisites","text":"<p>Before creating a NEAR AI agent, please make sure you have the NEAR AI CLI installed and have logged in with your Near wallet.</p>"},{"location":"agents/quickstart/#create-an-agent","title":"Create an Agent","text":"<p>You can create a new agent by running the following command using the NEAR AI CLI:</p> <p><pre><code>nearai agent create\n</code></pre> You will then be prompted to provide a few details about your agent:</p> <ol> <li>The name of your agent.</li> <li>A short description of your agent.</li> <li>Initial instructions for the agent (which can be edited later).</li> </ol> <p></p> <p>Once you have complete these three prompts, you'll see a summary to verify the information is correct:</p> <p></p> <p>If everything looks good, press <code>y</code> to build your agent. Once complete, you should see a confirmation screen similar to this:</p> <p></p> <p>Here you will find:</p> <ol> <li> <p>Where the agent was created:</p> <p><code>/home_directory/.nearai/regisitry/&lt;your-account.near&gt;/&lt;agent-name&gt;/0.0.1</code></p> </li> <li> <p>Useful commands to get started interacting with it:</p> <pre><code># Run agent locally\nnearai agent interactive &lt;path-to-agent&gt; --local\n\n# Select from a list of agents you created to run locally\nnearai agent interactive --local\n\n# Upload agent to NEAR AI's public registry\nnearai registry upload &lt;path-to-agent&gt;\n</code></pre> </li> </ol> <p>Success! You now have a new AI Agent ready to use!  </p>"},{"location":"agents/quickstart/#agent-files","title":"Agent Files","text":"<p>During the agent creation process, <code>nearai</code> builds your agent in your local AI registry located at:</p> <p><code>/home_directory/.nearai/registry/&lt;your-account.near&gt;/&lt;agent-name&gt;/0.0.1</code> </p> <p>This folder contains two files that define your agent:</p> <ol> <li><code>metadata.json</code>: Contains information / configuration about your agent.</li> <li><code>agent.py</code>: Python code that executes each time your agent receives a prompt.</li> </ol>"},{"location":"agents/quickstart/#metadatajson","title":"<code>metadata.json</code>","text":"<p>This file contains your agent information and configuration settings.</p> metadata.json<pre><code>{\n  \"name\": \"example-agent\",\n  \"version\": \"0.0.1\",\n  \"description\": \"NEAR AI docs example agent ;)\",\n  \"category\": \"agent\",\n  \"tags\": [],\n  \"details\": {\n    \"agent\": {\n      \"defaults\": {\n        \"model\": \"llama-v3p1-70b-instruct\",\n        \"model_provider\": \"fireworks\",\n        \"model_temperature\": 1.0,\n        \"model_max_tokens\": 16384\n      }\n    }\n  },\n  \"show_entry\": true\n}\n</code></pre>"},{"location":"agents/quickstart/#ai-model","title":"AI Model","text":"<p>Llama 3.1 70B Instruct is currently the default model for agents but you can easily change it by selecting one from app.near.ai/models and updating your JSON file.</p> <p>You can also fine tune and serve a model to fit your specific needs. (See Fine Tuning)</p>"},{"location":"agents/quickstart/#python-package-support","title":"Python Package Support","text":"<p>There are different frameworks for agents that define which Python packages they support and is configured in your <code>metadata.json</code> file. </p> <pre><code>{\n  \"details\": {\n    \"agent\": {\n      \"framework\": \"standard\"  // or \"minimal\", \"ts\", \"agentkit\", etc.\n    }\n  }\n}\n</code></pre> <p>See Supported Packages for more information.</p>"},{"location":"agents/quickstart/#agentpy","title":"<code>agent.py</code>","text":"<p>This file contains the code that executes each time your agent receives a prompt. By default it will use simple instructions provided by the user during the creation process.</p> <p>For more information on how to use the environment object, see The Agent Environment.</p> <p>For additional examples, see the NEAR AI Official Agents or the NEAR AI Public Registry.</p> agent.py<pre><code>from nearai.agents.environment import Environment\n\n\ndef run(env: Environment):\n    # A system message guides an agent to solve specific tasks.\n    prompt = {\"role\": \"system\", \"content\": \"You are a helpful agent that will educate users about NEAR AI.\"}\n\n    # Use the model set in the metadata to generate a response\n    result = env.completion([prompt] + env.list_messages())\n\n    # Store the result in the chat history\n    env.add_reply(result)\n\n    # Give the prompt back to the user\n    env.request_user_input()\n\nrun(env)\n</code></pre>"},{"location":"agents/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you have the basics down, here are some key areas to focus on next that will help you better understand what is possible when building with NEAR AI:</p>"},{"location":"agents/quickstart/#ship-your-agent","title":"Ship your agent \ud83d\ude80","text":"<p>Upload your agent to the agent registry and easily embed it into your website.</p>"},{"location":"agents/quickstart/#explore-the-registry","title":"Explore the Registry \ud83d\udd0d","text":"<p>The NEAR AI Registry is your hub for agent discovery and collaboration. Browse community-created agents, learn from examples, and share your own creations with others.</p>"},{"location":"agents/quickstart/#master-threads","title":"Master Threads \ud83d\udcac","text":"<p>Threads power agent execution and interaction. Learn to structure conversations, manage file attachments, and create coordinated multi-agent interactions - all within organized conversation threads. </p>"},{"location":"agents/quickstart/#explore-the-environment","title":"Explore the Environment \ud83e\uddd1\u200d\ud83d\udcbb","text":"<p>The environment object unlocks NEAR AI's powerful features:</p> <ul> <li>Create natural conversations with advanced message handling</li> <li>Leverage AI models for intelligent decision-making</li> <li>Enable agent-to-agent communication</li> <li>Extend capabilities with custom tools</li> </ul>"},{"location":"agents/quickstart/#learn-about-secrets-and-variables","title":"Learn About Secrets and Variables \ud83d\udd11","text":"<p>Learn how to manage environment variables and secure with proper secrets management. Store API keys safely and connect to external services with confidence.</p>"},{"location":"agents/registry/","title":"Agent Registry: Finding and Publishing Agents","text":"<p>NEAR AI agents can be deployed and hosted in a common registry, allowing the community to share their creations. This registry is used by the NEAR AI Developer Hub to store and serve agents.</p> <p>Let's take a look at how we can navigate this registry, download agents, and contribute our own agents to the ecosystem.</p> <p>Note</p> <p>The agent registry is backed by an S3 bucket with metadata stored in a database.</p>"},{"location":"agents/registry/#finding-an-agent","title":"Finding an Agent","text":"<p>There are two main ways to navigate the agent registry to discover agents: </p> <ul> <li>NEAR AI Developer Hub</li> <li>NEAR AI CLI</li> </ul> <p>For the rest of this guide, we will use the CLI to find and deploy agents. </p> <p>Tip</p> <p>Refer to the Quickstart Guide to learn how to install the CLI and login to the AI Developer Hub.</p>"},{"location":"agents/registry/#view-all-agents","title":"View all agents","text":"<p>To view all agents with <code>nearai</code> CLI, run:</p> <pre><code>nearai registry list --category agent\n</code></pre> Example Output <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 entry                           \u2502 description             \u2502 tags  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 zavodil.near/ai16z-docs/1.03    \u2502 AI agent with AI16Z ... \u2502 agent \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 flatirons.near/common-tool...   \u2502 A library of common ..  \u2502 llama \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 jayzalowitz.near/example_a...   \u2502 Example agent           \u2502       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ...                             \u2502 ...                     \u2502 ...   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"agents/registry/#filtering-agents","title":"Filtering Agents","text":"<p>You can further filter the agents with two flags:</p> <ul> <li><code>--namespace</code> : The developer that created it</li> <li><code>--tags</code>: Any tags that were added to the agent</li> </ul> <p>For example, to find all agents created by <code>gagdiez.near</code> with the tag <code>template</code>, run:</p> <pre><code>nearai registry list  --category agent \\\n                      --namespace gagdiez.near \\\n                      --tags template \\\n                      --show_all\n</code></pre> <p>Tip</p> <p>You can use the <code>info</code> command to get more details about a specific agent, for example:</p> <pre><code>nearai registry info gagdiez.near/hello-ai/latest\n</code></pre>"},{"location":"agents/registry/#downloading-an-agent","title":"Downloading an Agent","text":"<p>Once you find an agent that you would like to download, use the <code>download</code> command to save it locally. Agent details are passed in the following format:</p> <pre><code>nearai registry download &lt;account.near&gt;/&lt;agent_name&gt;/&lt;version&gt;\n</code></pre> <p>The <code>version</code> can be a specific version number, or <code>latest</code> to download the most recent version.</p> <p>Example: </p> <pre><code># Download a hello world agent\nnearai registry download gagdiez.near/hello-ai/latest\n</code></pre> <p>This command saves the agent locally in <code>.nearai/registry</code> under your home directory.</p> <p>The example above would save to: <code>~/.nearai/registry/gagdiez.near/hello-ai/latest</code>.</p> <p>Tip</p> <p>The <code>--force</code> flag allows you to overwrite the local agent with the version from the registry.</p>"},{"location":"agents/registry/#uploading-an-agent","title":"Uploading an Agent","text":"<p>If you created an agent and would like to share it with others, you can upload it to the registry. To upload an agent, you must be logged in.</p> <p>The <code>upload</code> command requires the path to the agent folder stored locally, for example:</p> <pre><code>nearai registry upload ~/.nearai/registry/&lt;your-account.near&gt;/&lt;agent_folder&gt;\n</code></pre> <p>The folder must contain:</p> <ul> <li><code>agent.py</code>: Agent logic</li> <li><code>metadata.json</code>: Agent information (ex: description, tags, and model, etc.)</li> </ul> Example <code>metadata.json</code> file metadata.json<pre><code>{\n\"name\": \"hello-ai\",\n\"version\": \"0.0.1\",\n\"description\": \"A friendly agent\",\n\"category\": \"agent\",\n\"tags\": [],\n\"details\": {\n  \"agent\": {\n    \"defaults\": {\n      \"model\": \"llama-v3p1-70b-instruct\",\n      \"model_provider\": \"fireworks\",\n      \"model_temperature\": 1.0,\n      \"model_max_tokens\": 16384\n    }\n  }\n},\n\"show_entry\": true\n}\n</code></pre> <p>Tags</p> <p>Remember to add tags to your agent to make it easier for others to find it in the registry, for example:</p> <pre><code>{ \"tags\": [\"travel\", \"assistant\", \"vacation\"] }\n</code></pre> <p>Danger</p> <p>All files in this folder will be uploaded to the registry which is PUBLIC! Make sure you are not including any sensitive data.</p> <p>Warning</p> <p>You can't remove or overwrite a file once it's uploaded, but you can hide the entire agent by setting the <code>\"show_entry\": false</code> field in the <code>metadata.json</code> file</p>"},{"location":"agents/registry/#embedding-an-agent","title":"Embedding an Agent","text":"<p>You can embed NEAR AI agents directly into your website using an iframe. This allows users to interact with your agent without leaving your site.</p>"},{"location":"agents/registry/#basic-embedding","title":"Basic Embedding","text":"<p>To embed an agent, use the following iframe code replacing the <code>src</code> with the agent you want to embed.</p> <p><code>Example</code>:</p> <pre><code>&lt;iframe \n  src=\"https://app.near.ai/embed/&lt;your-account.near&gt;/&lt;your-agent-name&gt;/latest\" \n  sandbox=\"allow-scripts allow-popups allow-same-origin allow-forms\"\n  style=\"border: none; height: 100svh;\"&gt;\n&lt;/iframe&gt;\n</code></pre> <p>Info</p> <ul> <li> <p>Note that the difference with this <code>src</code> path compared to a regular link to your agent is that it is using the <code>embed</code> endpoint.</p> </li> <li> <p>Also note that you can replace the <code>latest</code> with a specific agent version number.</p> </li> </ul> <p>Tip</p> <p>You can also copy/paste the snippet from the NEAR AI Dev Platform.</p> <ul> <li>Clicking the <code>share</code> icon from your agent page and select <code>&lt;embed&gt;</code></li> </ul> <p></p>"},{"location":"agents/registry/#customizing-the-embed","title":"Customizing the Embed","text":"<p>There are three ways to customize the appearance and behavior of your embedded agent:</p> <ol> <li>Basic iframe attributes</li> <li>URL parameters</li> <li><code>metadata.json</code> file</li> </ol> <p>Info</p> <p>The embedded agent will inherit the styling of the NEAR AI platform while maintaining a consistent look and feel with your website.</p>"},{"location":"agents/registry/#light-or-dark-theme","title":"Light or Dark Theme","text":"<p>For light or dark themes, add a <code>theme</code> parameter to the embed src URL:</p> <p><code>src=\"https://app.near.ai/embed/&lt;your-account.near&gt;/&lt;your-agent-name&gt;/latest?theme=dark\"</code></p>"},{"location":"agents/registry/#custom-logo","title":"Custom Logo","text":"<p>You can also add a custom logo to replace the default agent name in the upper left hand corner of your agent.</p> <p>In your <code>metadata.json</code> file add an <code>embed</code> section under the agent details:</p> <pre><code>{\n  \"details\": {\n    \"agent\": {\n      \"embed\": {\n        \"logo\": \"https://near.ai/logo-white.svg\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"agents/running/","title":"Running an Agent","text":"<p>Agents can be run locally or remotely. When running locally, you can run them interactively or as a task. When running remotely, you can use the NEAR AI API to run them.</p>"},{"location":"agents/running/#running-the-agent-locally","title":"Running the Agent Locally","text":"<p>You can execute it in two different ways: interactively or as a task.</p> <p>Know that you can also run agents directly on the Web AI Hub, you don't need to download an agent if you just want to see how they work.</p> <p>Always Review the Code</p> <p>Agents can execute arbitrary code on your machine, so please always review the agent's code before running it!</p> <p>By default, you will find the agent's code on the local directory <code>~/.nearai/registry</code>, there, check the agent's <code>agent.py</code> file either by using the <code>cat</code> command or opening it in a text editor.</p> <pre><code># Checking gagdiez.near/hello-ai/latest code\ncd ~/.nearai/registry/gagdiez.near/hello-ai/latest\ncat agent.py\n</code></pre>"},{"location":"agents/running/#interactive-run","title":"Interactive Run","text":"<p>Interactive runs execute the agent on a loop, allowing you to chat with it interactively until you decide to exit (using the <code>exit</code> command), or quit the session using <code>ctrl+c</code>.</p> <pre><code># Download the agent from the registry\nnearai registry download gagdiez.near/hello-ai/latest\n\n# Running the agent by absolute path\nnearai agent interactive ~/.nearai/registry/gagdiez.near/hello-ai/latest --local\n</code></pre>"},{"location":"agents/running/#running-as-a-task","title":"Running as a Task","text":"<p>When running an agent as a task, we simply provide an input and let the agent execute it without any user interaction.</p> <pre><code>nearai agent task ~/.nearai/registry/gagdiez.near/hello-ai/latest \"write a poem about the sorrow of losing oneself, but end on a positive note\" --local\n</code></pre>"},{"location":"agents/running/#running-the-agent-remotely","title":"Running the Agent Remotely","text":"<p>Agents can be run through the <code>/thread/runs</code>, <code>/thread/{thread_id}/runs</code> or  <code>/agent/runs</code> endpoints. The /thread syntax matches the OpenAI / LangGraph API. The /agent syntax is NEAR AI specific.</p> <p>You will need to pass a signed message to authenticate. This example uses the credentials written by <code>nearai login</code> to your <code>~/.nearai/config.json</code> file.</p> <pre><code>auth_json=$(jq -c '.auth' ~/.nearai/config.json);\n\ncurl \"https://api.near.ai/v1/threads/runs\" \\\n      -X POST \\\n      --header 'Content-Type: application/json' \\\n      --header \"Authorization: Bearer $auth_json\" \\\n-d @- &lt;&lt;'EOF'\n  {\n    \"agent_id\": \"flatirons.near/xela-agent/5.0.1\",\n    \"new_message\":\"Build a backgammon game\",\n    \"max_iterations\": \"1\"\n  }\nEOF\n</code></pre> <p>The full message will look like this. A <code>thread_id</code> param can also be passed to continue a previous conversation.  <pre><code>curl \"https://api.near.ai/v1/threads/runs\" \\\n      -X POST \\\n      --header 'Content-Type: application/json' \\\n      --header 'Authorization: Bearer {\"account_id\":\"your_account.near\",\"public_key\":\"ed25519:YOUR_PUBLIC_KEY\",\"signature\":\"A_REAL_SIGNATURE\",\"callback_url\":\"https://app.near.ai/\",\"message\":\"Welcome to NEAR AI Hub!\",\"recipient\":\"ai.near\",\"nonce\":\"A_UNIQUE_NONCE_FOR_THIS_SIGNATURE\"}' \\\n-d @- &lt;&lt;'EOF'\n  {\n    \"agent_id\": \"flatirons.near/xela-agent/5.0.1\",\n    \"thread_id\": \"a_previous_thread_id\",\n    \"new_message\":\"Build a backgammon game\", \n    \"max_iterations\": \"2\"\n  }\nEOF\n</code></pre></p> Remote results <p>The results of the /agent/runs endpoints are either an error or the resulting thread_id.</p> <p>\"thread_579e1cf3f42742c785218106\"</p> <p>Threads follow the OpenAI / LangGraph api standard. <code>/threads/{thread_id}/messages</code> will return the messages on the thread. See the full NEAR AI OpenAPI spec here: https://api.near.ai/openapi.json</p>"},{"location":"agents/threads/","title":"Threads","text":"<p>Every agent execution happens within a conversation thread, which is isolated from other threads. Threads allow agents to maintain a message history and persist files in time so the user can continue the conversation later.</p> <p>Info</p> <p>You can find how agents persist messages and files in the Environment: Messages &amp; Files section.</p>"},{"location":"agents/threads/#starting-a-thread","title":"Starting a Thread","text":"<p>If we start an agent without specifying an existing thread, a new thread is created. Let's try this by executing an agent using the interactive mode:</p> <pre><code>nearai agent interactive ~/.nearai/registry/&lt;your-account.near&gt;/hello-ai/0.0.1 --local\n\n&gt; Hello, my name is Guille, please remember it\n\n# Example Output:\n# ...\n# thread_id: thread_43c64803c0a948bc9a8eb8e8\n\n# Assistant: Nice to meet you, Guille! I've made a note of your name, so feel free to ask me anything or start a conversation, and I'll be sure to address you by your name throughout our chat. How's your day going so far, Guillermo?\n</code></pre> <p>We can see in the output that a new <code>thread_id</code> - <code>thread_43c64803c0a948bc9a8eb8e8</code> - was created for this conversation.</p>"},{"location":"agents/threads/#resuming-a-thread","title":"Resuming a Thread","text":"<p>If we want to resume a conversation thread with an agent, we can specify the thread ID when running the agent:</p> <pre><code>nearai agent interactive ~/.nearai/registry/&lt;your-account.near&gt;/hello-ai/0.0.1 --local --thread_id thread_43c64803c0a948bc9a8eb8e8\n\n&gt; What is my name?\n\n# Assistant: Your name is Guille\n</code></pre>"},{"location":"agents/threads/#messages-and-files","title":"Messages and Files","text":"<p>Agents can access and add messages and files on each thread, learn more about it in the Environment: Messages &amp; Files section.</p>"},{"location":"agents/vector-stores/","title":"Vector Stores","text":"<p>Vector Stores are special databases that allow retrieving documents with natural language. They are very useful to provide agents with knowledge on which they have not been trained.</p> <p>Internally, they use AI models to convert text into low-dimensional vectors known as <code>embeddings</code>. Similar text will shield similar <code>embeddings</code>, allowing us to find relevant documents for a query by comparing the query's <code>embedding</code> with the documents' <code>embeddings</code> in the store.</p> <p>This page describes how to create, upload, query, and manage a Vector Store in NEAR AI, and how to integrate it on agents to generate context-aware responses.</p> <p>Tip</p> <p>Read our tutorial on Vector Stores to discover how you can build an agent that answers questions based on your custom data</p>"},{"location":"agents/vector-stores/#1-import-and-configure","title":"1. Import and Configure","text":"<p>To use Vector Stores we need to import the NEAR AI module, load configuration settings, and initialize an OpenAI-compatible client which we will connect to the NEAR AI endpoint.</p> <pre><code>import json\nfrom glob import glob\n\nimport openai\nimport nearai\n\n# Load NEAR AI Hub configuration\nconfig = nearai.config.load_config_file()\nbase_url = config.get(\"api_url\", \"https://api.near.ai/\") + \"v1\"\nauth = config[\"auth\"]\n\nclient = openai.OpenAI(base_url=base_url, api_key=json.dumps(auth))\n</code></pre>"},{"location":"agents/vector-stores/#2-creating-a-vector-store","title":"2. Creating a Vector Store","text":"<p>Assuming you have all the files you want to add to the vector store in a local directory containing your files, you will need to upload them to NEAR AI, and assign them to a Vector Store.</p> <p>Once assigned, the files will be processed by the NEAR AI platform to automatically generate the embeddings </p> <pre><code># Load all .md files in the current directory\nmd_files = list(glob(\"./**/*.md\", recursive=True))\n\nfile_ids = []\nfor file_path in md_files:\n    print(f\"Processing {file_path}\")\n\n    with open(file_path, 'r', encoding='utf-8') as file:\n        uploaded_file = client.files.create(\n            file=(file_path, file.read(), \"text/markdown\"),\n            purpose=\"assistants\"\n        )\n        file_ids.append(uploaded_file.id)\n\nvs = client.vector_stores.create(\n    name=\"my-vector-store\",\n    file_ids=file_ids,\n    # chunking_strategy={\n    #     \"chunk_overlap_tokens\": 400,\n    #     \"max_chunk_size_tokens\": 800\n    # }\n)\n\nprint(f\"Vector store created: {vs.id}\")\n</code></pre> <p>Chunking Strategy</p> <p>Before converting documentation into vector embeddings, the NEAR AI platform segments the text into smaller, manageable chunks. The optional <code>chunking_strategy</code> parameter allows you to customize this process.</p> <p>By default, the platform will split the text into chunks of 800 tokens, with an overlap of 400 tokens. It is important to notice that chunks are not created based on the document's structure, but merely on counting tokens, which can lead to a loss of context. Feel free to adjust these values to better suit your data.</p> Processing single files <p>While less efficient for handling multiple files, you can upload and attach single files to the vector store.</p> <pre><code># Upload file\nuploaded_file = client.files.create(\n    file=(file_path, file.read(), \"text/markdown\"),\n    purpose=\"assistants\"\n)\n\n# Attach file to the vector store\nclient.vector_stores.files.create(\n    vector_store_id=vector_store.id,\n    file_id=uploaded_file.id,\n)\n</code></pre>"},{"location":"agents/vector-stores/#3-wait-for-processing","title":"3. Wait for Processing","text":"<p>After you attach files to a vector store they will be processed in the background. You can check the status of the vector store to see if the processing is complete.</p> <pre><code>while True:\n    status = client.vector_stores.retrieve(vector_store.id)\n    if status.file_counts.completed == 1:\n        break\n    time.sleep(1)\n\nprint(\"File processed! The vector store is ready.\")\n</code></pre>"},{"location":"agents/vector-stores/#4-delete-a-file","title":"4. Delete a File","text":"<p>You can delete a specific file from the vector store by providing both the store\u2019s and file\u2019s IDs. This operation removes the file and its embeddings, helping to manage and update your stored data.</p> <pre><code>client.vector_stores.files.delete(\n    vector_store_id=vector_store.id,\n    file_id=file_id\n)\n</code></pre>"},{"location":"agents/vector-stores/#5-query-the-vector-store","title":"5. Query the Vector Store","text":"<p>When building an agent, you can use the <code>env.query_vector_store()</code> function to retrieve documents from the vector store that are relevant to a user query.</p> agent.py<pre><code>def run(env: Environment):\n    user_query = env.list_messages()[-1][\"content\"]\n\n    # Query the Vector Store\n    vector_results = env.query_vector_store(VECTOR_STORE_ID, user_query)\n\nrun(env)\n</code></pre> <p>Agent Example</p> <p>Check our Docs AI Agent that uses a vector store to provide context-aware responses on NEAR Protocol documentation</p> Query Vector Store Result <p>The method returns a list of objects, each containing a <code>file_id</code>, <code>chunk_text</code>, and <code>distance</code> (similarity score), for example:</p> <pre><code>[\n    {\n      'file_id': 'file_278138cf53a245558766c31d',\n      'chunk_text': 'nMachine learning and data mining often employ the same methods and overlap significantly ...',\n      'distance': 0.6951444615680473\n    },\n    ...\n]\n</code></pre>"},{"location":"agents/vector-stores/#6-generate-an-llm-response-with-context","title":"6. Generate an LLM Response with Context","text":"<p>We can use the retrieved documents to provide a context for the AI model that generates the response.</p> <pre><code>import json\nfrom nearai.agents.environment import Environment\n\nMODEL = \"llama-v3p3-70b-instruct\"\nVECTOR_STORE_ID = \"vs_cb8d5537f64d4f4aa6cbc95f\"\n\ndef run(env: Environment):\n    user_query = env.list_messages()[-1][\"content\"]\n\n    # Query the Vector Store\n    vector_results = env.query_vector_store(VECTOR_STORE_ID, user_query)\n    docs = [{\"file\": res[\"chunk_text\"]} for res in vector_results[:6]]\n\n    prompt = [\n        {\n            \"role\": \"user query\",\n            \"content\": user_query,\n        },\n        {\n            \"role\": \"documentation\",\n            \"content\": json.dumps(docs),\n        },\n        {\n            \"role\": \"system\",\n            \"content\": \"Give a brief but complete answer to the user's query, staying as true as possible to the documentation SPECIALLY when dealing with code.\"\n        }\n    ]\n\n    answer = env.completion(model=MODEL, messages=prompt)\n    env.add_reply(answer)\n\nrun(env)\n</code></pre> <p>Note that we are embedding the retrieved documents directly into the model's prompt, so the AI can use them to generate a more context-aware response. Furthermore, notice that we are not using all the documents retrieved, but only the first six, to reduce the amount of tokens in the prompt, and filter out less relevant documents.</p>"},{"location":"agents/env/frameworks/","title":"Supported Packages","text":"<p>NEAR AI supports several framework configurations, each with its own set of Python packages. Here is an overview of available frameworks, the setting value, and descriptions:</p> Framework Setting Description Minimal <code>minimal</code> Basic essential packages - <code>DEFAULT</code> Standard <code>standard</code> More robust Agent Framework TypeScript <code>ts</code> For creating agents with TypeScript AgentKit <code>agentkit</code> For use with LangChain, LangGraph, or Coinbase's Agentkit <p>Need a package that is not currently supported?</p> <p>If you have a particular package that is not currently supported, you can reach out to the team to have it added:</p> <ul> <li>Open a PR -&gt; (Example)</li> <li>File an issue</li> <li>Ask in Telegram</li> </ul>"},{"location":"agents/env/frameworks/#framework-usage","title":"Framework Usage","text":"<p>To use a specific framework, specify it in your agent's <code>metadata.json</code>:</p> <pre><code>{\n  \"details\": {\n    \"agent\": {\n      \"framework\": \"standard\"  // or \"minimal\", \"ts\", \"agentkit\", etc.\n    }\n  }\n}\n</code></pre>"},{"location":"agents/env/frameworks/#framework-types","title":"Framework Types","text":"<p>Below are up-to-date package support for each framework as defined in NEAR AI's AWS Runner Frameworks settings.</p>"},{"location":"agents/env/frameworks/#minimal-framework","title":"Minimal Framework","text":"<pre><code># Minimal Base Framework\n# Default for NEAR AI Agents\n\n# AWS SDK for Python\n# https://github.com/boto/boto3\nboto3 &gt;= 1.35.3\n\n# Base58 encoding/decoding library\n# https://github.com/keis/base58\nbase58 == 2.1.1\n\n# Datadog tracing library\n# https://github.com/DataDog/dd-trace-py\nddtrace == 2.21.0\n\n# Ed25519 cryptographic signatures\n# https://github.com/warner/python-ed25519\ned25519 == 1.5\n\n# LiteLLM for unified LLM API access\n# https://github.com/BerriAI/litellm\nlitellm &gt;= 1.60.5\n\n# Loguru for better logging\n# https://github.com/Delgan/loguru\nloguru == 0.7.2\n\n# Model Context Protocol integration for LLM apps and external data sources and tools\n# https://github.com/modelcontextprotocol\nmcp\n\n# OpenAI Python client\n# https://github.com/openai/openai-python\nopenai == 1.66.2\n\n# Process and system utilities\n# https://github.com/giampaolo/psutil\npsutil &gt;= 5.9.5\n\n# Data validation using Python type annotations\n# https://github.com/pydantic/pydantic\npydantic &gt;=2.8.2\n\n# Python binding to the Networking and Cryptography library\n# https://github.com/pyca/pynacl\npynacl &gt;= 1.5.0\n\n# NEAR Protocol Python SDK\n# https://github.com/pvolnov/py-near\npy-near &gt;= 1.1.50\n\n# Python dateutil for handling dates and times\n# https://github.com/dateutil/dateutil\npython_dateutil &gt;= 2.5.3\n\n# World timezone definitions\n# https://github.com/stub42/pytz\npytz == 2024.2\n\n# Package development tools\n# https://github.com/pypa/setuptools\nsetuptools &gt;= 21.0.0\n\n# Retry logic with exponential backoff\n# https://github.com/jd/tenacity\ntenacity == 9.0.0\n\n# Twitter API wrapper\n# https://github.com/tweepy/tweepy\ntweepy &gt;= 4.14.0\n\n# Type hinting support\n# https://github.com/python/typing_extensions\ntyping-extensions &gt;= 4.7.1\n\n# HTTP client\n# https://github.com/urllib3/urllib3\nurllib3 &gt;= 1.25.3, &lt; 2.1.0\n</code></pre>"},{"location":"agents/env/frameworks/#standard-framework","title":"Standard Framework","text":"<pre><code># Standard Web Agent Framework\n# Extended framework for web-enabled NEAR AI Agents\n\n# Asynchronous HTTP client/server framework\n# https://github.com/aio-libs/aiohttp\naiohttp==3.11.0b0\n\n# Base58 encoding/decoding library\n# https://github.com/keis/base58\nbase58 == 2.1.1\n\n# AWS SDK for Python\n# https://github.com/boto/boto3\nboto3 &gt;= 1.35.3\n\n# Borsh serialization format implementation\n# https://github.com/near/borsh-construct-py\nborsh-construct\n\n# Beautiful Soup for HTML parsing\n# https://pypi.org/project/beautifulsoup4/\nbs4\n\n# Character encoding detection\n# https://github.com/chardet/chardet\nchardet\n\n# Cryptography library for secure encryption\n# https://github.com/pyca/cryptography\ncryptography==44.0.2\n\n# Datadog tracing library\n# https://github.com/DataDog/dd-trace-py\nddtrace == 2.21.0\n\n# Ed25519 cryptographic signatures\n# https://github.com/warner/python-ed25519\ned25519 == 1.5\n\n# Account abstraction library for web3.py\n# https://github.com/ethereum/eth-account\neth-account &gt;= 0.13.5\n\n# Google Search API wrapper\n# https://github.com/Nv7-GitHub/googlesearch\ngooglesearch-python &gt;= 1.2.5\n\n# LiteLLM for unified LLM API access\n# https://github.com/BerriAI/litellm\nlitellm &gt;= 1.60.5\n\n# Loguru for better logging\n# https://github.com/Delgan/loguru\nloguru == 0.7.2\n\n# Mutagen for audio/video metadata extraction\n# https://github.com/quodlibet/mutagen\nmutagen==1.47.0\n\n# NumPy for numerical computing\n# https://github.com/numpy/numpy\nnumpy &gt;= 1.21.0\n\n# OpenAI Python client\n# https://github.com/openai/openai-python\nopenai == 1.66.2\n\n# Pillow for image processing\n# https://github.com/python-pillow/Pillow\nPillow==11.2.1\n\n# Process and system utilities\n# https://github.com/giampaolo/psutil\npsutil &gt;= 5.9.5\n\n# Data validation using Python type hints\n# https://github.com/pydantic/pydantic\npydantic==2.9.2\n\n# Python binding to the Networking and Cryptography library\n# https://github.com/pyca/pynacl\npynacl &gt;= 1.5.0\n\n# NEAR Protocol Python SDK\n# https://github.com/pvolnov/py-near\npy-near &gt;= 1.1.50\n\n# Multibase encoding\n# https://github.com/multiformats/py-multibase\npy-multibase==1.0.3\n\n# Multicodec encoding\n# https://github.com/multiformats/py-multicodec\npy-multicodec==0.2.1\n\n# Python dateutil for handling dates and times\n# https://github.com/dateutil/dateutil\npython_dateutil &gt;= 2.5.3\n\n# World timezone definitions\n# https://github.com/stub42/pytz\npytz == 2024.2\n\n# PDF file manipulation\n# https://github.com/py-pdf/pypdf\nPyPDF2\n\n# PDF file creation and manipulation\n# https://docs.reportlab.com/\nreportlab\n\n# Package development tools\n# https://github.com/pypa/setuptools\nsetuptools &gt;= 21.0.0\n\n# Retry logic with exponential backoff\n# https://github.com/jd/tenacity\ntenacity == 9.0.0\n\n# Twitter API wrapper\n# https://github.com/tweepy/tweepy\ntweepy &gt;= 4.14.0\n\n# Type hinting support\n# https://github.com/python/typing_extensions\ntyping-extensions &gt;= 4.7.1\n\n# HTTP client\n# https://github.com/urllib3/urllib3\nurllib3 &gt;= 1.25.3, &lt; 2.1.0\n\n# Web3.py for Ethereum interaction\n# https://github.com/ethereum/web3.py\nweb3 &gt;= 7.8.0\n\n# YouTube transcript API\n# https://github.com/jdepoix/youtube-transcript-api\nyoutube_transcript_api &gt;= 0.6.2\n</code></pre>"},{"location":"agents/env/frameworks/#typescript-framework","title":"TypeScript Framework","text":"<p>For use when creating TypeScript agents.</p> <pre><code># Minimal Base Framework\n# Default for NEAR AI Agents\n\n# AWS SDK for Python\n# https://github.com/boto/boto3\nboto3 &gt;= 1.35.3\n\n# Base58 encoding/decoding library\n# https://github.com/keis/base58\nbase58 == 2.1.1\n\n# Datadog tracing library\n# https://github.com/DataDog/dd-trace-py\nddtrace == 2.21.0\n\n# Ed25519 cryptographic signatures\n# https://github.com/warner/python-ed25519\ned25519 == 1.5\n\n# LiteLLM for unified LLM API access\n# https://github.com/BerriAI/litellm\nlitellm &gt;= 1.60.5\n\n# Loguru for better logging\n# https://github.com/Delgan/loguru\nloguru == 0.7.2\n\n# Model Context Protocol integration for LLM apps and external data sources and tools\n# https://github.com/modelcontextprotocol\nmcp\n\n# OpenAI Python client\n# https://github.com/openai/openai-python\nopenai == 1.66.2\n\n# Process and system utilities\n# https://github.com/giampaolo/psutil\npsutil &gt;= 5.9.5\n\n# Data validation using Python type annotations\n# https://github.com/pydantic/pydantic\npydantic &gt;=2.8.2\n\n# Python binding to the Networking and Cryptography library\n# https://github.com/pyca/pynacl\npynacl &gt;= 1.5.0\n\n# NEAR Protocol Python SDK\n# https://github.com/pvolnov/py-near\npy-near &gt;= 1.1.50\n\n# Python dateutil for handling dates and times\n# https://github.com/dateutil/dateutil\npython_dateutil &gt;= 2.5.3\n\n# World timezone definitions\n# https://github.com/stub42/pytz\npytz == 2024.2\n\n# Package development tools\n# https://github.com/pypa/setuptools\nsetuptools &gt;= 21.0.0\n\n# Retry logic with exponential backoff\n# https://github.com/jd/tenacity\ntenacity == 9.0.0\n\n# Twitter API wrapper\n# https://github.com/tweepy/tweepy\ntweepy &gt;= 4.14.0\n\n# Type hinting support\n# https://github.com/python/typing_extensions\ntyping-extensions &gt;= 4.7.1\n\n# HTTP client\n# https://github.com/urllib3/urllib3\nurllib3 &gt;= 1.25.3, &lt; 2.1.0\n</code></pre>"},{"location":"agents/env/frameworks/#agentkit-framework","title":"AgentKit Framework","text":"<p>For use with LangChain, LangGraph, or Coinbase's Agentkit</p> <pre><code># AgentKit Framework\n# For use with LangChain, LangGraph, or Coinbase's Agentkit\n\n# Base58 encoding/decoding library\n# https://github.com/keis/base58\nbase58 == 2.1.1\n\n# AWS SDK for Python\n# https://github.com/boto/boto3\nboto3 &gt;= 1.35.3\n\n# Coinbase SDK for crypto integration\n# https://github.com/coinbase/cdp-sdk-python\ncdp-sdk &gt;= 0.15.0\n\n# Coinbase AgentKit Integration\n# https://github.com/coinbase/agentkit\ncoinbase-agentkit &gt;= 0.4.0\n\n# LangChain integration for Coinbase AgentKit\n# https://github.com/coinbase/agentkit\ncoinbase-agentkit-langchain &gt;= 0.3.0\n\n# Datadog tracing library\n# https://github.com/DataDog/dd-trace-py\nddtrace == 2.21.0\n\n# DuckDuckGo search API\n# https://github.com/deedy5/duckduckgo_search\nduckduckgo-search &gt;= 7.3.0\n\n# Ed25519 cryptographic signatures\n# https://github.com/warner/python-ed25519\ned25519 == 1.5\n\n# LangChain Agent Development Framework\n# https://github.com/langchain-ai/langchain\nlangchain &gt;= 0.3.4\nlangchain-community &gt;= 0.3.16\nlangchain-openai &gt;= 0.2.4\n\n# LangGraph for agent orchestration\n# https://github.com/langchain-ai/langgraph\nlanggraph &gt;= 0.2.39\n\n# LiteLLM for unified LLM API access\n# https://github.com/BerriAI/litellm\nlitellm &gt;= 1.41.0\n\n# Loguru for better logging\n# https://github.com/Delgan/loguru\nloguru == 0.7.2\n\n# NEAR AI LangChain integration\n# https://github.com/nearai/nearai_langchain\nnearai-langchain &gt;= 0.0.13\n\n# Process and system utilities\n# https://github.com/giampaolo/psutil\npsutil &gt;= 5.9.5\n\n# Data validation using Python type annotations\n# https://github.com/pydantic/pydantic\npydantic &gt;=2.8.2\n\n# Python binding to the Networking and Cryptography library\n# https://github.com/pyca/pynacl\npynacl &gt;= 1.5.0\n\n# Python dateutil for handling dates and times\n# https://github.com/dateutil/dateutil\npython_dateutil &gt;= 2.5.3\n\n# World timezone definitions\n# https://github.com/stub42/pytz\npytz == 2024.2\n\n# NEAR Protocol Python SDK\n# https://github.com/pvolnov/py-near\npy-near &gt;= 1.1.50\n\n# Package development tools\n# https://github.com/pypa/setuptools\nsetuptools &gt;= 21.0.0\n\n# Twitter API\n# https://github.com/tweepy/tweepy\ntweepy &gt;= 4.14.0\n\n# Type hinting support\n# https://github.com/python/typing_extensions\ntyping-extensions &gt;= 4.7.1\n\n# HTTP client\n# https://github.com/urllib3/urllib3\nurllib3 &gt;= 1.25.3\n\n# Web3.py for Ethereum interaction\n# https://github.com/ethereum/web3.py\nweb3 &gt;= 7.6.0\n</code></pre>"},{"location":"agents/env/inference/","title":"Inference","text":"<p>The <code>completion</code> method is used to run a prompt on a specific model, using a specific provider.</p> <p>If only the prompt is provided, the inference will be run on the model and provider specified in the agent's metadata.</p> <pre><code>messages = env.list_messages()\nresult = env.completion(messages)\n\nprint(\"Messages:\", messages)\nprint(\"Result:\", result)\n</code></pre> Example Output <pre><code>Messages: [{'id': 'msg_1149aa85884b4fe8abc7d859', 'content': 'Hello', 'role': 'user'}]\n\nResult: Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\n</code></pre>"},{"location":"agents/env/inference/#generating-an-image","title":"Generating an Image","text":"<p>The <code>generate_image</code> method is used to generate an image based on the provided description.</p> <pre><code>description = \"A puppy in the garden\"\nimage = env.generate_image(description)\n\n# Extract the base64 data from the first item in `data`\nb64_data = image.data[0].b64_json\n\n# Decode the base64 image data\nimage_data = base64.b64decode(b64_data)\n\n# Write the image file\nimage_file = env.write_file(\"puppy_image.png\", image_data)\n</code></pre> <p>Agent Example</p> <p>Check out this Agent example to learn how to use <code>generate_image</code> in your AI agent logic.</p>"},{"location":"agents/env/inference/#overriding-the-default-model","title":"Overriding the Default Model","text":"<p>To run the inference on a model different from the default one, you can pass the <code>MODEL</code> or <code>PROVIDER::MODEL</code> as second argument:</p> <pre><code>messages = env.list_messages()\nresult = env.completion([prompt] + messages, \"fireworks::qwen2p5-72b-instruct\")\n</code></pre> Example Output <pre><code>Messages: [{'id': 'msg_1149aa85884b4fe8abc7d859', 'content': 'Hello', 'role': 'user'}]\n\nResult: Hello! How can I assist you today? Is there something specific you'd like to talk about or any questions you have?\n</code></pre> <p>Tip</p> <p><code>completions</code>: returns the full llm response for more control.</p> <p>Using Models Locally: LangChain / LangGraph</p> <p>The example agent langgraph-min-example has metadata that specifies the <code>langgraph-0-1-4</code> framework to run on langgraph version 1.4. In addition, the agent.py code contains an adaptor class, <code>AgentChatModel</code> that maps LangChain inference operations to <code>env.completions</code> calls.</p>"},{"location":"agents/env/messages_files/","title":"Messages and Files","text":"<p>Agents interact with the users through messages, and can also access and create files. This page provides an overview of how agents can work with messages and files.</p> Quick Overview <ul> <li>Each run of an agent is executed in a separate thread, which contains messages and files.</li> <li>The agent can access the messages in the current thread using <code>env.list_messages()</code>.</li> <li>The agent can save temporary files to track the progress of a task.</li> <li>By default, the entire message history is stored in a file named <code>chat.txt</code>. The agent can add messages there by using <code>env.add_reply()</code>.</li> <li>During its operation, the agent creates a file named <code>.next_agent</code>, which stores the role of the next participant expected in the dialogue (either <code>user</code> or <code>agent</code>) during the next iteration of the loop. The agent can control this value using <code>env.set_next_actor()</code>.</li> <li>The agent can use local imports from the home folder or its subfolders. It is executed from a temporary folder within a temporary environment.</li> </ul>"},{"location":"agents/env/messages_files/#thread-messages","title":"Thread Messages","text":"<p>The environment provides methods for agents to access and interact with the messages in the current thread. Messages are stored in a list, with each message containing an <code>id</code>, <code>content</code>, and <code>role</code> field.</p>"},{"location":"agents/env/messages_files/#accessing-messages","title":"Accessing Messages","text":"<p>Agents can access the messages from the current thread using the <code>list_messages</code> method:</p> agent.py<pre><code>def run(env: Environment):\n  messages = env.list_messages()\n  print(messages)\n</code></pre> Example Output <pre><code>[{'id': 'msg_9b676ae4ad324ca58794739d', 'content': 'Hi', 'role': 'user'},\n  {'id': 'msg_58693367bcee42669a85cb69', 'content': \"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", 'role': 'assistant'},\n  {'id': 'msg_16acda223c294213bc3c814e', 'content': 'help me decide how to decorate my house!', 'role': 'user'}]\n</code></pre>"},{"location":"agents/env/messages_files/#adding-messages","title":"Adding Messages","text":"<p>Agents can add new messages to the thread using the <code>add_reply</code> method:</p> agent.py<pre><code>def run(env: Environment):\n  env.add_reply(\"I have finished\")\n</code></pre>"},{"location":"agents/env/messages_files/#files","title":"Files","text":"<p>Agents have access to two types of files through the environment:</p> <ol> <li>Those created within the current conversation thread</li> <li>Those uploaded with the agent to the registry</li> </ol>"},{"location":"agents/env/messages_files/#storing-data","title":"Storing Data","text":"<p>To create a new file in the thread we can use the <code>write_file</code> method from the environment:</p> agent.py<pre><code>def run(env: Environment):\n  env.write_file('file.txt', 'hello thread')\n</code></pre> Where is the file stored? <p>When running the agent locally, a temporary folder will be created to store each thread data. We can check exactly where the file is stored by using the <code>python debugger</code>:</p> agent.py<pre><code>def run(env: Environment):\n  env.write_file('file.txt', 'hello thread')\n  import ipdb; ipdb.set_trace()  # Call the ipdb debugger\n</code></pre> <p>After running the agent, we will be dropped into the debugger, where we can check the current working directory:</p> <pre><code>nearai agent interactive ~/.nearai/registry/&lt;your-account.near&gt;/hello-ai/0.0.1 --local --thread_id thread_43c64803c0a948bc9a8eb8e8\n\nipdb&gt; import os; os.getcwd() # Check the current working directory\n'/private/var/folders/v6/pw4e3e3r5t6h8i9oihtd9d7d1234df/T/agent_7e312s678b987sa4vc4s2zxs2s1w1345'\n</code></pre> <p>We can see that the current working directory is a temporary folder. Go ahead and start the <code>agent</code> again without the <code>--thread_id</code> parameter, you will see that the working directory changes.</p>"},{"location":"agents/env/messages_files/#accessing-files","title":"Accessing Files","text":"<p>To list the files in the thread storage, we can use the <code>list_files_from_thread</code> method from the environment:</p> agent.py<pre><code>def run(env: Environment):\n  files = env.list_files_from_thread()\n  content = env.read_file('file.txt')\n\n  print('Files:', files)\n  print('Content of file.txt:', content)\n</code></pre> Example Output <pre><code>Files [FileObject(id='file_31aab645e3214a13b402e321', bytes=12, created_at=1734733634, filename='file.txt', object='file', purpose='assistants', status='uploaded', status_details='File information retrieved successfully')]\n\nContent of file.txt hello thread\n</code></pre>"},{"location":"agents/env/messages_files/#logging","title":"Logging","text":"<p>You can turn on agent logging by passing an environment variable of <code>DEBUG</code> with a value of true.  In the UI this is set on the Run page of an agent while logged in as the agent author. Once this is set,  logs from either of the methods below will be written to the thread. The 'show logs' button (next to send message) toggles whether the logs show in the thread.</p> <ul> <li><code>add_system_log</code>: adds a system or environment log that is then saved into \"system_log.txt\".</li> <li><code>add_agent_log</code>: any agent logs may go here. Saved into \"agent_log.txt\".</li> </ul>"},{"location":"agents/env/near/","title":"NEAR Blockchain","text":""},{"location":"agents/env/near/#interacting-with-near-blockchain","title":"Interacting with NEAR Blockchain","text":"<p>The NEAR AI toolkit provides environment methods for interacting with the NEAR blockchain. This framework is designed for seamless integration using a private RPC when running an agent on a NEAR AI hosted runner.</p>"},{"location":"agents/env/near/#features","title":"Features","text":"<ul> <li>Private RPC Integration: NEAR AI provides a private RPC for agents to interact with the NEAR blockchain. This private RPC is optimized for both read operations (e.g., querying contract states) and write operations (e.g., sending transactions or modifying contract state). It ensures secure and reliable communication between hosted agents and the NEAR network, reducing latency and improving overall performance.</li> <li>Retry Mechanism: Both view and call methods include a robust retry mechanism to handle transient network or RPC errors.</li> </ul>"},{"location":"agents/env/near/#setting-up-the-near-account","title":"Setting Up the Near Account","text":"<pre><code>near = env.set_near(account_id, private_key)\n</code></pre> <p>This creates you an Account object from the <code>py-near</code> Python library. More details: py-near Account</p> <p>Important</p> <p>Ensure that the <code>account_id</code>and <code>private_key</code> are never exposed in plain text within the agent's code. We recommend using secrets to handle these credentials securely.</p> <p>Parameters: - <code>account_id</code>: The NEAR account ID (e.g., \"example.near\") that will act as the account for interactions - <code>private_key</code>: The private key associated with the account_id - <code>rpc_addr</code>: (Optional) A custom RPC address for connecting to the NEAR network. If not provided, the default NEAR RPC address is used.</p> <ul> <li>Example: <pre><code>near = env.set_near(\"account.near\", \"ed25519:3ABCD...XYZ\")\n</code></pre></li> </ul> <p>Once called, the <code>near</code> object is ready for use. Note that <code>near.view</code> can be used without providing to <code>env.set_near()</code> <code>account_id</code> or <code>private_key</code>.</p>"},{"location":"agents/env/near/#near-view-method","title":"NEAR VIEW Method","text":"<p>Performs a read-only operation on the NEAR blockchain. This is used to query the state of a contract without modifying it. Examples include retrieving contract states, or querying other read-only data.</p> <p>The result object contains the transaction details, including the logs and block hash, and any returned values. For more details on the format of the result object, refer to the py-near documentation.</p> <pre><code>near = env.set_near()\nawait near.view(\n    contract_id: str,\n    method_name: str,\n    args: dict,\n    block_id: Optional[int] = None,\n    threshold: Optional[int] = None,\n    max_retries: int = 3\n)\n</code></pre> <p>Parameters: - <code>contract_id</code>: The NEAR account ID of the smart contract you want to query. - <code>method_name</code>: The name of the view method to call on the contract. - <code>args</code>: A dictionary of arguments to pass to the view method. - <code>block_id</code>: (Optional) The block ID to query. Defaults to the latest block. - <code>threshold</code>: (Optional) A threshold parameter for advanced queries. - <code>max_retries</code>: (Optional) The maximum number of retry attempts in case of transient errors (default is 3, max is 10).</p> <p>Returns: - The result of the view method call, typically containing the queried data.</p> <p>Example: <pre><code>near = env.set_near()\nresult = await near.view(\n    contract_id=\"wrap.near\",\n    method_name=\"ft_balance_of\",\n    args={\n        \"account_id\": \"user.near\"\n    }\n)\n\nprint(\"Wrap.NEAR Balance:\", result.result)\n</code></pre></p>"},{"location":"agents/env/near/#near-call-method","title":"NEAR CALL Method","text":"<p>Executes a state-changing operation on the NEAR blockchain. This is used to call methods on contracts that can modify state, transfer tokens, or perform other operations requiring gas and/or attached tokens.</p> <p>The result object contains the transaction details, including the status, transaction hash, and any returned values. For more details on the format of the result object, refer to the py-near documentation.</p> <pre><code>near = env.set_near(\"user.near\", \"ed25519:3ABCD...XYZ\")\nawait near.call(\n    contract_id: str,\n    method_name: str,\n    args: dict,\n    gas: int = DEFAULT_ATTACHED_GAS,\n    amount: int = 0,\n    nowait: bool = False,\n    included: bool = False,\n    max_retries: int = 3\n)\n</code></pre> <p>Parameters: - <code>contract_id</code>: The NEAR account ID of the smart contract you want to call. - <code>method_name</code>: The name of the method to invoke on the contract. - <code>args</code>: A dictionary of arguments to pass to the method. - <code>gas</code>: (Optional) The amount of gas to attach for execution (default: DEFAULT_ATTACHED_GAS).  - <code>amount</code>: (Optional) The amount of NEAR tokens to attach to the transaction (default: 0).  - <code>nowait</code>: (Optional) If True, the call will not wait for transaction confirmation.  - <code>included</code>: (Optional) If True, ensures the transaction is included in the block before returning. - <code>max_retries</code>: (Optional) The maximum number of retry attempts in case of transient errors (default is 3, max is 10). Use this parameter only if necessary, as there is a risk that the transaction might be sent multiple times.</p> <p>Returns: - The result of the contract method call, including transaction details and status.</p> <p>Example: <pre><code>result = await env.near.call(\n    contract_id=\"wrap.near\",\n    method_name=\"ft_transfer\",\n    args={\n        \"receiver_id\": \"example.near\",\n        \"amount\": \"1000000\"\n    },\n    gas=30000000000000,\n    amount=1\n)\n\nif \"SuccessValue\" in result.status:\n    print(\"tx\", result.transaction.hash)\n</code></pre></p>"},{"location":"agents/env/near/#near-get-balance","title":"NEAR GET BALANCE","text":"<p><code>get_balance</code> retrieves the NEAR token balance of a given account. </p> <p>Parameters: - <code>account_id</code> : (Optional) The ID of the account to retrieve the balance for. If not provided, the balance of the current account is retrieved.</p> <p>Example: <pre><code>near = env.set_near(\"alice.near\")\nprint(await near.get_balance())\nprint(await near.get_balance(\"bob.near\"))\n</code></pre></p>"},{"location":"agents/env/overview/","title":"The Environment Object","text":"<p>Each time an agents executes it receives an environment, which gives it access to features such as:</p> <ul> <li>Retrieve messages in the conversation, both from the user and the agent</li> <li>Request input from the user</li> <li>Read and write files on the agent's storage</li> <li>Call other agents</li> </ul>"},{"location":"agents/env/overview/#available-variables","title":"Available variables","text":"<ul> <li><code>signer_account_id</code>: get the NEAR Account ID of the signer </li> </ul>"},{"location":"agents/env/tools/","title":"Tools &amp; Commands","text":"<p>NEAR AI supports function based tool calling where the LLM can decide to call one of the functions (Tools) that you pass it. You can register your own function or use any of the built-in tools (list_files, read_file, write_file, exec_command, query_vector_store, request_user_input).</p> <p>The tool registry supports OpenAI style tool calling and Llama style. When a llama model is explicitly passed to completion(s)_and_run_tools a system message is added to the conversation. This system message contains the tool definitions and instructions on how to invoke them  using <code>&lt;function&gt;</code> tags.</p> <p>To tell the LLM about your tools and automatically execute them when selected by the LLM, call one of these environment methods:</p> <ul> <li><code>completion_and_run_tools</code>: Allows tools to be passed and processes any returned tool_calls by running the tool</li> <li><code>completions_and_run_tools</code>: Handles tool calls and returns the full llm response.</li> <li><code>completion_and_get_tools_calls</code>: Returns completion message and/or tool calls from OpenAI or Llama tool formats.</li> </ul> <p>By default, these methods will add both the LLM response and tool invocation responses to the message list.  You do not need to call <code>env.add_message</code> for these responses. This behavior allows the LLM to see its call then tool responses in the message list on the next iteration or next run.  This can be disabled by passing <code>add_to_messages=False</code> to the method.</p>"},{"location":"agents/env/tools/#registering-tools","title":"Registering Tools","text":"<ul> <li><code>get_tool_registry</code>: returns the  tool registry, a dictionary of tools that can be called by the agent. By default it is populated with the tools listed above for working with files and commands plus [<code>request_user_input</code>] (../../api.md#nearai.agents.environment.Environment.request_user_input). To register a function as a new tool, call <code>register_tool</code> on the tool registry, passing it your function.</li> </ul> <p>The tool registry provides two ways to register tools:</p> <ol> <li> <p>Using <code>register_tool</code> for regular Python functions/callables: <pre><code>def my_tool():\n    \"\"\"A simple tool that returns a string. This docstring helps the LLM know when to call the tool.\"\"\"\n    return \"Hello from my tool\"\n\ntool_registry = env.get_tool_registry()\ntool_registry.register_tool(my_tool)\ntool_def = tool_registry.get_tool_definition('my_tool')\nresponse = env.completions_and_run_tools(messages, tools=[tool_def])\n</code></pre></p> </li> <li> <p>Using <code>register_mcp_tool</code> for MCP tools: <pre><code>from nearai.agents.models.tool_definition import MCPTool\n\nmcp_tool = MCPTool(\n    name=\"weather\",\n    description=\"Get the current weather in a location\",\n    inputSchema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and state, e.g. San Francisco, CA\"\n            }\n        },\n        \"required\": [\"location\"]\n    }\n)\n\nasync def call_weather_api(name: str, args: dict):\n    # Implementation of the weather API call\n    return f\"Weather in {args['location']}: Sunny\"\n\ntool_registry.register_mcp_tool(mcp_tool, call_weather_api)\n</code></pre></p> </li> </ol> <p>To pass all the built in tools plus any you have registered use the <code>get_all_tool_definitions</code> method. <pre><code>all_tools = env.get_tool_registry().get_all_tool_definitions()\nresponse = env.completions_and_run_tools(messages, tools=all_tools)\n</code></pre> If you do not want to use the built-in tools, use <code>get_tool_registry(new=True)</code> <pre><code>    tool_registry = env.get_tool_registry(new=True)\n    tool_registry.register_tool(my_tool)\n    tool_registry.register_tool(my_tool2)\n    response = env.completions_and_run_tools(messages, tools=tool_registry.get_all_tool_definitions())\n</code></pre></p>"},{"location":"agents/env/tools/#terminal-commands","title":"Terminal Commands","text":"<p>Agents have access to the local terminal through the environment, the following methods are available:</p> Method Description <code>list_terminal_commands()</code> Lists the history of terminal commands executed by the agent <code>exec_command(command)</code> Executes the terminal <code>command</code> and returns the output"},{"location":"agents/env/variables/","title":"Secrets &amp; Environment Variables","text":"<p>NEAR AI's environment variable system lets you securely manage configuration and sensitive data for your agents. Both agent developers and users can easily configure variables without modifying the agent's code. </p>"},{"location":"agents/env/variables/#key-features","title":"Key Features","text":"<ul> <li>Flexible variable management: Set and manage variables as agent authors or users</li> <li>Hierarchical variable resolution: Users can override agent variables and secrets</li> <li>NEAR wallet-based authentication: Only authorized users can set and get secrets</li> </ul>"},{"location":"agents/env/variables/#public-variables","title":"Public Variables","text":"<p>Public variables are configuration values that are visible in code and metadata. </p>"},{"location":"agents/env/variables/#agent-public-variables","title":"Agent Public Variables","text":"<p>Agent public variables are defined by by the agent author in the agent's <code>metadata.json</code> file:</p> <pre><code>{\n  \"details\": {\n    \"env_vars\": {\n      \"API_ENDPOINT\": \"https://api.example.com\",\n    }\n  }\n}\n</code></pre>"},{"location":"agents/env/variables/#user-public-variables","title":"User Public Variables","text":"<p>User public variables are set by users via the CLI or URL parameters.</p> <pre><code># Via CLI\nnearai agent run my-agent --env_vars='{\"CUSTOM_ENDPOINT\":\"https://api.custom.com\"}'\n\n# Via URL parameters\nhttps://app.near.ai/agents/casino.near/game/1?refId=ad.near\n</code></pre>"},{"location":"agents/env/variables/#private-variables-secrets","title":"Private Variables (Secrets)","text":"<p>These are private variables that are securely stored and never exposed in agent code.</p>"},{"location":"agents/env/variables/#agent-secrets","title":"Agent Secrets","text":"<ul> <li>Set by agent authors</li> <li>Scoped to specific agent versions (ex: <code>v0.0.1</code> vs <code>v0.0.2</code>)</li> </ul>"},{"location":"agents/env/variables/#user-secrets","title":"User Secrets","text":"<ul> <li>Set by users for specific agents</li> <li>Can override agent secrets</li> <li>Accessible only to authorized runners</li> </ul>"},{"location":"agents/env/variables/#how-variables-are-merged","title":"How Variables are Merged","text":"<p>It's important to note that at runtime both agent author and user environment variables and secrets are merged into a single <code>env_vars</code> object. </p> <p>If there are conflicting variables with the same name, user variables will take precedence. This enables agent users to easily override any default value or secret set by the agent author such as an API key or API endpoint.</p> <p>Priority Order</p> <p>Variables are merged with this priority (highest to lowest), ultimately user variables take precedence:</p> <ol> <li>User Public Variables (CLI/URL Params)</li> <li>User Secrets</li> <li>Agent Secrets</li> <li>Agent Public Variables (metadata.json)</li> </ol> <p><code>Example</code>:</p> <pre><code># Given these variables:\nagent_secrets = {\"API_KEY\": \"agent-key\"}\nagent_public = {\"API_KEY\": \"metadata-key\"}\nuser_secrets = {\"API_KEY\": \"user-key\"}\nuser_public = {\"API_KEY\": \"cli-key\"}\n\n# Your agent sees:\nenv.env_vars[\"API_KEY\"] == \"cli-key\"  # Highest priority wins\n</code></pre>"},{"location":"agents/env/variables/#using-variables-in-agent-code","title":"Using Variables in Agent Code","text":"<p>Using variables in your agent is straightforward. You can access any variable in your agent code  using Python\u2019s os module or by accessing the <code>env_vars</code> dictionary directly using the <code>env.env_vars</code> object.</p> <p><code>Examples</code>:</p> <pre><code># Access any variable\napi_key = env.env_vars.get('VARIABLE_NAME', 'default-value')\n\n# Using env.env_vars\nvalue = env.env_vars.get('VARIABLE_NAME', 'default_value')\n\n# Using os.environ\nimport os\nvalue = os.environ.get('VARIABLE_NAME', 'default_value')\n\n# Or using globals()\nvalue = globals()['env'].env_vars.get('VARIABLE_NAME', 'default_value')\n</code></pre> <p>You can also check if a variable exists:</p> <pre><code>if 'VARIABLE_NAME' in env.env_vars:\n    # Use API key\n    api_key = env.env_vars['VARIABLE_NAME']\n</code></pre>"},{"location":"agents/env/variables/#managing-secrets","title":"Managing Secrets","text":"<p>All secret variables are managed through the NEAR AI platform and require a NEAR account to access. This ensures that only authorized users can access sensitive information and that the variables are stored securely. </p> <p>You can manage these secrets at a lower level by using the secrets API, but the NEAR AI Developer Hub provides a more user-friendly interface for managing these variables.</p>"},{"location":"agents/env/variables/#using-developer-hub","title":"Using Developer Hub","text":"<p>The easiest way to manage variables is through app.near.ai:</p> <ol> <li>Select your agent</li> <li>Click the \"Run\" tab</li> <li>Under \"Environment Variables\":<ul> <li>Click \"+\" to add new variable</li> <li>Enter key-value pair</li> <li>Choose visibility (public/private)</li> </ul> </li> </ol> <p></p>"},{"location":"agents/env/variables/#using-cli","title":"Using CLI","text":"<p>Local Development Only</p> <p>For local development and testing only as the CLI does not upload secret variables to the NEAR AI platform. </p> <p>Also note that using <code>--env_vars</code> flag only works for a single run.</p> <pre><code># Set variables for a single run\nnearai agent interactive &lt;AGENT-PATH&gt; --env_vars='{\"API_KEY\":\"sk-...\",\"ENDPOINT\":\"https://api.custom.com\"}'\n</code></pre>"},{"location":"agents/env/variables/#secrets-api","title":"Secrets API","text":"<p>For programmatic management of secrets, you can use the following API endpoints:</p> Endpoint Method Description <code>/v1/get_user_secrets</code> GET Retrieve user secrets <code>/v1/create_hub_secret</code> POST Create a new secret <code>/v1/remove_hub_secret</code> POST Delete an existing secret"},{"location":"agents/env/variables/#get-v1get_user_secrets","title":"<code>GET /v1/get_user_secrets</code>","text":"<p>Retrieves secrets belonging to the authenticated user. (via <code>owner_namespace</code>)</p> <p>Params:</p> <ul> <li><code>limit</code>: Optional (default: 100)</li> <li><code>offset</code>: Optional (default: 0)</li> </ul> <p>Example Request:</p> <pre><code>curl -X GET \"https://&lt;api-url&gt;/v1/get_user_secrets?limit=10&amp;offset=0\" \\\n  -H \"Authorization: Bearer &lt;YOUR-NEAR-AUTH-TOKEN&gt;\"\n</code></pre> Example response <pre><code>[\n  {\n    \"id\": 123,\n    \"owner_namespace\": \"your_account.near\",\n    \"namespace\": \"example_agent\",\n    \"name\": \"my_secret_name\",\n    \"version\": \"1.0\",\n    \"key\": \"GITHUB_API_TOKEN\",\n    \"category\": \"agent\",\n    \"created_at\": \"2025-02-19T12:34:56.789Z\",\n    \"updated_at\": \"2025-02-19T12:34:56.789Z\"\n  }\n]\n</code></pre>"},{"location":"agents/env/variables/#post-v1create_hub_secret","title":"<code>POST /v1/create_hub_secret</code>","text":"<p>Creates a new secret for the authenticated user.</p> <p>Secrets are tied to:</p> <ul> <li>A specific version</li> <li>A category, such as \"agent\" or \"user\" (default is \"agent\")</li> </ul> <p>Example Request Body:</p> <pre><code>{\n  \"namespace\": \"string\",      // Required\n  \"name\": \"string\",           // Required\n  \"version\": \"string\",        // Optional\n  \"description\": \"string\",    // Optional\n  \"key\": \"string\",            // Required\n  \"value\": \"string\",          // Required\n  \"category\": \"string\"        // Optional (default: \"agent\")\n}\n</code></pre> <p>Example Request:</p> <pre><code>curl -X POST \"https://&lt;api-url&gt;/v1/create_hub_secret\" \\\n  -H \"Authorization: Bearer &lt;YOUR-NEAR-AUTH-TOKEN&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"namespace\": \"example_agent\",\n    \"name\": \"my_secret_name\",\n    \"version\": \"0.0.1\",\n    \"description\": \"GitHub token for my agent\",\n    \"key\": \"GITHUB_API_TOKEN\",\n    \"value\": \"ghp_abc123\",\n    \"category\": \"agent\"\n  }'\n</code></pre> <p>Example Response:</p> <pre><code>true\n</code></pre>"},{"location":"agents/env/variables/#post-v1remove_hub_secret","title":"<code>POST /v1/remove_hub_secret</code>","text":"<p>Deletes an existing secret.</p> <p>Example Request Body:</p> <pre><code>{\n  \"namespace\": \"string\",  // Required\n  \"name\": \"string\",       // Required\n  \"version\": \"string\",    // Optional\n  \"key\": \"string\",        // Required\n  \"category\": \"string\"    // Optional (default: \"agent\")\n}\n</code></pre> <p>Example Request:</p> <pre><code>curl -X POST \"https://&lt;api-url&gt;/v1/remove_hub_secret\" \\\n  -H \"Authorization: Bearer &lt;YOUR-NEAR-AUTH-TOKEN&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"namespace\": \"example_agent\",\n    \"name\": \"my_secret_name\",\n    \"version\": \"1.0\",\n    \"key\": \"GITHUB_API_TOKEN\",\n    \"category\": \"agent\"\n  }'\n</code></pre> <p>Example Response:</p> <pre><code>true\n</code></pre>"},{"location":"agents/env/variables/#security-authentication","title":"Security &amp; Authentication","text":"<p>The management of secret variables on the NEAR AI platform requires authentication via a NEAR account to ensure that only authorized users can access sensitive information.</p> <p>Both the NEAR AI CLI &amp; Developer Hub require logging in with a NEAR account and then abstract away the auth token creation process by signing a message with your NEAR wallet. At a low level this authentication is handled by creating an <code>auth_token</code> from a signed message which is then passed to all Secret API requests.</p> <p><code>Example</code>:</p> <pre><code>// Authentication flow\nconst signature = await wallet.signMessage({\n    message: messageToSign,\n    recipient: \"ai.near\",\n    nonce: generateNonce(),  // 32-byte random nonce\n});\n\nconst authToken = {\n    account_id: wallet.accountId,\n    public_key: wallet.publicKey,\n    signature: signature,\n    message: messageToSign,\n    nonce: nonce,\n    recipient: \"ai.near\"\n};\n</code></pre>"},{"location":"agents/env/variables/#security-model","title":"Security Model","text":"<ol> <li> <p>Access Control</p> <ul> <li>Variables are scoped to specific agents/users</li> <li>Each agent only sees its own variables</li> <li>User variables override agent variables</li> </ul> </li> <li> <p>Request Security</p> <ul> <li>All requests require NEAR wallet signature</li> <li>Nonces prevent replay attacks</li> <li>Rate limiting on failed attempts</li> <li>Request logging and monitoring</li> </ul> </li> </ol> <p>Security Best Practices</p> <ul> <li>Never commit secrets to source code</li> <li>Use descriptive key names</li> <li>Validate required variables exist</li> <li>Handle API errors gracefully</li> <li>Cache secret existence checks</li> <li>For use cases that need higher security secret handling, run your agent in a TEE and verify the TEE quote attestation (docs coming soon).</li> </ul>"},{"location":"agents/examples/overview/","title":"NEAR AI Agent Examples","text":"<p>Below you will find a list of easy-to-use agent templates as well as more comprehensive agent examples you can review, modify, and deploy.</p>"},{"location":"agents/examples/overview/#agent-templates","title":"Agent Templates","text":"<p>Ready-to-use Agent Templates to quickly get started.</p> Template Description Link NEAR Blockchain Agent that can view and perform transactions on the NEAR Blockchain. View Twitter / X Agent that listens for and responds to twitter mentions. View AgentKit For use with Langchain, LangGraph, &amp; Coinbase's Agentkit View TypeScript Create an AI agent using TypeScript. View <p>Info</p> <p></p> <p>You can deploy these templates right from the NEAR AI App. </p> <p>Just click the plus sign in the upper right hand corner. </p>"},{"location":"agents/examples/overview/#agent-examples","title":"Agent Examples","text":"<p>Community created agent examples to help you understand how to build on NEAR AI and showcase what's possible.</p>"},{"location":"agents/examples/overview/#general-purpose-agents","title":"General Purpose Agents","text":"Example Description Link Category AI Product Manager Agent that helps with product management tasks View Productivity Image Processing Agent for handling and processing images View Images Agent Builder Agent that can build other agents View Coding Shopping Agent Agent for shopping and product recommendations View E-commerce"},{"location":"agents/examples/overview/#blockchain-enabled-agents","title":"Blockchain Enabled Agents","text":"Example Description Link Linkdrop Agent Agent for creating and managing linkdrops View AI AMM AI-powered Automated Market Maker Agent View AMM Agent Automated Market Maker Agent View Memecoin Creation Agent for creating and managing memecoins View <ul> <li>For more examples, see NEAR AI Official Agents.</li> </ul> <p>Getting Started</p> <p>New to NEAR AI? Check out our quickstart guide to get up and running with your first agent.</p>"},{"location":"agents/patterns/agent_to_agent/","title":"Agent to Agent Communication","text":"<p>Tip</p> <p>You may not need to call other agents. See Orchestrating multiple agents for more information.</p> <p>Agents can call other agents to interact with them using the <code>run_agent</code> method. To call an agent, provide the agent's id. Optionally, a query can be passed to the agent.</p> <p>Example:</p> <pre><code>result = env.run_agent(\"travel.near/travel-agent/latest\", query=\"Plan a two-day trip to Buenos Aires\")\nprint(result)\n\n# result\n$ thread_312f2ea5e42742c785218106\n</code></pre> <p>The result of <code>run_agent</code> is a string containing the <code>thread_id</code> where the external agent executed.</p> <p>Shared Environment</p> <p>With the <code>SAME</code> and <code>FORK</code> thread modes below the agent being called will receive the thread,  meaning it can access all the messages and files from the current conversation.  Moreover, the called agent will be able to add messages and files to the current thread.</p>"},{"location":"agents/patterns/agent_to_agent/#thread-mode","title":"Thread Mode","text":"<p>The <code>run_agent</code> method has an optional <code>thread_mode</code> parameter to control whether the called agent should  write to: the same thread (ThreadMode.SAME), a forked thread (ThreadMode.FORK), or a child thread (ThreadMode.CHILD). By default, <code>thread_mode</code> is set to <code>ThreadMode.FORK</code>. <code>ThreadMode.SAME</code> causes the called agent to write to the current thread. <code>ThreadMode.FORK</code> creates a new thread for the called agent and copies all messages and files from the current thread. <code>ThreadMode.CHILD</code> creates a new thread for the called agent and copies only the value of the <code>query</code> parameter to the new thread.</p>"},{"location":"agents/patterns/agent_to_agent/#run-mode-experimental","title":"Run Mode (Experimental)","text":"<p>The <code>run_agent</code> method has an optional <code>run_mode</code> parameter to control whether the calling agent should be called again after the called agent finishes. By default, <code>run_mode</code> is set to <code>RunMode.SIMPLE</code>. <code>RunMode.SIMPLE</code> calls the agent once. <code>RunMode.WITH_CALLBACK</code> calls the calling agent again after the called agent finishes. This is designed to be used with  <code>ThreadMode.CHILD</code>.</p> <p>To use RunMode.WITH_CALLBACK, the calling agent MUST check whether it was called on the parent thread or the child thread. This can be done by fetching the current thread with <code>env.get_thread()</code> and checking whether it has a <code>parent_thread_id</code>.</p> <p></p> <p>When a thread is forked, the agent we are calling will work on a copy of the thread, meaning that they have access to all files and messages created so far, but any message or file they create will be part of their own thread.</p> <p>With ThreadMode.SAME, the called agent will work in the same thread as the current agent, meaning that they have access to all files and messages created so far, and any message or file they create will be part of the current thread.</p>"},{"location":"agents/patterns/agent_to_agent/#schedule-a-run","title":"Schedule a run","text":"<p>Agents can schedule a run for a later time using the <code>schedule_run</code> method. The scheduled run will be executed  by the scheduler using hub credentials.</p>"},{"location":"agents/patterns/agent_triggers/","title":"Agent Triggers","text":"<p>Agents can be triggered by having them listen to a named event source.</p>"},{"location":"agents/patterns/agent_triggers/#twitter-x","title":"Twitter (X)","text":"<p>NearAI maintains a read-only Twitter interface that can be used to trigger agents under certain conditions. </p>"},{"location":"agents/patterns/agent_triggers/#the-x_mentions-event-source","title":"The x_mentions event source","text":"<p>The <code>x_mentions</code> event source produces an event when a configured account is mentioned.</p> <p>To have an agent listen for mentions, create trigger metadata in the agent's metadata.json file as in the example below.</p> <p>To trigger an agent, mention the X account configured in the metadata.json. The agent will be invoked.</p> <pre><code>{\n  \"name\": \"near-secret-agent\",\n  \"version\": \"0.0.1\",\n  \"description\": \"An example agent that responds to Twitter mentions\",\n  \"category\": \"agent\",\n  \"tags\": [\"twitter\"],\n  \"details\": {\n    \"agent\": {\n      \"welcome\": {\n        \"title\": \"No chat interface\",\n        \"description\": \"To use tweet a message and mention @nearsecretagent.\"\n      },\n      \"defaults\": {\n        \"max_iterations\": 1,\n        \"model\": \"llama-v3p2-3b-instruct\",\n        \"model_provider\": \"fireworks\",\n        \"model_temperature\": 0.0,\n        \"model_max_tokens\": 1000\n      }\n    },\n    \"triggers\": {\n      \"events\" : {\n        \"x_mentions\": [\"@nearsecretagent\"]\n      }\n    }\n  },\n  \"show_entry\": true\n}\n</code></pre>"},{"location":"agents/patterns/agent_triggers/#posting-to-twitter-x","title":"Posting to Twitter (X)","text":"<p>To allow your agent to post to X you will need your own developer api key. Free X developer accounts have low read limits but fairly high write limits.</p> <p>NearAI Runners include the <code>tweepy</code> library, which supports several ways to authenticate with X https://docs.tweepy.org/en/stable/authentication.html</p> <p>The example agent https://app.near.ai/agents/flatirons.near/near-secret-agent/latest/source uses 3 legged Oauth to  authorize an X account other than the developer account to post through the api as described here in the twitter docs. To accomplish this it has four secrets set on the agent: X_ACCESS_TOKEN, X_ACCESS_TOKEN_SECRET, X_CONSUMER_KEY, X_CONSUMER_SECRET.</p>"},{"location":"agents/patterns/near_events/","title":"Running Agents Based on Events from the NEAR Blockchain","text":""},{"location":"agents/patterns/near_events/#overview","title":"Overview","text":"<p>The NEAR AI HUB monitors the latest blocks from the NEAR blockchain and can trigger agents when it detects <code>EVENT_JSON</code> entries following the <code>nearai</code> standard in transactions.</p>"},{"location":"agents/patterns/near_events/#example-of-an-event-log-entry","title":"Example of an Event Log Entry","text":"<pre><code>{\n  \"standard\": \"nearai\",\n  \"version\": \"0.1.0\",\n  \"event\": \"run_agent\",\n  \"data\": [\n    {\n      \"message\": \"Hello from NEAR Blockchain\",\n      \"agent\": \"user.near/agent-name/latest\",\n      \"max_iterations\": null,\n      \"env_vars\": null,\n      \"signer_id\": \"account.near\",\n      \"referral_id\": null,\n      \"request_id\": null,\n      \"amount\": \"0\"\n    }\n  ]\n}\n</code></pre> <p>Example Transaction.</p> <p>When such an event is detected, the agent specified in the <code>agent</code> field (e.g., <code>user.near/agent-name/latest</code>) will be automatically triggered. The agent will receive a JSON string containing the following object as its input:</p> <pre><code>{\n  \"event\": \"run_agent\",\n  \"message\": \"...\",\n  \"receipt_id\": \"...\",\n  // Other fields from the `data` object in the logs.\n}\n</code></pre> <p>To allow your agent to be invoked in this way, add a function that parses the incoming user message as a JSON string. If the required values for <code>event</code> and <code>message</code> are present, it should take the appropriate actions. The agent is not required to trust the data sent by the NEAR AI HUB and can independently verify the blockchain by reading the necessary block based on the <code>receipt_id</code>.</p>"},{"location":"agents/patterns/orchestration/","title":"Orchestrating multiple agent","text":"<p>NEAR AI provides flexible architecture for orchestrating multiple agents to work together effectively.</p>"},{"location":"agents/patterns/orchestration/#one-agent-one-trust-boundary","title":"One Agent - One Trust Boundary","text":"<p>Usually, a swarm of multiple agent roles can be all orchestrated within a single deployed NEAR AI agent. If your organization is the author of all the agents, combining these roles into a single agent is the most straightforward and often recommended approach which keeps things simple, efficient, and within one trust boundary.</p> <p>Examples:</p> <ul> <li>common-tool-library-agent - contains      over a hundred prompts for tackling specific problems</li> <li>langchain-reflection-agent -      contains separate code generation and reviews sub-agents that hand off work to each other</li> </ul> <p>To track turns or which sub-agent to invoke there are two common patterns:</p> <ul> <li>Router - the initial agent logic reviews the thread messages and decides which sub-agent to call.</li> <li>State file - a file is written to the thread that contains the current programmatic state of the conversation.      The agent reads this file to determine what to do next. See messages_files.md.</li> </ul>"},{"location":"agents/patterns/orchestration/#agent-to-agent-multiple-trust-boundaries","title":"Agent to Agent - Multiple trust boundaries","text":"<p>Agents can call other agents to interact with them using the <code>run_agent</code> method. This can be on the same thread or a sub-thread. This introduces multiple trust boundaries which should be considered before implementation.</p> <p>For more information on this, see Agent to Agent Communication.</p>"},{"location":"agents/patterns/orchestration/#api-integration","title":"API integration","text":"<p>External applications can call one or more NEAR AI Agents using the NEAR AI Assistants API. For more on this, see Integrating Agents.</p>"},{"location":"api/guide/","title":"API Basics","text":"<p>NEAR AI provides a standard Web API based on OpenAPI to interact with the Developer Hub, allowing powerful backend integrations.</p> <p>In this article you'll find information on how to generate a valid <code>auth</code> token to use the API, and links to the API reference documentation:</p> <ul> <li>Using the API</li> <li>API documentation</li> <li>Interactive API</li> </ul>"},{"location":"api/guide/#using-the-api","title":"Using the API","text":"<p>To use the Near AI Web API methods, you'll need an authorization token generated from your NEAR account.</p> <p>In the next section, you can find detailed information about the <code>auth</code> bearer token, and how it can be generated in a programmatic way.</p>"},{"location":"api/guide/#auth-token","title":"Auth token","text":"<p>The <code>auth</code> bearer token is a stringyfied JSON that must contain <code>account_id</code>, <code>public_key</code>, <code>signature</code>, <code>nonce</code>, and <code>message</code> (it can also include some optional fields).</p> <p>For example, this object:</p> <pre><code>{\n  \"account_id\": \"demoaccount.near\",\n  \"public_key\": \"ed25519:G59i7tou.....QGUrfSkeJ\",\n  \"signature\": \"P6fZ5bp9j.....Z7BvtqDQ==\",\n  \"callback_url\": \"https://app.near.ai/sign-in/callback\",\n  \"message\": \"Welcome to NEAR AI Hub!\",\n  \"recipient\": \"ai.near\",\n  \"nonce\": \"00000000000000000001741287395592\"\n}\n</code></pre> <p>Becomes a string token:</p> <pre><code>auth:'{\"account_id\":\"demoaccount.near\",\"public_key\":\"ed25519:G59i7touKk.....QGUrfSkeJ\",\"signature\":\"P6fZ5bp9j.....BVTZ7BvtqDQ==\",\"callback_url\":\"https://app.near.ai/sign-in/callback\",\"message\":\"Welcome to NEAR AI Hub!\",\"recipient\":\"ai.near\",\"nonce\":\"00000000000000000001741287395592\"}'\n</code></pre> <p>Tip</p> <p>If you're logged into app.near.ai, you can grab the token out of the <code>auth</code> cookie. For example:</p> <pre><code>auth:\"%7B%22account_id%22%3A%22demoaccount.near%22%2C%22public_key%22%3A%22ed25519%3AG59i7tou.....QGUrfSkeJ%22%2C%22signature%22%3A%22P6fZ5bp9j.....Z7BvtqDQ%3D%3D%22%2C%22callback_url%22%3A%22https%3A%2F%2Fapp.near.ai%2Fsign-in%2Fcallback%22%2C%22message%22%3A%22Welcome%20to%20NEAR%20AI%20Hub!%22%2C%22recipient%22%3A%22ai.near%22%2C%22nonce%22%3A%2200000000000000000001741287395592%22%7D\"\n</code></pre>"},{"location":"api/guide/#generate-the-token","title":"Generate the token","text":"<p>You can also generate the <code>auth</code> bearer token using your preferred programming language. In this section you can find a few code samples using Python, Rust, and JavaScript.</p> PythonJavaScriptRust <p>This code example uses the <code>nearai</code> CLI to complete the authentication process, and then generates the <code>auth</code> token. For additional details, check the full implementation.</p> <pre><code>import shlex\nimport sys\nimport fire  # type: ignore\n\nfrom nearai.cli import LoginCLI  # type: ignore\nfrom nearai.config import load_config  # type: ignore\nfrom nearai.shared.client_config import ClientConfig  # type: ignore\n\ndef get_nearai_client_config() -&gt; ClientConfig:\n  config = load_config()\n  if self.config.auth is None:\n    print(\"Attempt to get local client config, nearai_langchain v ^0.0.11\")\n    print(\"NearAI authentication required. Running web-based login...\")\n    command = \"nearai login --remote\"\n    sys.argv = shlex.split(command)\n    fire.Fire(CLI)\n\n    # Note: At this point, the user needs to:\n    # 1. Follow the auth URL that will be printed\n    # 2. Complete the authentication process\n    # 3. Get the login save command with parameters\n\n    save_command = input(\"Please enter the login save command: \")\n    sys.argv = shlex.split(save_command)  # Properly splits command respecting quotes\n    fire.Fire(CLI)\n\n    config = load_config()\n  return config.get_client_config()\n\n\ndef generate_nearai_auth_token(config: ClientConfig):\n  auth_bearer_token = config.auth.generate_bearer_token()\n  new_token = json.loads(auth_bearer_token)\n  new_token[\"runner_data\"] = json.dumps(\n    {\"agent\": \"\", \"runner_api_key\": \"\"}\n  )\n  auth_bearer_token = json.dumps(new_token)\n  return auth_bearer_token\n\n\napi_key = generate_nearai_auth_token(get_nearai_client_config())\n</code></pre> <p>This JS code example uses the Wallet selector to complete the authentication process, and then generates the <code>auth</code> token. For additional information, you can check the complete Next.js implementation.</p> <pre><code>export const NEAR_AI_AUTH_OBJECT_STORAGE_KEY = \"NearAIAuthObject\";\n\nexport async function handleNearAILoginCallback() {\n  const callbackparams = new URLSearchParams(location.hash);\n  const accountId = callbackparams.get(\"#accountId\");\n\n  if (accountId) {\n    const nearaiauthobject = JSON.parse(\n      localStorage?.getItem(NEAR_AI_AUTH_OBJECT_STORAGE_KEY),\n    );\n    nearaiauthobject.account_id = accountId;\n    nearaiauthobject.signature = callbackparams.get(\"signature\");\n    nearaiauthobject.public_key = callbackparams.get(\"publicKey\");\n    localStorage.setItem(\n      NEAR_AI_AUTH_OBJECT_STORAGE_KEY,\n      JSON.stringify(nearaiauthobject),\n    );\n    location.hash = \"\";\n  }\n}\n\nexport async function nearAIlogin(wallet, message) {\n  // Generate nonce based on current time in milliseconds\n  const nonce = new String(Date.now());\n  const nonceBuffer = Buffer.from(\n    new TextEncoder().encode(nonce.padStart(32, \"0\")),\n  );\n\n  const recipient = \"ai.near\";\n  const callbackUrl = location.href;\n\n  const authObject = {\n    message,\n    nonce,\n    recipient,\n    callback_url: callbackUrl,\n    signature:\"\",\n    account_id: \"\",\n    public_key: \"\"\n  };\n\n  localStorage.setItem(\n    NEAR_AI_AUTH_OBJECT_STORAGE_KEY,\n    JSON.stringify(authObject),\n  );\n  const signedMessage = await wallet.signMessage({\n    message,\n    nonce: nonceBuffer,\n    recipient,\n    callbackUrl,\n  });\n\n  authObject.signature = signedMessage.signature;\n  authObject.account_id = signedMessage.accountId;\n  authObject.public_key = signedMessage.publicKey;\n\n  localStorage.setItem(\n    NEAR_AI_AUTH_OBJECT_STORAGE_KEY,\n    JSON.stringify(authObject),\n  );\n\n  return authObject;\n}\n</code></pre> <p>This code example builds the auth payload, signs it using the <code>sign_message_nep413()</code> method, and stringifies the JSON result to generate the <code>auth</code> token. For additional information, see full implementation.</p> <pre><code>async fn get_api_key(account: SelectedAccount) -&gt; Result&lt;String, anyhow::Error&gt; {\n    let nonce = SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .unwrap()\n        .as_millis();\n    let payload = NEP413Payload {\n        message: \"Welcome to NEAR AI\".to_string(),\n        recipient: \"ai.near\".to_string(),\n        nonce: [\n            vec!['0' as u8; 32 - nonce.to_string().as_bytes().len()],\n            nonce.to_string().as_bytes().to_vec(),\n        ]\n        .concat()\n        .try_into()\n        .unwrap(),\n        callback_url: Some(\"https://example.callback.url\".to_string()),\n    };\n    let signature = account\n        .signer\n        .sign_message_nep413(\n            account.account_id.clone(),\n            account.public_key.clone(),\n            payload.clone(),\n        )\n        .await?;\n    Ok(serde_json::to_string(&amp;serde_json::json!({\n        \"account_id\": account.account_id,\n        \"signature\": BASE64_STANDARD.encode(match signature {\n            Signature::ED25519(sig) =&gt; sig.to_bytes(),\n            Signature::SECP256K1(_) =&gt; unreachable!(), // we're working only with ed25519 on trading bot side\n        }),\n        \"public_key\": account.public_key,\n        \"nonce\": nonce.to_string(),\n        \"recipient\": payload.recipient,\n        \"message\": payload.message,\n        \"callback_url\": payload.callback_url,\n        \"on_behalf_of\": null,\n    }))?)\n}\n</code></pre>"},{"location":"api/guide/#api-documentation","title":"API documentation","text":"<p>You can find complete and detailed technical reference documentation regarding available NEAR AI API methods in this page.</p> <p></p> <p>Reference documentation includes:</p> <ul> <li>Request schemas</li> <li>Query parameters</li> <li>Responses</li> <li>Response schemas</li> </ul> <p>API Endpoints reference documentation</p> Link Description Default Main Hub methods. Registry Registry management methods. Agents &amp; Assistants Agent management methods. Benchmark Benchmarking methods. Stars Star management methods. Jobs Jobs management methods. Permissions Permission methods. Evaluation Evaluation methods. Delegation Delegation management methods. Logs Logging methods. Vector Stores Vector Store management methods. Files File management methods. Threads Thread management methods. Hub Secrets Manage Hub secrets. Run Schedule Scheduling methods."},{"location":"api/guide/#interactive-api","title":"Interactive API","text":"<p>NEAR AI also provides an interactive Web API based on Swagger UI that allows you to visualize and interact with NEAR AI API\u2019s resources without having any of the implementation logic in place.</p> <p>The interactive API is automatically generated from the OpenAPI specification, providing a simple API tool for back end implementation and client side consumption.</p> <p>Info</p> <p>Please note that to execute API calls using this interactive tool, you need to provide a valid authentication token. Check this section to learn more about generating your <code>auth</code> token.</p> <p></p> <p>Interactive API Endpoints</p> <ul> <li>Default</li> <li>Registry</li> <li>Agents &amp; Assistants</li> <li>Benchmark</li> <li>Stars</li> <li>Jobs</li> <li>Permissions</li> <li>Evaluation</li> <li>Delegation</li> <li>Logs</li> <li>Vector Stores</li> <li>Files</li> <li>Threads</li> <li>Hub Secrets</li> <li>Run Schedule</li> </ul>"},{"location":"integration/overview/","title":"Integrating Applications","text":"<p>NEAR AI agents are compatible with the OpenAI Assistants API, allowing for easy integration of agents into your own web, mobile or other applications.</p> <p>The full NEAR AI OpenAPI specification can be found at https://api.near.ai/openapi.json. </p> <p>An Assistant has instructions and can leverage models, tools, and files to respond to user queries. </p>"},{"location":"integration/overview/#how-assistants-work","title":"How Assistants work","text":"<p>The Assistants API is designed to help developers build powerful AI assistants capable of performing a variety of tasks.</p> <ol> <li>Assistants can call various models with specific instructions to tune their personality and capabilities.</li> <li>Assistants can access multiple tools.</li> <li>Assistants can access persistent Threads. Threads simplify AI application development by storing message history and truncating it when the conversation gets too long for the model\u2019s context length. You create a Thread once, and simply append Messages to it as your users reply.</li> <li>Assistants can access files in several formats \u2014 either as part of their creation or as part of Threads between Assistants and users. When using tools, Assistants can also create files (e.g., images, spreadsheets, etc) and cite files they reference in the Messages they create.</li> </ol>"},{"location":"integration/overview/#key-concepts","title":"Key Concepts","text":"Object What it represents Assistant Purpose-built AI that uses various models and calls tools. Thread A conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a model\u2019s context. Message A message created by an Assistant or a user. Messages can include text, images, and other files. Messages stored as a list on the Thread. Run An invocation of an Assistant on a Thread. The Assistant uses its configuration and the Thread\u2019s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread. Run Step A detailed list of steps the Assistant took as part of a Run. An Assistant can call tools or create Messages during its run. Examining Run Steps allows you to introspect how the Assistant is getting to its final results. Service Agent A specialized Agent called by the Assistant to accomplish a task such as purchasing, undertaking a swap, or generating a smart contract."},{"location":"integration/overview/#next-steps","title":"Next Steps","text":"<p>Integrate an Assistant into your application</p>"},{"location":"integration/quickstart/","title":"Integrate NEAR AI Agents using the Assistant API","text":"<p>The NEAR AI Assistants API is compatible with the OpenAI Assistants API. You can run your own agent or any agent in the  registry using the NEAR AI Assistants API.</p> <p>NEAR AI offers a powerful Assistant that answers questions, queries other agents, and more.  You can integrate this Assistant into your own applications by using the Assistant API as shown below. Other agents can be called in the same manner simply by passing a different <code>assistant_id</code> to the <code>runs.create_and_poll</code> call.</p>"},{"location":"integration/quickstart/#step-0-login-into-near-account","title":"Step 0: Login into NEAR account","text":""},{"location":"integration/quickstart/#javascript-client-side-useful-for-wallets","title":"JavaScript, client side. Useful for wallets.","text":"<p>From client side, you can use the following function to sign the message and get the required NEAR AI authorization token.</p> <pre><code>async function login(wallet, message, nonce, recipient, callbackUrl) {\n    const signedMessage = await wallet.signMessage({\n        message,\n        nonce,\n        recipient,\n        callbackUrl\n    });\n    return {\n        signature: signedMessage.signature,\n        accountId: signedMessage.accountId,\n        publicKey: signedMessage.publicKey,\n        message,\n        nonce,\n        recipient,\n        callbackUrl\n    };\n}\n\n// Generate nonce based on current time in milliseconds\nconst nonce = String(Date.now());\nconst recipient = YOUR_RECIPIENT_ADDRESS;\nconst callbackUrl = YOUR_CALLBACK_URL;\n\n// Example usage of login function\nconst auth = await login(wallet, \"Login to NEAR AI\", nonce, recipient, callbackUrl);\n</code></pre>"},{"location":"integration/quickstart/#python","title":"Python","text":"<p>In Python, we recommend using the <code>nearai</code> CLI to login into your NEAR account. More details here.</p> <pre><code>nearai login\n</code></pre>"},{"location":"integration/quickstart/#step-1-create-a-thread","title":"Step 1: Create a Thread","text":"<p>A Thread represents a conversation between a user and one or many Assistants. You can create a Thread when a user (or your AI application) starts a conversation with your Assistant.</p>"},{"location":"integration/quickstart/#create-a-thread","title":"Create a Thread","text":"<p>In JavaScript:</p> <pre><code>import OpenAI from \"openai\";\nconst openai = new OpenAI({\n    baseURL: \"https://api.near.ai/v1\",\n    apiKey: `Bearer ${JSON.stringify(auth)}`,\n});\n\nconst thread = await openai.beta.threads.create();\n</code></pre> <p>In Python:</p> <pre><code>import openai\n\nclient = openai.OpenAI(\n    api_key=\"YOUR_NEARAI_SIGNATURE\",\n    base_url=\"https://api.near.ai/v1\",\n)\n\nthread = client.beta.threads.create()\n</code></pre>"},{"location":"integration/quickstart/#step-2-add-a-message-to-the-thread","title":"Step 2: Add a Message to the Thread","text":"<p>The contents of the messages your users or applications create are added as Message objects to the Thread. Messages can contain both text and files. There is a limit of 100,000 Messages per Thread and we smartly truncate any context that does not fit into the model's context window.</p>"},{"location":"integration/quickstart/#add-a-message-to-the-thread","title":"Add a Message to the Thread","text":"<p>In JavaScript:</p> <pre><code>const message = await openai.beta.threads.messages.create(\n  thread.id,\n  {\n    role: \"user\",\n    content: \"Help me plan my trip to Tokyo\"\n  }\n);\n</code></pre> <p>In Python:</p> <pre><code>message = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"Help me plan my trip to Tokyo\"\n)\n</code></pre>"},{"location":"integration/quickstart/#step-3-create-a-run","title":"Step 3: Create a Run","text":"<p>Once all the user Messages have been added to the Thread, you can Run the Thread with any Assistant. Creating a Run uses the model and tools associated with the Assistant to generate a response. These responses are added to the Thread as assistant Messages.</p> <p>Runs are asynchronous, which means you'll want to monitor their status by polling the Run object until a terminal status is reached. For convenience, the 'create and poll' SDK helpers assist both in creating the run and then polling for its completion.</p>"},{"location":"integration/quickstart/#create-a-run","title":"Create a Run","text":"<p>In JavaScript:</p> <pre><code>const assistant_id = \"near-ai-agents.near/assistant/latest\"\nlet run = await openai.beta.threads.runs.createAndPoll(\n  thread.id,\n  { \n    assistant_id: assistant_id,\n  }\n);\n</code></pre> <p>In Python:</p> <pre><code>assistant_id = \"near-ai-agents.near/assistant/latest\"\nrun = client.beta.threads.runs.create_and_poll(\n    thread_id=thread.id,\n    assistant_id=assistant_id,\n)\n</code></pre> <p>Once the Run completes, you can list the Messages added to the Thread by the Assistant.</p> <pre><code>if (run.status === 'completed') {\n  const messages = await openai.beta.threads.messages.list(\n    run.thread_id\n  );\n  for (const message of messages.data.reverse()) {\n    console.log(`${message.role} &gt; ${message.content[0].text.value}`);\n  }\n} else {\n  console.log(run.status);\n}\n</code></pre> <pre><code>if run.status == 'completed':\n    messages = client.beta.threads.messages.list(run.thread_id)\n    for message in messages:\n        print(f\"{message.role} &gt; {message.content[0].text.value}\")\nelse:\n    print(run.status)\n</code></pre> <p>You may also want to list the Run Steps of this Run if you'd like to look at any tool calls made during this Run.</p>"},{"location":"models/benchmarks_and_evaluations/","title":"Benchmarks and Evaluations","text":"<p><code>Benchmarks</code> allow you to compare different agents and solvers on specific tasks, so you can determine which is the best fit for your needs.</p> <p><code>Evaluations</code> are the results of running benchmarks. They are stored in the registry and can be used to compare different agents and solvers.</p>"},{"location":"models/benchmarks_and_evaluations/#how-is-a-benchmark-implemented","title":"How is a benchmark implemented?","text":"<p>A benchmark is the combination of a dataset and a solver (more on this below). </p> <p>Once you have created a dataset and its solver, you can run the benchmark using the <code>benchmark</code> command.</p> <p>For example, to run the <code>mpbb</code> benchmark on the <code>llama v3</code>, you can use:</p> <pre><code>nearai benchmark run mbpp MBPPSolverStrategy \\\n    --model llama-v3-70b-instruct \\\n    --subset=train \\\n    --max_concurrent=1\n</code></pre>"},{"location":"models/benchmarks_and_evaluations/#adding-a-benchmark-dataset","title":"Adding a benchmark dataset","text":"<p><code>nearai</code> leverages huggingface datasets as the primitive when operating with datasets + benchmarks (see <code>load_dataset</code>). This means that to add a new benchmark, you need to create a new dataset and register it with the <code>nearai</code> registry (we will go over this in Implementing the \"3 digit addition\" benchmark).</p> <p>There is also a support for datasets of custom format.</p>"},{"location":"models/benchmarks_and_evaluations/#adding-a-solver","title":"Adding a solver","text":"<p>To implement a solver, you will need to implement the SolverStrategy interface under the <code>nearai.solvers</code> module. The most important method the solver should implement is the <code>solve</code> method. This method should take a datum, run your implementation specific agentic strategy / strategies, and return a result.</p>"},{"location":"models/benchmarks_and_evaluations/#implementing-the-3-digit-addition-benchmark","title":"Implementing the \"3 digit addition\" benchmark","text":"<p>In this section we will be implementing a benchmark we'll call \"3 digit addition\". The goal of the benchmark is to test an agents ability to add two 1-3 digit numbers together. The dataset will consist of 1000 examples of 3 digit addition problems and their solutions. The solver will adjudicate the agent answers and return a single accuracy score. While this benchmark is simple and can be solved with a simple program, it serves as a good example of how to implement a benchmark in <code>nearai</code>.</p>"},{"location":"models/benchmarks_and_evaluations/#step-1-creating-the-dataset","title":"Step 1: Creating the dataset","text":"<p>To create this dataset, we will first synthetically generate the data. We will then register the dataset with the <code>nearai</code> registry.</p> <pre><code>import random\nfrom itertools import product\n\nimport datasets\n\nSAMPLE_SIZE = 1000\nSEED = 42\nPATH = \"3_digit_addition\"\n\nrandom.seed(SEED)\ndatasets.Dataset.from_generator(\n    lambda: iter(\n        {\n            \"input\": f\"{a} + {b}\",\n            \"output\": str(a + b)\n        }\n        for a, b in random.sample(list(product(range(1000), range(1000))), SAMPLE_SIZE)\n    ),\n    features=datasets.Features(\n        {\n            \"input\": datasets.Value(\"string\"),\n            \"output\": datasets.Value(\"string\")\n        }\n    )\n).save_to_disk(PATH)\n</code></pre> <p>Now to upload the dataset to the registry we'll run the command:</p> <pre><code>nearai registry upload ./3_digit_addition\n</code></pre>"},{"location":"models/benchmarks_and_evaluations/#step-2-creating-the-solver","title":"Step 2: Creating the solver","text":"<p>To create the solver, we will implement the <code>SolverStrategy</code> interface. The solver will take in a datum, parse the input, execute any setup for the agent, run the agent, and return the correctness of the agents result.</p> Remember <p>To ensure this solver is registered with <code>nearai</code>:</p> <ol> <li>Write this implementation in the <code>nearai.solvers</code> module.</li> <li>Import it in the <code>__init__.py</code> file in the <code>nearai.solvers</code> module.</li> </ol> <pre><code># ... other imports ...\nfrom pydantic import BaseModel\nfrom huggingface import Dataset\nfrom nearai.solvers import SolverStrategy\n\nfrom typing import Dict, List\n\nclass ThreeDigitAdditionDatum(BaseModel):\n    input: str\n    output: str\n\nclass ThreeDigitAdditionSolver(SolverStrategy):\n    \"\"\"Solver for the 3 digit addition benchmark.\"\"\"\n\n    def __init__(self, dataset_ref: Dataset, model: str = \"\", agent: str = \"\"):\n        super().__init__(model, agent)\n        self.dataset_ref = dataset_ref\n\n    def evaluation_name(self) -&gt; str:\n        return \"3_digit_addition\"\n\n    def compatible_datasets(self) -&gt; List[str]:\n        return [\"3_digit_addition\"]\n\n    def solve(self, datum: Dict[str, str]) -&gt; bool:\n        datum = ThreeDigitAdditionDatum(**datum)\n        label = datum.input.replace(\" + \", \"+\")\n        session = self.start_inference_session(label)\n\n        goal = f\"\"\"Please add the following numbers together: {datum.input}\\n\\nOutput the result only.\"\"\"\n        result = session.run_task(goal).strip()\n        return result == datum.output\n</code></pre> <p>The code above can run for both models and agents. If both <code>model</code> and <code>agent</code> are given, the <code>model</code> value will be inserted into <code>agent</code> metadata.</p> <p>To check agent functionality to write files: <pre><code>    def solve(self, datum: Dict[str, str]) -&gt; bool:\n        datum = ThreeDigitAdditionDatum(**datum)\n        label = datum.input.replace(\" + \", \"+\")\n        session = self.start_inference_session(label)\n\n        goal = f\"\"\"Please add the following numbers together: {datum.input}\\n\\nOutput the result in a file called 'result.txt'.\"\"\"\n        session.run_task(goal)\n        with open(os.path.join(session.path, \"result.txt\"), \"r\") as f:\n            result = f.read().strip()\n        return result == datum.output\n</code></pre></p>"},{"location":"models/benchmarks_and_evaluations/#step-3-running-the-benchmark","title":"Step 3: Running the benchmark","text":"<p>To run the benchmark, we will use the <code>nearai</code> CLI. We will specify the dataset and solver we want to use.</p> <pre><code>nearai benchmark run near.ai/3_digit_addition/1.00 ThreeDigitAdditionSolver --agent ~/.nearai/registry/&lt;my_agent&gt;\n</code></pre>"},{"location":"models/benchmarks_and_evaluations/#benchmarks-cache","title":"Benchmarks Cache","text":"<p>Benchmark individual tasks and completion are cached in registry or locally. To see registry benchmark completion caches:</p> <pre><code>nearai benchmark list\n</code></pre> <p>To force execution and overwrite cache pass <code>--force</code> flag.</p> <pre><code>nearai benchmark run near.ai/mbpp/1.0.0 MBPPSolverStrategy --model 'llama-3p2-1b-instruct' --subset test --force\n</code></pre>"},{"location":"models/benchmarks_and_evaluations/#example-runs","title":"Example runs","text":"<pre><code>$ nearai benchmark run near.ai/mbpp/1.0.0 MBPPSolverStrategy --model 'llama-3p2-1b-instruct' --subset test\n$ nearai benchmark run near.ai/mmlu/1.0.0 MMLUSolverStrategy --model 'llama-v3p1-405b-instruct' --subset test\n$ nearai benchmark run near.ai/mbpp/1.0.0 MBPPSolverStrategy --model 'qwen2p5-72b-instruct' --subset test --agent ~/.nearai/registry/flatirons.near/example-travel-agent/1\n$ nearai benchmark run near.ai/live_bench/1.0.0 LiveBenchSolverStrategy --model 'qwen2p5-72b-instruct' --agent ~/.nearai/registry/flatirons.near/example-travel-agent/1\n</code></pre>"},{"location":"models/benchmarks_and_evaluations/#evaluations","title":"Evaluations","text":""},{"location":"models/benchmarks_and_evaluations/#recording-benchmark-result-as-an-evaluation","title":"Recording benchmark result as an evaluation","text":"<p>To record benchmark results as an evaluation, pass <code>--record</code>. It is strongly recommended to pass this flag after verifying successful run of the benchmark.</p> <pre><code>$ nearai benchmark run near.ai/mbpp/1.0.0 MBPPSolverStrategy --model 'llama-3p2-1b-instruct' --subset test\nFinal score: 131/500 - 26.20%\n$ nearai benchmark run near.ai/mbpp/1.0.0 MBPPSolverStrategy --model 'llama-3p2-1b-instruct' --subset test --record\n</code></pre> <p>That creates new evaluation entry in the registry: <pre><code>$ nearai registry list --category=evaluation\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 entry                                                                  \u2502 category   \u2502 description   \u2502 tags   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 alomonos.near/evaluation_mbpp_model_llama-v3p2-1b-                     \u2502 evaluation \u2502               \u2502        \u2502\n\u2502 instruct_provider_fireworks/0.0.1                                      \u2502            \u2502               \u2502        \u2502\n</code></pre></p>"},{"location":"models/benchmarks_and_evaluations/#view-evaluation-table","title":"View evaluation table","text":"<p>To view evaluation table in CLI: <pre><code>$ nearai evaluation table --num_columns=8\n$ nearai evaluation table --all_key_columns --num_columns=8\n$ nearai evaluation table --all_metrics\n</code></pre></p> <p>https://app.near.ai/evaluations has a functionality to choose any columns.</p>"},{"location":"models/benchmarks_and_evaluations/#submit-an-experiment","title":"Submit an experiment","text":"<p>To submit a new experiment run:</p> <pre><code>nearai submit --command &lt;COMMAND&gt; --name &lt;EXPERIMENT_NAME&gt; [--nodes &lt;NUMBER_OF_NODES&gt;] [--cluster &lt;CLUSTER&gt;]\n</code></pre> <p>This will submit a new experiment. The command must be executed from a folder that is a git repository (public github repositories, and private github repositories on the same organization as nearai are supported). The current commit will be used for running the command so make sure it is already available online. The diff with respect to the current commit will be applied remotely (new files are not included in the diff).</p> <p>On each node the environment variable <code>ASSIGNED_SUPERVISORS</code> will be available with a comma separated list of supervisors that are running the experiment. The current supervisor can be accessed via <code>nearai.CONFIG.supervisor_id</code>. See examples/prepare_data.py for an example.</p>"},{"location":"models/benchmarks_and_evaluations/#issues","title":"Issues","text":"<ul> <li>Overwriting existing evaluation entry is currently not supported</li> <li>litellm.Timeout errors when running benchmark</li> <li>Feature request: tag individual evaluation metrics</li> <li>Feature request: add view for a metric</li> <li>Feature request: add cost of running benchmark to evaluation results as a separate metric</li> <li>Feature request: hide evaluation results for hidden agents and models</li> <li>Capabilities Benchmarks Tracking: list of benchmarks we want to add</li> </ul>"},{"location":"models/fine_tuning/","title":"<code>nearai</code> fine-tuning guide","text":"<p>As a part of the <code>nearai</code> project, we provide a collection of tools to fine-tune and evaluate models. Fine-tuning is a set of techniques to tune model parameters in a parameter-efficient way to improve model performance on specific tasks. More commonly, fine-tuning is used to modify the behavior of a pre-trained model. Some examples of this are to produce structured output (JSON, XLM, etc), to produce stylized output (poetic, neutral, etc), or to respond properly to instruction based prompts.</p> <p>In this guide, we will walk through the process of fine-tuning <code>llama-3-8b-instruct</code> on the orca-math-word-problems-200k dataset to improve its performance on the gsm8k benchmark.</p>"},{"location":"models/fine_tuning/#step-1-create-the-dataset","title":"Step 1: Create the dataset","text":"<p>The two datasets we will be using are orca-math-word-problems-200k and gsm8k. Both datasets are a collection of word based math problems + answers. For convenience, we will download the datasets from huggingface, save it to disk, and then upload it into the <code>nearai</code> registry.</p> <pre><code>import re\nfrom textwrap import dedent\nfrom datasets import load_dataset, concatenate_datasets, DatasetDict\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n\nds_math_word_problems = load_dataset(\"HuggingFaceH4/orca-math-word-problems-200k\")\nds_gsm8k = load_dataset(\"openai/gsm8k\", \"main\")['train']\n\n## create new column by concatenating the 'question' and 'answer' columns\ndef to_q_a(x):\n    q_n_a = tokenizer.apply_chat_template(\n        [\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful assistant. Please answer the math question.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": x[\"question\"]\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": x[\"answer\"]\n            }\n        ],\n        tokenize=False\n    )\n    return {\n        \"question_and_answer\": q_n_a\n    }\nds_math_word_problems = ds_math_word_problems.map(to_q_a)\n\ndef to_q_a_gsm8k(x):\n    q_n_a = tokenizer.apply_chat_template(\n        [\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful assistant. Please answer the math question.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": x[\"question\"]\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": re.sub(r\"&lt;&lt;.*?&gt;&gt;\", \"\", x[\"answer\"])\n            }\n        ],\n        tokenize=False\n    )\n    return {\n        \"question_and_answer\": q_n_a\n    }\nds_gsm8k = ds_gsm8k.map(to_q_a_gsm8k)\n\n## combine the datasets\nds_combined = concatenate_datasets([ds_math_word_problems['train_sft'], ds_gsm8k])\nds_combined = ds_combined.remove_columns([col for col in ds_combined.column_names if col != \"question_and_answer\"])\n\n# Add a split on 'train'\nds_combined = ds_combined.train_test_split(test_size=0.0001, seed=42)\nds_dict = DatasetDict({\n    'train': ds_combined['train'],\n    'validation': ds_combined['test']\n})\nds_dict.save_to_disk(\"orca_math_gsm8k_train\")\n</code></pre> <pre><code>nearai registry upload ./orca_math_gsm8k_train\n</code></pre>"},{"location":"models/fine_tuning/#step-2-fine-tune-the-model","title":"Step 2: Fine-tune the model","text":"<p>Under the hood, <code>nearai</code> uses torchtune to manage the fine-tuning process. To launch a fine-tuning job you can use <code>nearai finetune</code>.</p> <p>Here is the command we used to fine-tune <code>llama-3-8b-instruct</code> on our combined <code>orca-math-word-problems-200k</code> and <code>gsm8k</code> dataset on an 8-GPU machine:</p> <pre><code>uv run python3 -m nearai finetune start \\\n    --model llama-3-8b-instruct \\\n    --format llama3-8b \\\n    --tokenizer llama-3-8b-instruct/tokenizer.model \\\n    --dataset ./orca_math_gsm8k_train \\\n    --method nearai.finetune.text_completion.dataset \\\n    --column question_and_answer \\\n    --split train \\\n    --num_procs 8\n</code></pre> <p>To change the configuration of the fine-tuning job, edit <code>etc/finetune/llama3-8b.yml</code>.</p> <p>Included in the output of the command is the path to the fine-tuned model checkpoint. In this case, the path was <code>~.nearai/finetune/job-2024-08-29_20-58-08-207756662/checkpoint_output</code>. The path may/will be different based on the time you run the command.</p>"},{"location":"models/fine_tuning/#step-3-serve-the-fine-tuned-model","title":"Step 3: Serve the fine-tuned model","text":"<p>To serve fine-tuned models, we use vllm. Once we serve the fine-tuned model + the baseline model, we will benchmark it against both.</p> <pre><code>uv run python3 -m vllm.entrypoints.openai.api_server \\\n    --model meta-llama/Meta-Llama-3-8B-Instruct \\\n    --enable-lora \\\n    --lora-modules mynewlora=&lt;path_to_checkpoint&gt; \\\n    --tensor-parallel 8\n</code></pre> <p>Now we will run the <code>gsm8k</code> benchmark on both the baseline model and the fine-tuned model using <code>nearai benchmark</code>. The solvers will call our fine-tuned model and the baseline model through the vllm server.</p> <pre><code>python3 -m nearai benchmark run \\\n    cmrfrd.near/gsm8k/0.0.2 \\\n    GSM8KSolverStrategy \\\n    --subset test \\\n    --model local::meta-llama/Meta-Llama-3-8B-Instruct\n\npython3 -m nearai benchmark run \\\n    cmrfrd.near/gsm8k/0.0.2 \\\n    GSM8KSolverStrategy \\\n    --subset test \\\n    --model local::mynewlora\n</code></pre> <p>And we can see the results of the benchmark. And we can see that the fine-tuned model performs better than the baseline model.</p> <pre><code># meta-llama/Meta-Llama-3-8B-Instruct\nCorrect/Seen - 1061/1319 - 80.44%\n\n# fine tuned llama3-8b-instruct\nCorrect/Seen - 966/1319 - 73.24%\n</code></pre> <p>From these results, we can see that our fine-tuned model needs improvement to perform better than the baseline model.</p>"},{"location":"models/home/","title":"Home","text":"<p>NEAR AI provides access to powerful open-source AI models including Llama, Qwen, Deepseek and Stable Diffusion, leveraging various AI providers to deliver high-quality responses.</p> <p>Seamlessly find, tune and integrate models into your applications for chat completions, image creation, and function calling.</p> <p>Tip</p> <p>Are you looking to use the model in an agent? Check out the Agents Guide.</p>"},{"location":"models/home/#prerequisites","title":"\u26a0\ufe0f Prerequisites","text":"<p>Before you start using NEAR AI models, please make sure you have the NEAR AI CLI installed and have logged in with your Near wallet.</p>"},{"location":"models/home/#listing-available-models","title":"Listing Available Models","text":"<p>You can find a non-exhaustive list of models available on NEAR AI in the Web Hub. If you want to find all supported models on NEAR AI, run the following Python script:</p> <pre><code>import openai\nimport json\nimport nearai\n\nhub_url = \"https://api.near.ai/v1\"\nauth = nearai.config.load_config_file()[\"auth\"]\nsignature = json.dumps(auth)\n\nclient = openai.OpenAI(base_url=hub_url, api_key=signature)\n\nmodels = client.models.list()\nprint(models)\n</code></pre> <p>Warning</p> <p>Remember to use the NEAR CLI to login using your NEAR wallet</p> <pre><code>$&gt; nearai login\n</code></pre> Output <pre><code>{'fireworks': 'fireworks::accounts/yi-01-ai/models/yi-large'}, NamespacedName(name='aiderlm0', namespace='melse0299e'): {'fireworks': 'fireworks::accounts/mels-e0299e/models/aiderlm-v0'}, NamespacedName(name='flux1schnellfp8', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/flux-1-schnell-fp8'}, NamespacedName(name='flux1devfp8', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/flux-1-dev-fp8'}, NamespacedName(name='mistralsmall24binstruct2501', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/mistral-small-24b-instruct-2501'}, NamespacedName(name='deepseekr1', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/deepseek-r1'}, NamespacedName(name='mixtral8x22binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/mixtral-8x22b-instruct'}, NamespacedName(name='llama3_8binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3-8b-instruct'}, NamespacedName(name='deepseek3', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/deepseek-v3'}, NamespacedName(name='qwq32bpreview', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/qwen-qwq-32b-preview'}, NamespacedName(name='llama3p1_405binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3p1-405b-instruct'}, NamespacedName(name='llama3p1_8binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3p1-8b-instruct'}, NamespacedName(name='llama3_8binstructhf', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3-8b-instruct-hf'}, NamespacedName(name='llama3p2_3binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3p2-3b-instruct'}, NamespacedName(name='qwen2p5_72binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/qwen2p5-72b-instruct'}, NamespacedName(name='llama3p1_405binstructlong', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3p1-405b-instruct-long'}, NamespacedName(name='llama3p1_70binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3p1-70b-instruct'}, NamespacedName(name='llama3_70binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3-70b-instruct'}, NamespacedName(name='llama3p2_90bvisioninstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3p2-90b-vision-instruct'}, NamespacedName(name='llama3p3_70binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3p3-70b-instruct'}, NamespacedName(name='qwen2p5coder32binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/qwen2p5-coder-32b-instruct'}, NamespacedName(name='qwen2vl72binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/qwen2-vl-72b-instruct'}, NamespacedName(name='llama3p2_11bvisioninstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-v3p2-11b-vision-instruct'}, NamespacedName(name='llamaguard3_8b', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/llama-guard-3-8b'}, NamespacedName(name='phi3vision128kinstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/phi-3-vision-128k-instruct'}, NamespacedName(name='dobbyminileashedllama3_18b', namespace='sentientfoundation'): {'fireworks': 'fireworks::accounts/sentientfoundation/models/dobby-mini-leashed-llama-3-1-8b'}, NamespacedName(name='dobbyminiunhingedllama3_18b', namespace='sentientfoundation'): {'fireworks': 'fireworks::accounts/sentientfoundation/models/dobby-mini-unhinged-llama-3-1-8b'}, NamespacedName(name='statetransitionllama3p1', namespace='marco0dece6'): {'fireworks': 'fireworks::accounts/marco-0dece6/models/state-transition-llama3p1'}, NamespacedName(name='mixtral8x7binstruct', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/mixtral-8x7b-instruct'}, NamespacedName(name='mythomaxl2_13b', namespace=''): {'fireworks': 'fireworks::accounts/fireworks/models/mythomax-l2-13b'}, NamespacedName(name='tsr3', namespace='guzmanesneider75_94d6ba'): {'fireworks': 'fireworks::accounts/guzmanesneider75-94d6ba/models/tsr3'}, NamespacedName(name='serviceemergencyclassifierllama3_8binstruct', namespace='carlos0f74b3'): {'fireworks': 'fireworks::accounts/carlos-0f74b3/models/service-emergency-classifier-llama3-8b-instruct'}\n</code></pre> <p>Each model follows the format: <code>provider::account/model_name/model_version</code>. To list all providers:</p> <pre><code>providers = set([model.id.split(\"::\")[0] for model in models])\nprint(providers)\n</code></pre>"},{"location":"models/home/#working-with-ai-models","title":"Working with AI Models","text":"<p>When working with AI models, you will either want to directly use a model for inference, or fine-tune it for a specific use case.</p> <ul> <li>Fine-Tuning \u2013 Customize models for specific use cases.</li> <li>Benchmarks &amp; Evaluations \u2013 Assess model performance.</li> <li>Running Inference \u2013 Execute models for AI responses.</li> </ul> <pre><code>graph TD;\n    B[Available Models];\n    B --&gt;|Use Model| C[Inference API];\n    C --&gt;|Run Inference| D[Get Response];\n    B --&gt;|Fine-Tune| E[Customized Model];\n    E --&gt;|Benchmark| F[Evaluate Performance]; \n    F ----&gt;|Deploy| B;</code></pre>"},{"location":"tutorials/rag/agent/","title":"RAG Agent","text":"<p>Let's see how simple it is to create an agent that leverages the vector store we created in the previous section. This agent will demonstrate how to effectively use RAG (Retrieval-Augmented Generation) to provide accurate answers based on NEAR's documentation.</p> <p>Tip</p> <p>You can try out a live demo of this agent by signing in with your NEAR account below!</p>"},{"location":"tutorials/rag/agent/#documentation-agent","title":"Documentation Agent","text":"<p>In the previous section, we created a vector store and obtained its unique <code>id</code>. This <code>id</code> is a crucial piece that allows us to reference and interact with our stored embeddings. We'll now use this <code>id</code> within our agent to:</p> <ol> <li>Retrieve the vector store from storage</li> <li>Query it for relevant information based on user input</li> <li>Use the retrieved context to generate more informed responses</li> </ol> <p>The vector store <code>id</code> acts as a persistent identifier, enabling our agent to access the same knowledge base across multiple sessions or interactions.</p> <p>Let's update your <code>agent.py</code> file to include the vector store <code>id</code> and the RAG logic:</p> <pre><code>import json\nfrom nearai.agents.environment import Environment\n\nMODEL = \"llama-v3p3-70b-instruct\"\nVECTOR_STORE_ID = \"vs_cb8d5537f64d4f4aa6cbc95f\"\n\n\ndef run(env: Environment):\n    user_query = env.list_messages()[-1][\"content\"]\n\n    # Query the Vector Store\n    vector_results = env.query_vector_store(VECTOR_STORE_ID, user_query)\n    docs = [{\"file\": res[\"chunk_text\"]} for res in vector_results[:6]]\n\n    prompt = [\n        {\n            \"role\": \"user query\",\n            \"content\": user_query,\n        },\n        {\n            \"role\": \"documentation\",\n            \"content\": json.dumps(docs),\n        },\n        {\n            \"role\": \"system\",\n            \"content\": \"Give a brief but complete answer to the user's query, staying as true as possible to the documentation SPECIALLY when dealing with code.\"\n        }\n    ]\n\n    answer = env.completion(model=MODEL, messages=prompt)\n    env.add_reply(answer)\n\n\nrun(env)\n</code></pre>"},{"location":"tutorials/rag/agent/#how-it-works","title":"How it works?","text":"<p>In the code above, we extract the user's question from the environment's message history and use it as a semantic search query against our vector store. This allows us to find the most relevant document chunks based on their embedding similarity to the query.</p> <pre><code>vector_results = env.query_vector_store(VECTOR_STORE_ID, user_query)\n</code></pre> <p>The vector store returns a list of documents ranked by relevance to the user's query. To maintain efficiency and focus, we limit our context to the 6 most relevant document chunks:</p> <pre><code>docs = [{\"file\": res[\"chunk_text\"]} for res in vector_results[:6]]\n</code></pre> <p>We then construct a structured prompt with three key components:</p> <ol> <li>The user's original query</li> <li>The relevant documentation chunks</li> <li>A system message that guides the model's response behavior</li> </ol> <pre><code>prompt = [\n    {\n        \"role\": \"user query\",\n        \"content\": user_query,\n    },\n    {\n        \"role\": \"documentation\",\n        \"content\": json.dumps(docs),\n    },\n    {\n        \"role\": \"system\",\n        \"content\": \"Give a brief but complete answer to the user's query, staying as true as possible to the documentation SPECIALLY when dealing with code.\"\n    }\n]\n</code></pre> <p>This prompt structure ensures that the model has both the necessary context from our documentation and clear instructions on how to use it. We then pass this prompt to <code>env.completion()</code> to generate a response that accurately addresses the user's question based on our documentation.</p> <pre><code>answer = env.completion(model=MODEL, messages=prompt)\nenv.add_reply(answer)\n</code></pre>"},{"location":"tutorials/rag/agent/#did-it-work","title":"Did it work?","text":"<p>Let's try it out! Lets ask the agent the same questions we used when talking about hallucination:</p> What types of access keys are there in NEAR? <p>Assistant: There are two types of access keys in NEAR: </p> <ol> <li><code>Full Access</code> keys: Have full control over an account and should never be shared.</li> <li><code>Function-Call</code> keys: Can only sign calls for specific contracts, are meant to be shared, and do not allow transferring NEAR tokens. </li> </ol> <p><code>Function-Call</code> keys are defined by three attributes:  - <code>receiver_id</code>: The only contract that the key allows to call. - <code>method_names</code> (Optional): The contract's methods the key allows to call. - <code>allowance</code> (Optional): The amount of NEAR allowed to be spent on gas.</p> How can I create an account using the NEAR CLI? <p>Assistant: To create an account using the NEAR CLI, you can use the following command:</p> <pre><code>near account create-account sponsor-by-faucet-service &lt;your-account-id.testnet&gt; autogenerate-new-keypair save-to-keychain network-config testnet create\n</code></pre> <p>Replace <code>&lt;your-account-id.testnet&gt;</code> with the desired name for your account. This will create a new account with a generated key pair and save it to your keychain. </p> <p>Alternatively, you can also create an account using the <code>near create-account</code> command with the <code>--useFaucet</code> option:</p> <pre><code>near create-account &lt;accountId&gt; --useFaucet\n</code></pre> <p>Let's compare the results with our previous attempts. Without the vector store, the agent was prone to hallucination - generating plausible but incorrect responses. Now, the answers are both correct and complete grounded in the actual documentation - meaning that the agent was able to retrieve the right answers from the vector store.</p> <p>More impressively, the vector store was able to correctly pick up the relevant documents from the more than than 100 files that compose the official NEAR documentation.</p>"},{"location":"tutorials/rag/chunking/","title":"Chunking","text":"<p>Before converting documentation into vector embeddings, the NEAR AI platform segments the text into smaller, manageable chunks.</p> <p>This process - known as text chunking - makes it easier to process the documents, while allowing the model to better represent the information within each document.</p> <p>Tip</p> <p>Embedding models transform documents into fixed-size vectors, regardless of the original document size.</p> <p>By dividing documents into smaller chunks we can achieve a granular and accurate representation, since a single vector cannot capture a entire document's meaning.</p> <p>Warning</p> <p>Most users won't need to modify the default chunking settings. Only consider adjusting them if you notice the agent consistently struggles to answer questions due to how the documents are segmented.</p>"},{"location":"tutorials/rag/chunking/#chunking-strategy","title":"Chunking Strategy","text":"<p>When creating the vector store we left a parameter commented out in the code - <code>chunking_strategy</code>. This parameter allows you to specify how the documents are \"split\" into chunks before being processed by the model.</p> <pre><code>vs = client.vector_stores.create(\n    name=\"docs-vector-store-chunks\",\n    file_ids=file_ids,\n    # chunking_strategy={\n    #     \"chunk_overlap_tokens\": 400,\n    #     \"max_chunk_size_tokens\": 800\n    # }\n)\n</code></pre> <p>The <code>chunking_strategy</code> parameter is a dictionary that can have the following keys:</p> <ul> <li><code>chunk_overlap_tokens</code>: Number of tokens that chunks will overlap. (Default 400)</li> <li><code>max_chunk_size_tokens</code>: Max number of tokens that a chunk can have. (Default 800)</li> </ul> <p></p> <p>It is important to notice that chunks are not created based on the document's structure, but merely on counting tokens, which can lead to a loss of context.</p> <p>Make sure you change the <code>chunking_strategy</code> to better fit your documents' structure. For example, if your documents have a lot of code snippets, you can increase the <code>size</code> and <code>overlap</code> to make sure that the code can be correctly retrieved by the vector store.</p> <p>Additionally, you can use embedding models that are able to understand the document's structure and create chunks accordingly. We'll cover this in the next section.</p>"},{"location":"tutorials/rag/embeddings/","title":"Manual Embeddings","text":"<p>In the previous section we talked about chunking, and how it can help the model to better understand the document as a whole.</p> <p>However, current chunking strategies are very limited, dividing the document into chunks of fixed size with a fixed overlap, without considering the document's structure.</p> <p>If you know that your documents have a specific structure, you can create your own embeddings by manually dividing the document into chunks and processing them separately.</p> <p>Warning</p> <p>As with chunking, there are high chances that you do NOT need to create your own embeddings. We recommend to read this section only to gain understanding on how vector stores are implemented.</p>"},{"location":"tutorials/rag/embeddings/#manual-embeddings_1","title":"Manual Embeddings","text":"<p>Instead of using a vector store, you can directly call the Nomic v1.5 model so it creates the embedding vector for our documents:</p> <p>Example:</p> <pre><code>import json\nimport os\nimport re\n\nfrom glob import glob\nfrom urllib.parse import urlparse\n\nimport openai\nimport pandas as pd\nimport requests\nimport nearai\n\n# Load NEAR AI Hub configuration\nconfig = nearai.config.load_config_file()\nbase_url = config.get(\"api_url\", \"https://api.near.ai/\") + \"v1\"\nauth = config[\"auth\"]\n\nclient = openai.OpenAI(base_url=base_url, api_key=json.dumps(auth))\n\n# Create embeddings for all files\nembeddings_model = \"fireworks::nomic-ai/nomic-embed-text-v1.5\"\nprefix = \"classification: \"\n\ndocs = []\nmd_files = list(glob(\"./**/*.md\", recursive=True))\n\nfor file_path in md_files:\n    print(f\"Processing {file_path}\")\n\n    with open(file_path, 'r') as file:\n        docs.append(f\"{prefix}{file.read()}\")\n\nembeddings = client.embeddings.create(\n    input=docs,\n    model=embeddings_model\n)\n\ndf = pd.DataFrame.from_dict({\n    \"docs\": docs,\n    \"embeddings\": [e.embedding for e in embeddings.data]\n})\n\ndf.to_csv(\"embeddings.csv\", index=False)\n</code></pre> <p>Notice that we are manually storing the embeddings into a <code>CSV</code> file. This is because the platform does not support uploading embeddings directly into a vector store.</p> <p>Tip</p> <p>The Nomic v1.5 model uses <code>prefixes</code> (e.g. <code>classification:</code>, <code>search-document:</code>) to better guide the model on how to transform the documents. Make sure to read your model's documentation before using it to make the most of the embeddings</p>"},{"location":"tutorials/rag/embeddings/#using-manual-embeddings","title":"Using Manual Embeddings","text":"<p>After creating the embeddings, you will need to emulate the vector store's behavior by querying the embeddings and selecting the most relevant documents.</p> <p>Example:</p> <pre><code>import json\n\nimport openai\nimport nearai\nimport numpy as np\nimport pandas as pd\nfrom nearai.agents.environment import Environment\n\n# Load NEAR AI Hub configuration\nconfig = nearai.config.load_config_file()\nbase_url = config.get(\"api_url\", \"https://api.near.ai/\") + \"v1\"\nauth = config[\"auth\"]\n\nclient = openai.OpenAI(base_url=base_url, api_key=json.dumps(auth))\n\nMODEL = \"llama-v3p3-70b-instruct\"\n\ndf = pd.read_csv('./embeddings.csv')\nEMBEDDING_MODEL = \"fireworks::nomic-ai/nomic-embed-text-v1.5\"\nPREFIX = \"classification: \"\n\n\ndef cosine_similarity(a, b):\n    a = np.matrix(a)\n    b = np.array(b)\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\n\ndef run(env: Environment):\n    user_query = env.list_messages()[-1][\"content\"]\n\n    embedding = client.embeddings.create(\n                input=[f\"{PREFIX}{user_query}\"],\n                model=EMBEDDING_MODEL,\n            ).data[0].embedding\n\n    df['similarities'] = df.embeddings.apply(\n        lambda x: cosine_similarity(x, embedding)\n    )\n\n    res = df.sort_values('similarities', ascending=False).head(6)\n\n    prompt = [\n        {\n            \"role\": \"user query\",\n            \"content\": user_query,\n        },\n        {\n            \"role\": \"documentation\",\n            \"content\": json.dumps(res.docs.tolist()),\n        },\n        {\n            \"role\": \"system\",\n            \"content\": \"Give a brief but complete answer to the user's query, staying as true as possible to the documentation SPECIALLY when dealing with code.\"\n        }\n    ]\n\n    answer = env.completion(model=MODEL, messages=prompt)\n    env.add_reply(answer)\n\n\nrun(env)\n</code></pre> <p>In the code above, we transform the user's query into a vector embedding using the same model that created our documentation embeddings. </p> <p>The system then calculates the cosine similarity between the query embedding and all stored document embeddings to find the most relevant matches.</p> <p>Finally, we rank the documents by their similarity scores and select the 6 most relevant chunks to provide context for the model's response.</p>"},{"location":"tutorials/rag/introduction/","title":"Building a Documentation Agent with RAG","text":"<p>Current AI models are trained on vast datasets, making them powerful at generating general-purpose text. However, when asked about specific topics outside their training data (like your company's internal documentation), these models often hallucinate - generating plausible-sounding but incorrect information.</p> <p>Thankfully, there is a solution to this problem: Retrieval-Augmented Generation (RAG). This technique consists on combining two key components:</p> <ol> <li>A retrieval system that finds relevant information from your custom dataset</li> <li>A language model that generates accurate responses using the retrieved information</li> </ol> <p>In this tutorial, you'll learn how to build a RAG-powered agent that accurately answers questions about NEAR Protocol.</p>"},{"location":"tutorials/rag/introduction/#what-you-will-need","title":"What You Will Need","text":"<p>To follow this tutorial you will need:</p> <ol> <li>NEAR AI CLI installed on your local machine \u2192 Installation Guide</li> <li>Basic understanding of creating a NEAR AI agent \u2192 Agents Quickstart Tutorial</li> </ol>"},{"location":"tutorials/rag/introduction/#overview","title":"Overview","text":"<p>This tutorial is divided in the following sections:</p> <ul> <li>The problem \u2192 Understanding AI hallucination from incorrect data</li> <li>Vector Stores \u2192 Getting started with vector stores</li> <li>RAG Agent \u2192 Building a NEAR Documentation Q&amp;A agent</li> <li>Chunking \u2192 Dive deeper into how vector stores store documents</li> <li>Embeddings \u2192 Creating document embeddings manually</li> </ul>"},{"location":"tutorials/rag/problem/","title":"The Problem","text":"<p>Let's start by understanding the problem that RAG solves. For this, we will create an agent that uses the open-source <code>llama</code> model, and ask it questions about NEAR Protocol.</p> <p>Then, we will enhance the agent by giving it access to the actual documentation, demonstrating how this dramatically improves the accuracy of its responses.</p>"},{"location":"tutorials/rag/problem/#an-agent-that-hallucinates","title":"An Agent that Hallucinates","text":"<p>Let's create an agent that uses the open-source <code>llama</code> model, and ask it questions about NEAR Protocol. For this, we will run the command <code>nearai agent create</code>, using the following parameters:</p> <pre><code>Agent Name: docs-ai-tutorial\nDescription: Answer questions about NEAR Protocol\nInstructions: You are a helpful assistant that answers questions about NEAR Protocol\n</code></pre> NEAR CLI not installed? <p>If you haven't installed the NEAR CLI yet, follow our Agent Quickstart Tutorial for installation instructions.</p> <p>Once the agent creation is complete, the CLI will show you how to run the agent locally:</p> <pre><code>nearai agent interactive ~/.nearai/registry/&lt;your-account.near&gt;/docs-ai-tutorial/0.0.1 --local\n</code></pre> <p>Now ask it a few questions about NEAR Protocol:</p> What types of access keys are there in NEAR? <pre><code>Assistant: In the NEAR Protocol, there are two main types of access keys:\n\n1. **Full Access Key**: This type of key has full control over the account and can perform any action, including managing other access keys. It's like the master key to the account.\n2. **Function Call Access Key**: This type of key has limited permissions and can only call specific functions on the account's smart contracts. It's like a key that only unlocks a specific door.\n\nThere's also a special case:\n\n3. **View Function Access Key**: This type of key can only call view functions on the account's smart contracts, which means it can only retrieve information but not modify the state of the contract. It's like a key that only allows peeking through a window.\n\nThese access keys are used to manage account permissions and control access to the account's resources. By setting up different access keys with varying levels of permissions, users can ensure that their account is secure and that others can only perform specific actions.\n\nDo you have any follow-up questions about access keys on NEAR Protocol?\n</code></pre> How can I create an account using the NEAR CLI? <pre><code>Assistant: To create an account using the NEAR CLI, you can use the `near create-account` command.\n\nHere's an example:\n\n`near create-account mynewaccount.near --masterAccount mymainaccount.near`\n\nThis will create a new account `mynewaccount.near` with a full access key, derived from the `mymainaccount.near` master account.\n\nIf you want to create an account with a specific public key or a specific access key permission, you can use additional options. For example:\n\n`near create-account mynewaccount.near --publicKey &lt;public_key&gt; --accessKey &lt;access_key_permission&gt;`\n\nReplace `&lt;public_key&gt;` with the actual public key and `&lt;access_key_permission&gt;` with one of the following: `FullAccess`, `FunctionCall`, or `ViewFunction`.\n\nMake sure to replace `mymainaccount.near` and `mynewaccount.near` with the actual account IDs you want to use.\n\nNote: You need to have the NEAR CLI installed and configured, and have a master account with sufficient balance to cover the account creation fee.\n</code></pre> <p>This agent uses <code>llama-v3p1-70b-instruct</code> model, which is a powerful open-domain model, and gets the answers mostly right... but then it starts to invent things.</p> <p>Without going too deep on the specifics of NEAR Protocol - which are not relevant for this tutorial - the agent invented a third type of access key (<code>View Function Access Key</code>), which simply does not exist, and proposed outdated commands to create accounts.</p>"},{"location":"tutorials/rag/problem/#giving-context-to-the-model","title":"Giving Context to the Model","text":"<p>Now, lets try to give some context to the model so it can improve its answers. </p> <p>For that, lets directly embed into the agent's prompt documentation on:</p> <ul> <li><code>Access Keys</code> </li> <li><code>NEAR CLI</code></li> </ul> <p>In your agent directory, let's download these files from the official NEAR docs repo:</p> <pre><code>curl -L https://raw.githubusercontent.com/near/docs/master/docs/1.concepts/protocol/access-keys.md -o access-keys.md &amp;&amp; \\\ncurl -L https://raw.githubusercontent.com/near/docs/master/docs/4.tools/cli.md -o cli.md\n</code></pre> <p>Your agent directory should now look like this:</p> <pre><code>\ud83d\udcc1 ~/.nearai/registry/&lt;your-account.near&gt;/ai-docs-tutorial/0.0.1\n\u251c\u2500\u2500 \ud83d\udcc4 agent.py\n\u251c\u2500\u2500 \ud83d\udcc4 access-keys.md\n\u251c\u2500\u2500 \ud83d\udcc4 cli.md\n\u2514\u2500\u2500 \ud83d\udcc4 metadata.json\n</code></pre> <p>Next, we'll update <code>agent.py</code> and instruct it to use these two markdown files:</p> <pre><code>import json\nfrom nearai.agents.environment import Environment\n\n\ndef run(env: Environment):\n    # Load files\n    files = [\"cli.md\", \"access-keys.md\"]\n    content = [{f: open(f, encoding=\"utf-8\").read()} for f in files]\n\n    # Get user query from last messages\n    user_query = env.list_messages()[-1][\"content\"]\n\n    prompt = [\n        {\n            \"role\": \"user query\",\n            \"content\": user_query,\n        },\n        {\n            \"role\": \"documentation\",\n            \"content\": json.dumps(content)\n        },\n        {\n            \"role\": \"system\",\n            \"content\": \"Give a brief but complete answer to the user's query, staying as true as possible to the documentation ESPECIALLY when dealing with code.\"\n        }\n    ]\n\n    result = env.completion(prompt)\n    env.add_reply(result)\n\nrun(env)\n</code></pre> <p>After updating the agent code, lets invoke it again and ask it the same questions:</p> What types of access keys are there in NEAR? <pre><code>Assistant: NEAR Protocol distinguishes two types of Access Keys:\n\n1. **Full-Access Keys**: Have full control over the account and should never be shared.\n2. **Function-Call Keys**: Can only sign calls for a specific contract and are meant to be shared.\n\nEach account in NEAR can hold multiple keys, which can be added or removed to fine-grain control over the account's permissions.\n</code></pre> How can I create an account using the NEAR CLI? <pre><code>Assistant: To create an account using the NEAR CLI, you can use the `create-account` command. Here is an example of how to do it:\n\n`\nexport ACCOUNT_ID=bob.testnet\nnear account create-account sponsor-by-faucet-service $ACCOUNT_ID autogenerate-new-keypair save-to-keychain network-config testnet create\n`\n\nAlternatively, you can use the short version of the command:\n\n`\nexport ACCOUNT_ID=bob.testnet\nnear create-account $ACCOUNT_ID --useFaucet --networkId testnet\n`\n</code></pre> <p>As you can see the answers now are much more accurate, which is expected, as we are providing the model with the actual documentation that it needs to generate the answers.</p>"},{"location":"tutorials/rag/problem/#limitations-of-this-approach","title":"Limitations of this Approach","text":"<p>While useful to understand the concept, this agent has a very important limitation: It does not scale</p> <p>Since this approach loads all of the content of a document into the prompt, it would quickly hit a limit on the number of tokens that the model can process if we were to load all of the documentation.</p> <p>To solve this problem, we need to use rely on a special kind of database called a Vector Store, which can help us to store documents and easily retrieve the most relevant ones to answer a given query.</p>"},{"location":"tutorials/rag/vector_store/","title":"Vector Stores","text":"<p>Vector Stores are a special kind of database that stores documents and allows retrieving them through natural language. </p> <p>In our case, we will store all NEAR documentation in a vector store, this way if a user asks \"What types of access keys are there in NEAR?\", the vector store will help us find our access keys docs, so we can use it to answer the question.</p> <p>Tip</p> <p>The Vector Store is built separately from the agent, and can be used in multiple places.</p> <p>Info</p> <p>This tutorial assumes OpenAI version 1.66.2 or greater. For previous versions the vector store methods can be found at <code>client.beta.vector_stores</code> instead of <code>client.vector_stores</code>.</p>"},{"location":"tutorials/rag/vector_store/#how-vector-stores-work","title":"How Vector Stores Work","text":"<p>Vector Stores use AI models to convert text documents into low-dimensional numerical representations that computers can easily process and compare. These vectors are like \"fingerprints\" of the documents - each one unique, but much smaller than the original text.</p> <p>For example, the Nomic v1.5 model can take our entire <code>cli.md</code> documentation file and represent it as a compact vector:</p> <pre><code>[0.01025390625, 0.048309326171875, -0.166015625, ... , -0.004741668701171875, -0.048553466796875]\n</code></pre> <p>Each number in this vector captures some aspect of the document's meaning. Documents with similar meanings will have similar vectors, appearing \"closer\" to each other in the vector space - like clusters of related topics.</p> <p>This is powerful because it means we can convert user questions into vectors too - allowing us to find relevant documentation by looking for documents that appear \"closest\" to the user's question.</p> <p></p> <p>When a user asks a question, the vector still will help us find relevant documentation by:</p> <ol> <li>Converting their question into a vector</li> <li>Comparing it with all our stored document vectors</li> <li>Retrieving the documents whose vectors are closest to the question's vector</li> </ol> <p>Tip</p> <p>How these representations are generated is a complex topic that exceeds the scope of this tutorial. For us, it suffices to know that such models already exist and are available for us to use.</p>"},{"location":"tutorials/rag/vector_store/#creating-a-vector-store","title":"Creating a Vector Store","text":"<p>Let's create a vector store using using all of our documentation files in the dataset.</p> <p>Didn't download the dataset?</p> <p>If you have not completed the problem section yet, you can download the dataset by running the following command: <pre><code>curl -L https://api.github.com/repos/near-examples/docs-ai/tarball/main | tar xz --strip=2 '*/docs-gpt/dataset'\n</code></pre></p> <p>Creating a vector store in NEAR AI consist of 2 main steps:</p> <p>1.) uploading the files to NEAR AI</p> <p>2.) assigning them to a vector store. </p> <p>Let's start by uploading the files to NEAR AI. Create a new file called <code>vector.py</code> and paste the following code:</p> <pre><code>import json\nfrom glob import glob\n\nimport openai\nimport nearai\n\n# Load NEAR AI Hub configuration\nconfig = nearai.config.load_config_file()\nbase_url = config.get(\"api_url\", \"https://api.near.ai/\") + \"v1\"\nauth = config[\"auth\"]\n\nclient = openai.OpenAI(base_url=base_url, api_key=json.dumps(auth))\n\n# Create a vector store for vector store docs\nmd_files = list(glob(\"./**/*.md\", recursive=True))\nfile_ids = []\n\nfor file_path in md_files:\n    print(f\"Processing {file_path}\")\n\n    with open(file_path, 'r', encoding='utf-8') as file:\n        uploaded_file = client.files.create(\n            file=(file_path, file.read(), \"text/markdown\"),\n            purpose=\"assistants\"\n        )\n        file_ids.append(uploaded_file.id)\n\nvs = client.vector_stores.create(\n    name=\"docs-vector-store-chunks\",\n    file_ids=file_ids,\n    # chunking_strategy={\n    #     \"chunk_overlap_tokens\": 400,\n    #     \"max_chunk_size_tokens\": 800\n    # }\n)\n\nprint(vs.id)\n</code></pre>"},{"location":"tutorials/rag/vector_store/#how-it-works","title":"How it works?","text":"<p>In the code above we are first instantiating an OpenAI compatible client</p> <pre><code># Load NEAR AI Hub configuration\nconfig = nearai.config.load_config_file()\nbase_url = config.get(\"api_url\", \"https://api.near.ai/\") + \"v1\"\nauth = config[\"auth\"]\n\nclient = openai.OpenAI(base_url=base_url, api_key=json.dumps(auth))\n</code></pre> <p>Note</p> <p>While we are using a OpenAI client, the files are being uploaded to the NEAR AI platform, not OpenAI.</p> <p>Then, we list all markdown files in the current directory and its subdirectories</p> <pre><code>md_files = list(glob(\"./**/*.md\", recursive=True))\n</code></pre> <p>For each file, we read its content and upload it to the NEAR AI platform</p> <pre><code>for file_path in md_files:\n    print(f\"Processing {file_path}\")\n\n    with open(file_path, 'r', encoding='utf-8') as file:\n        uploaded_file = client.files.create(\n            file=(file_path, file.read(), \"text/markdown\"),\n            purpose=\"assistants\"\n        )\n        file_ids.append(uploaded_file.id)\n</code></pre> <p>Finally, we create a vector store with the uploaded files and print its <code>id</code></p> <pre><code>vs = client.vector_stores.create(\n    name=\"docs-vector-store-chunks\",\n    file_ids=file_ids,\n    # chunking_strategy={\n    #     \"chunk_overlap_tokens\": 400,\n    #     \"max_chunk_size_tokens\": 800\n    # }\n)\n\nprint(vs.id)\n</code></pre> <p>Now run the script:</p> <p><pre><code>python3 vector.py\n</code></pre> You should see each file being uploaded to NEAR AI in the console. </p> <p>At the end of the script, you will get the <code>id</code> of the vector store that was created. This <code>id</code> will be used in the next section to build an agent that leverages the knowledge contained on it.</p> Where are the Embeddings? <p>No need to worry about this, the NEAR AI platform abstracts away all the complexity of processing the files to create embeddings, and then storing them in a database to be queried.</p> <p>You only need to upload the files and the platform will take care of the rest</p> <p>Chunking Strategy</p> <p>In the code above we have commented the <code>chunking_strategy</code> parameter, which allows you to specify how the documents are \"split\" into chunks before being processed by the model.</p> <p>Do not worry about this parameter for now, we will come back to it later in this tutorial.</p>"},{"location":"tutorials/rag/vector_store/#a-note-on-preprocessing","title":"A Note on Preprocessing","text":"<p>While the platform abstracts away the complexity of creating embeddings, it is still a good idea to preprocess the files before uploading them.</p> <p>In our case, our <code>markdown</code> files contain a lot of unnecessary information, such as <code>imports</code>, <code>iframes</code> and other tags that are simply not relevant for the document's semantics.</p> <p>Furthermore - and this might be common to many documentation files - our files do not necessarily contain the plain-text code snippets, but instead embed them from external sources (e.g. GitHub). So we need to preprocess them to translate the Github tags into actual code snippets.</p> <p>In case you are curious, you can file all the preprocessing steps we use for our documentation in the vector.py script</p>"}]}